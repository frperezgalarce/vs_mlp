{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq1_harmonics_rel_phase_0\n",
      "Freq2_harmonics_rel_phase_0\n",
      "Freq3_harmonics_rel_phase_0\n",
      "downsampling\n",
      "21885\n",
      "369616\n",
      "done downsampling\n",
      "        Amplitude  AndersonDarling  Autocor_length  Beyond1Std    CAR_mean  \\\n",
      "5472      0.27550         0.229660               1    0.353333   23.520652   \n",
      "59067     0.34500         0.000116               1    0.370000   55.028761   \n",
      "325888    0.24050         0.003151               1    0.353333   26.861221   \n",
      "315033    0.05400         0.000000               1    0.173333  193.960646   \n",
      "67839     0.13900         0.000000              11    0.206667    0.071036   \n",
      "...           ...              ...             ...         ...         ...   \n",
      "332862    0.38350         0.000000               1    0.423333   91.773398   \n",
      "45732     0.11275         0.000000               5    0.243243    0.003321   \n",
      "160255    0.01850         0.058081               2    0.316667   36.404377   \n",
      "133394    0.03000         0.000130               4    0.390000   22.836133   \n",
      "310395    0.02550         0.000417               2    0.231579   22.579923   \n",
      "\n",
      "        CAR_sigma      CAR_tau       Con        Eta_e  \\\n",
      "5472     0.199295     0.791394  0.000000    11.391262   \n",
      "59067    0.814120     0.345795  0.000000   695.875695   \n",
      "325888   0.201487     0.698896  0.000000  1217.209351   \n",
      "315033   0.080924     0.086497  0.000000    15.237443   \n",
      "67839    0.009089   224.203674  0.036913   876.164644   \n",
      "...           ...          ...       ...          ...   \n",
      "332862   0.982281     0.183130  0.000000    97.026012   \n",
      "45732    0.009558  4501.969071  0.041667     0.245273   \n",
      "160255   0.623976     0.416017  0.003356     5.744891   \n",
      "133394   0.714665     0.584894  0.000000     3.745459   \n",
      "310395   0.324348     0.607118  0.032258   105.955036   \n",
      "\n",
      "        FluxPercentileRatioMid20  ...      Skew  SlottedA_length  \\\n",
      "5472                    0.192661  ... -0.175080          1.89454   \n",
      "59067                   0.178268  ... -0.334748          0.10380   \n",
      "325888                  0.181384  ...  0.012530          1.86178   \n",
      "315033                  0.145161  ...  1.438135          1.90543   \n",
      "67839                   0.102767  ...  1.023642          0.06310   \n",
      "...                          ...  ...       ...              ...   \n",
      "332862                  0.235795  ... -0.573422          0.21337   \n",
      "45732                   0.051163  ...  1.549998          1.79450   \n",
      "160255                  0.166667  ...  0.406383          3.79944   \n",
      "133394                  0.224490  ... -0.128008          7.06784   \n",
      "310395                  0.162162  ... -0.905932          3.56820   \n",
      "\n",
      "        SmallKurtosis       Std  StetsonK  StetsonK_AC  \\\n",
      "5472        -0.116561  0.132898  0.785708     0.720950   \n",
      "59067       -0.591644  0.183732  0.831309     0.792281   \n",
      "325888      -0.711951  0.128307  0.838653     0.712007   \n",
      "315033       4.728533  0.020866  0.689299     0.617853   \n",
      "67839        0.125340  0.078050  0.805649     0.774046   \n",
      "...               ...       ...       ...          ...   \n",
      "332862      -0.804224  0.219728  0.855664     0.778263   \n",
      "45732        3.354022  0.059594  0.731380     0.787845   \n",
      "160255       0.378937  0.009555  0.807396     0.756188   \n",
      "133394      -0.708372  0.016124  0.846854     0.764854   \n",
      "310395       2.255607  0.013032  0.765097     0.716790   \n",
      "\n",
      "        StructureFunction_index_21  StructureFunction_index_31  \\\n",
      "5472                      1.823350                    2.553383   \n",
      "59067                     1.925273                    2.764164   \n",
      "325888                    1.604025                    2.028600   \n",
      "315033                    1.868735                    2.800471   \n",
      "67839                     1.930869                    2.816307   \n",
      "...                            ...                         ...   \n",
      "332862                    1.495590                    1.757148   \n",
      "45732                     1.831998                    2.576058   \n",
      "160255                    1.660973                    2.236973   \n",
      "133394                    1.590015                    1.980266   \n",
      "310395                    1.853950                    2.652578   \n",
      "\n",
      "        StructureFunction_index_32   label  \n",
      "5472                      1.480318  ClassA  \n",
      "59067                     1.540029  ClassA  \n",
      "325888                    1.301411  ClassA  \n",
      "315033                    1.639819  ClassB  \n",
      "67839                     1.476419  ClassB  \n",
      "...                            ...     ...  \n",
      "332862                    1.233612  ClassA  \n",
      "45732                     1.427096  ClassB  \n",
      "160255                    1.450298  ClassB  \n",
      "133394                    1.262270  ClassB  \n",
      "310395                    1.585277  ClassB  \n",
      "\n",
      "[40000 rows x 61 columns]\n",
      "(40000, 61)\n",
      "(31940, 61)\n",
      "(28625, 60)\n",
      "(22840, 61)\n",
      "Index(['PeriodLS', 'Amplitude', 'AndersonDarling', 'Autocor_length',\n",
      "       'Beyond1Std', 'CAR_mean', 'CAR_sigma', 'CAR_tau', 'Con', 'Eta_e',\n",
      "       'FluxPercentileRatioMid20', 'FluxPercentileRatioMid35',\n",
      "       'FluxPercentileRatioMid50', 'FluxPercentileRatioMid65',\n",
      "       'FluxPercentileRatioMid80', 'Freq1_harmonics_amplitude_0',\n",
      "       'Freq1_harmonics_amplitude_1', 'Freq1_harmonics_amplitude_2',\n",
      "       'Freq1_harmonics_amplitude_3', 'Freq1_harmonics_rel_phase_1',\n",
      "       'Freq1_harmonics_rel_phase_2', 'Freq1_harmonics_rel_phase_3',\n",
      "       'Freq2_harmonics_amplitude_0', 'Freq2_harmonics_amplitude_1',\n",
      "       'Freq2_harmonics_amplitude_2', 'Freq2_harmonics_amplitude_3',\n",
      "       'Freq2_harmonics_rel_phase_1', 'Freq2_harmonics_rel_phase_2',\n",
      "       'Freq2_harmonics_rel_phase_3', 'Freq3_harmonics_amplitude_0',\n",
      "       'Freq3_harmonics_amplitude_1', 'Freq3_harmonics_amplitude_2',\n",
      "       'Freq3_harmonics_amplitude_3', 'Freq3_harmonics_rel_phase_1',\n",
      "       'Freq3_harmonics_rel_phase_2', 'Freq3_harmonics_rel_phase_3', 'Gskew',\n",
      "       'LinearTrend', 'MaxSlope', 'Mean', 'Meanvariance', 'MedianAbsDev',\n",
      "       'MedianBRP', 'PairSlopeTrend', 'PercentAmplitude',\n",
      "       'PercentDifferenceFluxPercentile', 'Period_fit', 'Psi_CS', 'Psi_eta',\n",
      "       'Q31', 'Rcs', 'Skew', 'SlottedA_length', 'SmallKurtosis', 'Std',\n",
      "       'StetsonK', 'StetsonK_AC', 'StructureFunction_index_21',\n",
      "       'StructureFunction_index_31', 'StructureFunction_index_32', 'label'],\n",
      "      dtype='object')\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([4800, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([1201, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([28746, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([31940, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([1201, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([22840, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([22840, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  1000\n",
      "Epoch:  0\n",
      "training: epoch:  1  loss:  82.67606103420258 -- aux loss:  753.8707415163517\n",
      "validating: epoch:  1  loss:  1.569274365901947\n",
      "Epoch:  1\n",
      "training: epoch:  2  loss:  82.8394084572792 -- aux loss:  673.5187869668007\n",
      "validating: epoch:  2  loss:  1.5667539238929749\n",
      "Epoch:  2\n",
      "training: epoch:  3  loss:  82.83942550420761 -- aux loss:  673.1160491108894\n",
      "validating: epoch:  3  loss:  1.566419780254364\n",
      "Epoch:  3\n",
      "training: epoch:  4  loss:  82.83942949771881 -- aux loss:  673.0416297614574\n",
      "validating: epoch:  4  loss:  1.5663401186466217\n",
      "Epoch:  4\n",
      "training: epoch:  5  loss:  82.839430809021 -- aux loss:  673.022249430418\n",
      "validating: epoch:  5  loss:  1.5663178265094757\n",
      "Epoch:  5\n",
      "training: epoch:  6  loss:  82.83943140506744 -- aux loss:  673.0166806280613\n",
      "validating: epoch:  6  loss:  1.5663112998008728\n",
      "Epoch:  6\n",
      "training: epoch:  7  loss:  82.83943158388138 -- aux loss:  673.0150200426579\n",
      "validating: epoch:  7  loss:  1.566309541463852\n",
      "Epoch:  7\n",
      "training: epoch:  8  loss:  82.83943170309067 -- aux loss:  673.0145761072636\n",
      "validating: epoch:  8  loss:  1.5663086771965027\n",
      "Epoch:  8\n",
      "training: epoch:  9  loss:  82.83943170309067 -- aux loss:  673.0142981410027\n",
      "validating: epoch:  9  loss:  1.5663082301616669\n",
      "Epoch:  9\n",
      "training: epoch:  10  loss:  82.83943170309067 -- aux loss:  673.0141898989677\n",
      "validating: epoch:  10  loss:  1.566308170557022\n",
      "The current loss: 1.566308170557022\n",
      "the_last_loss: 1.5663082301616669\n",
      "trigger times: 0\n",
      "recall\n",
      "tensor(1.)\n",
      "precision\n",
      "tensor(0.5799)\n",
      "f1_score\n",
      "tensor(0.7341)\n",
      "Accuracy of the network on test objects: 57 %\n",
      "57.990677\n",
      "recall\n",
      "tensor(1.)\n",
      "precision\n",
      "tensor(1.)\n",
      "f1_score\n",
      "tensor(1.)\n",
      "Accuracy of the network on test objects: 100 %\n",
      "100.0\n",
      "recall\n",
      "tensor(1.)\n",
      "precision\n",
      "tensor(0.3092)\n",
      "f1_score\n",
      "tensor(0.4723)\n",
      "Accuracy of the network on test objects: 30 %\n",
      "30.91506\n",
      "sum mask2 - L1:  tensor(0, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(0, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(0, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(6000, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(10000, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(200, device='cuda:0')\n",
      "Epoch:  10\n",
      "training: epoch:  11  loss:  82.83943170309067 -- aux loss:  673.0141386985779\n",
      "validating: epoch:  11  loss:  1.566308081150055\n",
      "Epoch:  11\n",
      "training: epoch:  12  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  12  loss:  1.566308081150055\n",
      "Epoch:  12\n",
      "training: epoch:  13  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  13  loss:  1.566308081150055\n",
      "Epoch:  13\n",
      "training: epoch:  14  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  14  loss:  1.566308081150055\n",
      "Epoch:  14\n",
      "training: epoch:  15  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  15  loss:  1.566308081150055\n",
      "Epoch:  15\n",
      "training: epoch:  16  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  16  loss:  1.566308081150055\n",
      "Epoch:  16\n",
      "training: epoch:  17  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  17  loss:  1.566308081150055\n",
      "Epoch:  17\n",
      "training: epoch:  18  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  18  loss:  1.566308081150055\n",
      "Epoch:  18\n",
      "training: epoch:  19  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  19  loss:  1.566308081150055\n",
      "Epoch:  19\n",
      "training: epoch:  20  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  20  loss:  1.566308081150055\n",
      "The current loss: 1.566308081150055\n",
      "the_last_loss: 1.566308081150055\n",
      "trigger times: 0\n",
      "recall\n",
      "tensor(1.)\n",
      "precision\n",
      "tensor(0.5799)\n",
      "f1_score\n",
      "tensor(0.7341)\n",
      "Accuracy of the network on test objects: 57 %\n",
      "57.990677\n",
      "recall\n",
      "tensor(1.)\n",
      "precision\n",
      "tensor(1.)\n",
      "f1_score\n",
      "tensor(1.)\n",
      "Accuracy of the network on test objects: 100 %\n",
      "100.0\n",
      "recall\n",
      "tensor(1.)\n",
      "precision\n",
      "tensor(0.3092)\n",
      "f1_score\n",
      "tensor(0.4723)\n",
      "Accuracy of the network on test objects: 30 %\n",
      "30.91506\n",
      "sum mask2 - L1:  tensor(0, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(0, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(0, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(6000, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(10000, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(200, device='cuda:0')\n",
      "Epoch:  20\n",
      "training: epoch:  21  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  21  loss:  1.566308081150055\n",
      "Epoch:  21\n",
      "training: epoch:  22  loss:  82.83943170309067 -- aux loss:  673.0141252577305\n",
      "validating: epoch:  22  loss:  1.566308081150055\n",
      "Epoch:  22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a4d5ef31f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                                     hist_val, hist_train = nn.train(net, train_loader, train_loader_prior, val_loader, test_loader,\n\u001b[0;32m--> 101\u001b[0;31m                                     EPS1, learning_rate, input_size, aux_loss_activated=aux_loss_activated, patience=20)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                                     \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/vsbms_multiple_classes/vsbms_multiple_classes/Network.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, train_loader_prior, val_loader, test_loader, EPS1, learning_rate, input_size, num_epochs_prior, aux_loss_activated, patience)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocked_masks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as f \n",
    "from torch.autograd import Variable\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from scipy import stats\n",
    "from itertools import cycle\n",
    "import sys\n",
    "import utilities as ut\n",
    "from Network import Net\n",
    "import Network as nn\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#ab y c con 3000 samples, 256 batch y 10000 objetos. \n",
    "\n",
    "results = []\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "samples = 3000 #\n",
    "epsilon=0.2\n",
    "#for epsilon in [0.1, 0.05, 0.025, 0.15]:\n",
    "for sc in ['_RRab']: #,'_RRc','_RRab'\n",
    "    for batch_size in [256]:\n",
    "        for hidden_size in [100]:\n",
    "            for aux_loss_activated in [True]:\n",
    "                for EPS1 in [0.175]:\n",
    "                    for n in [40000]:\n",
    "                        for opt in [1]:\n",
    "                            for t in range(15):\n",
    "                                train_dataset, test_dataset = ut.load_files(dataset=1, subclass=sc)\n",
    "                                input_size = train_dataset.shape[1]-1\n",
    "\n",
    "                                if n < 50000:\n",
    "                                    train_dataset = ut.down_sampling(train_dataset)\n",
    "                                    train_dataset = train_dataset.sample(n)\n",
    "                                    print(train_dataset)\n",
    "                                else: \n",
    "                                    trainig_dataset_a = train_dataset[train_dataset.label=='ClassA']\n",
    "                                    print('shape: ', trainig_dataset_a.shape[0])\n",
    "                                    n2 = n - trainig_dataset_a.shape[0]\n",
    "                                    print('clase no RR Lrae', n2)\n",
    "                                    trainig_dataset_b = train_dataset[~(train_dataset.label=='ClassA')].sample(n2)\n",
    "                                    train_dataset = pd.concat([trainig_dataset_a, trainig_dataset_b])\n",
    "\n",
    "                                train_dataset, test_dataset = ut.delete_outliers(train_dataset, test_dataset)\n",
    "\n",
    "                                train_dataset = ut.sort_columns(train_dataset)\n",
    "                                test_dataset = ut.sort_columns(test_dataset)\n",
    "\n",
    "                                test_dataset_pred = test_dataset.copy()\n",
    "                                train_dataset_pred = train_dataset.copy()\n",
    "\n",
    "                                try:\n",
    "                                    '''data_prior = ut.generate_samples_2D(samples, train_dataset, distribution='uniform',subclass=False, \n",
    "                                                 DRs={'up': 0.65, 'lp': 0.35, 'ua':0.45, 'la':0.1})\n",
    "                                                                        # 2d uniform DRs={'up': 0.65, 'lp': 0.35, 'ua':0.45, 'la':0.1})'''\n",
    "                                    data_prior = ut.generate_samples(samples, train_dataset, epsilon,  option = opt, \n",
    "                                                                    DRs={'feature': 'Amplitude', 'up':0.45, 'lp':0.20})#'PeriodLS', 'up': 0.65, 'lp': 0.35})\n",
    "\n",
    "                                    train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "                                    train_dataset_prior, val_dataset_prior = train_test_split(data_prior, test_size=0.2, random_state=42)\n",
    "                                    print(train_dataset_prior.columns)\n",
    "                                    _, _, train_target_prior, train_loader_prior = ut.get_tensors(train_dataset_prior, batch_size)\n",
    "                                    _, _, val_target_prior, val_loader_prior     = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                                    _, _, train_target, train_loader             = ut.get_tensors(train_dataset, batch_size)\n",
    "                                    _, _, train_target_pred, train_loader_pred   = ut.get_tensors(train_dataset_pred, batch_size)\n",
    "                                    _, _, val_target, val_loader                 = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                                    _, _, test_target, test_loader               = ut.get_tensors(test_dataset, batch_size)\n",
    "                                    _, _, test_target_pred, test_loader_pred     = ut.get_tensors(test_dataset_pred, batch_size)\n",
    "\n",
    "                                    net = Net(input_size, hidden_size, hidden_size, num_classes)\n",
    "                                    net.cuda()\n",
    "\n",
    "                                    hist_val, hist_train = nn.train(net, train_loader, train_loader_prior, val_loader, test_loader,\n",
    "                                    EPS1, learning_rate, input_size, aux_loss_activated=aux_loss_activated, patience=20)\n",
    "\n",
    "                                    acc_train, recall_train, f1_train = nn.get_results(net, train_loader, input_size)\n",
    "                                    acc_test, recall_test, f1_test  = nn.get_results(net, test_loader, input_size)\n",
    "                                    \n",
    "                                    \n",
    "                                    roc_train = nn.get_roc_curve(net, train_loader, input_size)\n",
    "                                    roc_test = nn.get_roc_curve(net, test_loader, input_size)\n",
    "                                    \n",
    "                                    \n",
    "                                    results.append([acc_train, acc_test,recall_train, recall_test, f1_train, f1_test, roc_train, roc_test, epsilon, batch_size, hidden_size, aux_loss_activated, EPS1, n, opt, sc])\n",
    "                                    pd.DataFrame(results, columns=['acc_train', 'acc_test','recall_train', 'recall_test','f1_train', 'f1_test', \n",
    "                                                                   'roc_train', 'roc_test', 'epsilon', 'batch_size', 'hidden_size',\n",
    "                                     'aux_loss_activated', 'EPS1', 'n', 'opt', 'sc']).to_csv('rrab_2D_amplitude-19-05-2022.csv')\n",
    "                                except Exception as e:\n",
    "                                    print(e) \n",
    "                                    print(str(batch_size)+\"-\"+str(hidden_size)+\"-\"+str(aux_loss_activated)+\"-\"+str(EPS1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.get_results(net, train_loader, input_size)\n",
    "nn.get_results(net, test_loader, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = ut.load_files(dataset=1, subclass='_RRab')\n",
    "train_dataset[train_dataset['PeriodLS']<1].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[train_dataset['PeriodLS']<1][train_dataset.label=='ClassA']['PeriodLS'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[test_dataset['PeriodLS']<1][test_dataset.label=='ClassA']['PeriodLS'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[train_dataset.label==1]['Amplitude'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[test_dataset.label==1]['Amplitude'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.get_roc_curve(net, test_loader, input_size, title=\"Regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.plot_training(hist_val, hist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "curves, labels, probs_test = ut.get_predictions(net, test_loader_pred, device)\n",
    "pred_labels = probs_test.argmax(1, keepdim = True)\n",
    "ut.plot_confusion_matrix(np.round(labels), pred_labels, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_file = open(\"size_MLP_noise.csv\", \"a\")\n",
    "#csv_file.write(str(np.asarray(acc_testing))+\",\"+str(np.asarray(acc_training))+\",\"+str(samples)+\",\"+str(epsilon)+\",\"+str(n)+\",\"+str(hidden_size)+\"\\n\")\n",
    "#csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, intermediates, intermediates2, labels = ut.get_representations(net, train_loader, device)\n",
    "outputs_test, intermediates_test, intermediates2_test, labels_test = ut.get_representations(net, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_pca_data, intermediate_pca_data_test = ut.get_pca(intermediates, data_test=intermediates_test)\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,15))\n",
    "ut.plot_representations(intermediate_pca_data, labels, axs[0, 0])\n",
    "ut.plot_representations(intermediate_pca_data_test, labels_test, axs[1, 0])\n",
    "intermediate2_pca_data, intermediate2_pca_data_test = ut.get_pca(intermediates2, data_test=intermediates2_test)\n",
    "ut.plot_representations(intermediate2_pca_data, labels, axs[0, 1])\n",
    "ut.plot_representations(intermediate2_pca_data_test, labels_test, axs[1, 1])\n",
    "output_pca_data, output_pca_data_test = ut.get_pca(outputs, data_test=outputs_test)\n",
    "ut.plot_representations(output_pca_data, labels, axs[0, 2])\n",
    "ut.plot_representations(output_pca_data_test, labels_test, axs[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,15))\n",
    "print('first')\n",
    "reducer = umap.UMAP()\n",
    "print('first ..')\n",
    "mapper_train = reducer.fit_transform(intermediates.numpy())\n",
    "print('first ...')\n",
    "reducer = umap.UMAP()\n",
    "mapper_test = reducer.fit_transform(intermediates_test.numpy())\n",
    "ut.plot_representations(mapper_train, labels, axs[0, 0])\n",
    "ut.plot_representations(mapper_test, labels_test, axs[1, 0])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "mapper_train = reducer.fit_transform(intermediates2.numpy())\n",
    "reducer = umap.UMAP()\n",
    "mapper_test = reducer.fit_transform(intermediates2_test.numpy())\n",
    "ut.plot_representations(mapper_train, labels, axs[0, 1])\n",
    "ut.plot_representations(mapper_test, labels_test, axs[1, 1])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "mapper_train = reducer.fit_transform(outputs.numpy())\n",
    "reducer = umap.UMAP()\n",
    "mapper_test = reducer.fit_transform(outputs_test.numpy())\n",
    "\n",
    "ut.plot_representations(mapper_train, labels, axs[0, 2])\n",
    "ut.plot_representations(mapper_test, labels_test, axs[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CURVES = 25000\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,15))\n",
    "intermediate_tsne_data, intermediate_tsne_data_test = ut.get_tsne(intermediates, data_test= intermediates_test, n_curves = N_CURVES)\n",
    "ut.plot_representations(intermediate_tsne_data, labels, axs[0, 0],  n_curves = N_CURVES)\n",
    "ut.plot_representations(intermediate_tsne_data_test, labels_test, axs[1, 0], n_curves = N_CURVES)\n",
    "\n",
    "intermediate2_tsne_data, intermediate2_tsne_data_test = ut.get_tsne(intermediates2, data_test=intermediates2_test, n_curves = N_CURVES)\n",
    "ut.plot_representations(intermediate2_tsne_data, labels, axs[0, 1], n_curves = N_CURVES)\n",
    "ut.plot_representations(intermediate2_tsne_data_test, labels_test, axs[1, 1], n_curves = N_CURVES)\n",
    "\n",
    "output_tsne_data, output2_tsne_data_test = ut.get_tsne(outputs, data_test=outputs_test, n_curves = N_CURVES)\n",
    "ut.plot_representations(output_tsne_data, labels, axs[0, 2], n_curves = N_CURVES)\n",
    "ut.plot_representations(output2_tsne_data_test, labels_test, axs[1, 2], n_curves = N_CURVES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
    "#curves, labels, probs_train = ut.get_predictions(net, train_loader_pred, device)\n",
    "#pred_labels = probs_train.argmax(1, keepdim = True)\n",
    "#ut.plot_confusion_matrix(np.round(labels), pred_labels, ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves, labels, probs_train_sample = ut.get_predictions(net, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_WEIGHTS = 25\n",
    "#weights = net.fc2.weight.data\n",
    "#plot_weights(weights, N_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = net.fc1.weight.data\n",
    "w1 = weights1.cpu().numpy().reshape(-1,1)\n",
    "weights2 = net.fc2.weight.data\n",
    "w2 = weights2.cpu().numpy().reshape(-1,1)\n",
    "weights3 = net.fc3.weight.data\n",
    "w3 = weights3.cpu().numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,15))\n",
    "ax1.hist(w1, color='black')\n",
    "ax1.set_xlabel('Layer 1')\n",
    "ax2.hist(w2, color='black')\n",
    "ax2.set_xlabel('Layer 2')\n",
    "ax3.hist(w3, color='black')\n",
    "ax3.set_xlabel('Layer 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15,15))\n",
    "curves, labels, probs_train = ut.get_predictions(net, train_loader_pred, device)\n",
    "pred_labels = torch.argmax(probs_train, 1)\n",
    "ut.plot_confusion_matrix(np.round(labels), pred_labels, ax1)\n",
    "curves, labels, probs_test = ut.get_predictions(net, test_loader_pred, device)\n",
    "pred_labels = torch.argmax(probs_test, 1)\n",
    "ut.plot_confusion_matrix(np.round(labels), pred_labels, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
