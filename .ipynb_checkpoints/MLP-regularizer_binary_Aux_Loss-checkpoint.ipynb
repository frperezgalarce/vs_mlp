{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as f \n",
    "from torch.autograd import Variable\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "from sklearn import manifold\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels, ax):\n",
    "    #fig = plt.figure(figsize = (10, 10));\n",
    "    #ax = fig.add_subplot(1, 1, 1);\n",
    "    cm = metrics.confusion_matrix(labels, pred_labels, normalize='pred');\n",
    "    cm = metrics.ConfusionMatrixDisplay(cm);\n",
    "    cm.plot(cmap = 'Blues', ax = ax)\n",
    "    cm.im_.colorbar.remove()\n",
    "\n",
    "\n",
    "def get_predictions(model, iterator, device):\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _, _ = model(x)\n",
    "\n",
    "            y_prob = f.softmax(y_pred, dim = -1)\n",
    "            top_pred = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "\n",
    "    return images, labels, probs\n",
    "\n",
    "def regularization_method(params):\n",
    "    l1_regularization = 0\n",
    "    l2_regularization = 0\n",
    "    lambda1 = 0.001\n",
    "    lambda2 = 0.001\n",
    "    for param in params:\n",
    "        l1_regularization += torch.norm(param, 1)**2\n",
    "        l2_regularization += torch.norm(param, 2)**2\n",
    "    loss = loss + lambda1*l1_regularization + lambda2*l2_regularization\n",
    "    \n",
    "def plot_weights(weights, n_weights):\n",
    "\n",
    "    rows = int(np.sqrt(n_weights))\n",
    "    cols = int(np.sqrt(n_weights))\n",
    "\n",
    "    fig = plt.figure(figsize = (20, 10))\n",
    "    \n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(weights[i].view(5, 10).cpu().numpy(), cmap = 'bone')\n",
    "        #plt.title(str(train_target[i]))\n",
    "        ax.axis('off')\n",
    "        \n",
    "def get_pca(data, data_test=None, n_components = 2):\n",
    "    pca = decomposition.PCA()\n",
    "    \n",
    "    pca.n_components = n_components\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    \n",
    "    if data_test is not None: \n",
    "        pca_data_test = pca.transform(data_test)\n",
    "        return pca_data, pca_data_test \n",
    "    \n",
    "    return pca_data\n",
    "\n",
    "\n",
    "def get_tsne(data, data_test = None, n_components = 2, n_curves = None):\n",
    "    if n_curves is not None:\n",
    "        data = data[:n_curves]\n",
    "    tsne = manifold.TSNE(n_components = n_components, random_state = 0)\n",
    "    tsne_data = tsne.fit_transform(data)\n",
    "    \n",
    "    if data_test is not None: \n",
    "        tsne_data_test = tsne.fit_transform(data_test)\n",
    "        return tsne_data, tsne_data_test  \n",
    "    \n",
    "    return tsne_data\n",
    "\n",
    "def get_representations(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    intermediates = []\n",
    "    intermediates2 = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in iterator:\n",
    "            x = x.to(device)\n",
    "            y_pred, h2, h1 = net(x)\n",
    "            outputs.append(y_pred.cpu())\n",
    "            intermediates.append(h1.cpu())\n",
    "            intermediates2.append(h2.cpu())\n",
    "            labels.append(y)\n",
    "        \n",
    "    outputs = torch.cat(outputs, dim = 0)\n",
    "    intermediates = torch.cat(intermediates, dim = 0)\n",
    "    intermediates2 = torch.cat(intermediates2, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "\n",
    "    return outputs, intermediates, intermediates2, labels\n",
    "\n",
    "def plot_representations(data, labels, ax, n_curves = None):\n",
    "    if n_curves is not None:\n",
    "        data = data[:n_curves]\n",
    "        labels = labels[:n_curves]\n",
    "    #fig = plt.figure(figsize = (10, 10))\n",
    "    #ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, alpha =0.5)\n",
    "    handles, labels = scatter.legend_elements()\n",
    "    legend = ax.legend(handles = handles, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 1\n",
    "fileTrain = '/home/franciscoperez/Documents/GitHub/data/BIASEDFATS/Train_rrlyr-'+str(number)+'.csv'\n",
    "fileTest = '/home/franciscoperez/Documents/GitHub/data/BIASEDFATS/Test_rrlyr-'+str(number)+'.csv'\n",
    "train_dataset = pd.read_csv(fileTrain, index_col ='Unnamed: 0')\n",
    "test_dataset = pd.read_csv(fileTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq1_harmonics_rel_phase_0\n",
      "Freq2_harmonics_rel_phase_0\n",
      "Freq3_harmonics_rel_phase_0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_dataset =  train_dataset.drop(['Pred', 'Pred2', 'h', 'e', 'u','ID'], axis = 1)\n",
    "    for col in train_dataset.columns:\n",
    "        if col not in ['label']:\n",
    "            if train_dataset[col].var()==0:\n",
    "                print(col)\n",
    "                del train_dataset[col]\n",
    "    test_dataset = test_dataset[list(train_dataset.columns)]\n",
    "except:\n",
    "    print(col)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train_dataset.shape[0] \n",
    "epsilon = 0\n",
    "input_size = train_dataset.shape[1]-1\n",
    "hidden_size = 50\n",
    "hidden_size2 = 50\n",
    "num_classes = 2\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "learning_rate2 = 0.0001\n",
    "regularization = False\n",
    "add_DR_based_data = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391501, 61)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.sample(n)\n",
    "train_dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28625, 61)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset['PeriodLS'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306844, 61)\n"
     ]
    }
   ],
   "source": [
    "label = train_dataset['label']\n",
    "del train_dataset['label']\n",
    "\n",
    "\n",
    "train_dataset_z=(train_dataset-train_dataset.mean())/train_dataset.std()\n",
    "z_scores = stats.zscore(train_dataset_z)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "train_dataset['label'] = label\n",
    "train_dataset = train_dataset[filtered_entries]\n",
    "print(train_dataset.shape)\n",
    "train_dataset_pred = train_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28625, 60)\n",
      "(28625, 61)\n"
     ]
    }
   ],
   "source": [
    "label = test_dataset['label']\n",
    "del test_dataset['label']\n",
    "\n",
    "print(test_dataset.shape)\n",
    "\n",
    "test_dataset_z=(test_dataset-test_dataset.mean())/test_dataset.std()\n",
    "z_scores = stats.zscore(test_dataset_z)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "test_dataset['label'] = label\n",
    "\n",
    "print(test_dataset.shape)\n",
    "\n",
    "test_dataset = test_dataset[filtered_entries]\n",
    "\n",
    "test_dataset_pred = test_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset[['PeriodLS', 'Amplitude', 'AndersonDarling', 'Autocor_length', 'Beyond1Std',\n",
    "       'CAR_mean', 'CAR_sigma', 'CAR_tau', 'Con', 'Eta_e',\n",
    "       'FluxPercentileRatioMid20', 'FluxPercentileRatioMid35',\n",
    "       'FluxPercentileRatioMid50', 'FluxPercentileRatioMid65',\n",
    "       'FluxPercentileRatioMid80', 'Freq1_harmonics_amplitude_0',\n",
    "       'Freq1_harmonics_amplitude_1', 'Freq1_harmonics_amplitude_2',\n",
    "       'Freq1_harmonics_amplitude_3', 'Freq1_harmonics_rel_phase_1',\n",
    "       'Freq1_harmonics_rel_phase_2', 'Freq1_harmonics_rel_phase_3',\n",
    "       'Freq2_harmonics_amplitude_0', 'Freq2_harmonics_amplitude_1',\n",
    "       'Freq2_harmonics_amplitude_2', 'Freq2_harmonics_amplitude_3',\n",
    "       'Freq2_harmonics_rel_phase_1', 'Freq2_harmonics_rel_phase_2',\n",
    "       'Freq2_harmonics_rel_phase_3', 'Freq3_harmonics_amplitude_0',\n",
    "       'Freq3_harmonics_amplitude_1', 'Freq3_harmonics_amplitude_2',\n",
    "       'Freq3_harmonics_amplitude_3', 'Freq3_harmonics_rel_phase_1',\n",
    "       'Freq3_harmonics_rel_phase_2', 'Freq3_harmonics_rel_phase_3', 'Gskew',\n",
    "       'LinearTrend', 'MaxSlope', 'Mean', 'Meanvariance', 'MedianAbsDev',\n",
    "       'MedianBRP', 'PairSlopeTrend', 'PercentAmplitude',\n",
    "       'PercentDifferenceFluxPercentile', 'Period_fit', 'Psi_CS',\n",
    "       'Psi_eta', 'Q31', 'Rcs', 'Skew', 'SlottedA_length', 'SmallKurtosis',\n",
    "       'Std', 'StetsonK', 'StetsonK_AC', 'StructureFunction_index_21',\n",
    "       'StructureFunction_index_31', 'StructureFunction_index_32', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset[['PeriodLS', 'Amplitude', 'AndersonDarling', 'Autocor_length', 'Beyond1Std',\n",
    "       'CAR_mean', 'CAR_sigma', 'CAR_tau', 'Con', 'Eta_e',\n",
    "       'FluxPercentileRatioMid20', 'FluxPercentileRatioMid35',\n",
    "       'FluxPercentileRatioMid50', 'FluxPercentileRatioMid65',\n",
    "       'FluxPercentileRatioMid80', 'Freq1_harmonics_amplitude_0',\n",
    "       'Freq1_harmonics_amplitude_1', 'Freq1_harmonics_amplitude_2',\n",
    "       'Freq1_harmonics_amplitude_3', 'Freq1_harmonics_rel_phase_1',\n",
    "       'Freq1_harmonics_rel_phase_2', 'Freq1_harmonics_rel_phase_3',\n",
    "       'Freq2_harmonics_amplitude_0', 'Freq2_harmonics_amplitude_1',\n",
    "       'Freq2_harmonics_amplitude_2', 'Freq2_harmonics_amplitude_3',\n",
    "       'Freq2_harmonics_rel_phase_1', 'Freq2_harmonics_rel_phase_2',\n",
    "       'Freq2_harmonics_rel_phase_3', 'Freq3_harmonics_amplitude_0',\n",
    "       'Freq3_harmonics_amplitude_1', 'Freq3_harmonics_amplitude_2',\n",
    "       'Freq3_harmonics_amplitude_3', 'Freq3_harmonics_rel_phase_1',\n",
    "       'Freq3_harmonics_rel_phase_2', 'Freq3_harmonics_rel_phase_3', 'Gskew',\n",
    "       'LinearTrend', 'MaxSlope', 'Mean', 'Meanvariance', 'MedianAbsDev',\n",
    "       'MedianBRP', 'PairSlopeTrend', 'PercentAmplitude',\n",
    "       'PercentDifferenceFluxPercentile', 'Period_fit', 'Psi_CS',\n",
    "       'Psi_eta', 'Q31', 'Rcs', 'Skew', 'SlottedA_length', 'SmallKurtosis',\n",
    "       'Std', 'StetsonK', 'StetsonK_AC', 'StructureFunction_index_21',\n",
    "       'StructureFunction_index_31', 'StructureFunction_index_32', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeriodLS</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AndersonDarling</th>\n",
       "      <th>Autocor_length</th>\n",
       "      <th>Beyond1Std</th>\n",
       "      <th>CAR_mean</th>\n",
       "      <th>CAR_sigma</th>\n",
       "      <th>CAR_tau</th>\n",
       "      <th>Con</th>\n",
       "      <th>Eta_e</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SlottedA_length</th>\n",
       "      <th>SmallKurtosis</th>\n",
       "      <th>Std</th>\n",
       "      <th>StetsonK</th>\n",
       "      <th>StetsonK_AC</th>\n",
       "      <th>StructureFunction_index_21</th>\n",
       "      <th>StructureFunction_index_31</th>\n",
       "      <th>StructureFunction_index_32</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391262</th>\n",
       "      <td>74.277705</td>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>10</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>22.791959</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>0.619429</td>\n",
       "      <td>0.02349</td>\n",
       "      <td>14.104876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194838</td>\n",
       "      <td>17.79498</td>\n",
       "      <td>-0.488208</td>\n",
       "      <td>0.078843</td>\n",
       "      <td>0.814231</td>\n",
       "      <td>0.784707</td>\n",
       "      <td>1.801910</td>\n",
       "      <td>2.535099</td>\n",
       "      <td>1.448028</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230291</th>\n",
       "      <td>1020.470095</td>\n",
       "      <td>0.01750</td>\n",
       "      <td>0.115532</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>274.744191</td>\n",
       "      <td>0.211135</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.686240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133719</td>\n",
       "      <td>5.69361</td>\n",
       "      <td>0.111186</td>\n",
       "      <td>0.009347</td>\n",
       "      <td>0.793480</td>\n",
       "      <td>0.745731</td>\n",
       "      <td>1.620815</td>\n",
       "      <td>2.129265</td>\n",
       "      <td>1.607298</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26148</th>\n",
       "      <td>0.486126</td>\n",
       "      <td>0.02575</td>\n",
       "      <td>0.536316</td>\n",
       "      <td>2</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>39.534998</td>\n",
       "      <td>0.553698</td>\n",
       "      <td>0.389701</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6307.485427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058798</td>\n",
       "      <td>4.92600</td>\n",
       "      <td>-0.091798</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.791180</td>\n",
       "      <td>0.738202</td>\n",
       "      <td>1.453116</td>\n",
       "      <td>1.593353</td>\n",
       "      <td>1.206530</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34003</th>\n",
       "      <td>921.153420</td>\n",
       "      <td>0.01825</td>\n",
       "      <td>0.253883</td>\n",
       "      <td>5</td>\n",
       "      <td>0.283186</td>\n",
       "      <td>206.752429</td>\n",
       "      <td>0.049652</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.364235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502323</td>\n",
       "      <td>1.18029</td>\n",
       "      <td>1.457469</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.777735</td>\n",
       "      <td>0.741196</td>\n",
       "      <td>1.317766</td>\n",
       "      <td>1.621916</td>\n",
       "      <td>1.385394</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189282</th>\n",
       "      <td>1.139047</td>\n",
       "      <td>0.45500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>18.179650</td>\n",
       "      <td>0.189635</td>\n",
       "      <td>1.087083</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.117858</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129390</td>\n",
       "      <td>1.89933</td>\n",
       "      <td>2.278362</td>\n",
       "      <td>0.219409</td>\n",
       "      <td>0.742077</td>\n",
       "      <td>0.726959</td>\n",
       "      <td>2.211178</td>\n",
       "      <td>3.532070</td>\n",
       "      <td>1.632040</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PeriodLS  Amplitude  AndersonDarling  Autocor_length  Beyond1Std  \\\n",
       "391262    74.277705    0.15100         0.001250              10    0.346667   \n",
       "230291  1020.470095    0.01750         0.115532               2    0.363333   \n",
       "26148      0.486126    0.02575         0.536316               2    0.299065   \n",
       "34003    921.153420    0.01825         0.253883               5    0.283186   \n",
       "189282     1.139047    0.45500         0.000000               1    0.220000   \n",
       "\n",
       "          CAR_mean  CAR_sigma   CAR_tau      Con        Eta_e  ...      Skew  \\\n",
       "391262   22.791959   0.537868  0.619429  0.02349    14.104876  ...  0.194838   \n",
       "230291  274.744191   0.211135  0.053812  0.00000     5.686240  ...  0.133719   \n",
       "26148    39.534998   0.553698  0.389701  0.00000  6307.485427  ... -0.058798   \n",
       "34003   206.752429   0.049652  0.068576  0.00000     8.364235  ... -0.502323   \n",
       "189282   18.179650   0.189635  1.087083  0.00000    17.117858  ...  1.129390   \n",
       "\n",
       "        SlottedA_length  SmallKurtosis       Std  StetsonK  StetsonK_AC  \\\n",
       "391262         17.79498      -0.488208  0.078843  0.814231     0.784707   \n",
       "230291          5.69361       0.111186  0.009347  0.793480     0.745731   \n",
       "26148           4.92600      -0.091798  0.012686  0.791180     0.738202   \n",
       "34003           1.18029       1.457469  0.010113  0.777735     0.741196   \n",
       "189282          1.89933       2.278362  0.219409  0.742077     0.726959   \n",
       "\n",
       "        StructureFunction_index_21  StructureFunction_index_31  \\\n",
       "391262                    1.801910                    2.535099   \n",
       "230291                    1.620815                    2.129265   \n",
       "26148                     1.453116                    1.593353   \n",
       "34003                     1.317766                    1.621916   \n",
       "189282                    2.211178                    3.532070   \n",
       "\n",
       "        StructureFunction_index_32   label  \n",
       "391262                    1.448028  ClassB  \n",
       "230291                    1.607298  ClassB  \n",
       "26148                     1.206530  ClassB  \n",
       "34003                     1.385394  ClassB  \n",
       "189282                    1.632040  ClassB  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 3000\n",
    "samples1 = samples*2\n",
    "number_columns = train_dataset.shape[1]\n",
    "option = 2\n",
    "\n",
    "\n",
    "data_prior = pd.DataFrame(0, index=np.arange(1), columns=train_dataset.columns)\n",
    "\n",
    "if add_DR_based_data:\n",
    "    #option 1\n",
    "    if option == 1:\n",
    "        for i in range(samples1):\n",
    "            new_data = pd.DataFrame(0, index=np.arange(1), columns=train_dataset.columns) \n",
    "            new_data.columns = train_dataset.columns\n",
    "            new_data['PeriodLS']= (np.random.uniform(0.2-epsilon,1.0+epsilon))#-minimum_period)/(maximum_period-minimum_period)\n",
    "            new_data['label'] = 'Noise'\n",
    "            frames = [data_prior, new_data]\n",
    "            data_prior = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "    if option==2:\n",
    "        #option 2\n",
    "        for i in range(samples):\n",
    "            new_data = pd.DataFrame(0, index=np.arange(1), columns=train_dataset.columns) \n",
    "            new_data.columns = train_dataset.columns\n",
    "            new_data['PeriodLS']=(np.random.uniform(0.1,0.2))#-minimum_period)/(maximum_period-minimum_period)\n",
    "            new_data['label'] = 'Noise'\n",
    "            frames = [data_prior, new_data]\n",
    "            data_prior = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "        for i in range(samples):    \n",
    "            new_data = pd.DataFrame(0, index=np.arange(1), columns=train_dataset.columns) \n",
    "            new_data.columns = train_dataset.columns\n",
    "            new_data['PeriodLS']=(np.random.uniform(1.0,1.1))\n",
    "            new_data['label'] = 'Noise'\n",
    "            frames = [data_prior, new_data]\n",
    "            data_prior = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "        \n",
    "    #option 3\n",
    "    if option==3:\n",
    "        for i in range(samples):    \n",
    "            new_data = pd.DataFrame(0, index=np.arange(1), columns=train_dataset.columns) #pd.DataFrame([train_dataset.sample(1000).mean()]).T\n",
    "            new_data['PeriodLS']= 1.0\n",
    "            new_data['label'] = 'Noise'\n",
    "            frames = [data_prior, new_data]\n",
    "            data_prior = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "        for i in range(samples):    \n",
    "            new_data = pd.DataFrame(0, index=np.arange(1), columns=train_dataset.columns) \n",
    "            new_data.columns = train_dataset.columns\n",
    "            new_data['PeriodLS']= 0.2\n",
    "            new_data['label'] = 'Noise'\n",
    "            frames = [data_prior, new_data]\n",
    "            data_prior = pd.concat(frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeriodLS</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AndersonDarling</th>\n",
       "      <th>Autocor_length</th>\n",
       "      <th>Beyond1Std</th>\n",
       "      <th>CAR_mean</th>\n",
       "      <th>CAR_sigma</th>\n",
       "      <th>CAR_tau</th>\n",
       "      <th>Con</th>\n",
       "      <th>Eta_e</th>\n",
       "      <th>...</th>\n",
       "      <th>Rcs</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SlottedA_length</th>\n",
       "      <th>SmallKurtosis</th>\n",
       "      <th>Std</th>\n",
       "      <th>StetsonK</th>\n",
       "      <th>StetsonK_AC</th>\n",
       "      <th>StructureFunction_index_21</th>\n",
       "      <th>StructureFunction_index_31</th>\n",
       "      <th>StructureFunction_index_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6001.000000</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "      <td>6001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.600119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.450411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.151092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.199955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.049650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.099956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PeriodLS  Amplitude  AndersonDarling  Autocor_length  Beyond1Std  \\\n",
       "count  6001.000000     6001.0           6001.0          6001.0      6001.0   \n",
       "mean      0.600119        0.0              0.0             0.0         0.0   \n",
       "std       0.450411        0.0              0.0             0.0         0.0   \n",
       "min       0.000000        0.0              0.0             0.0         0.0   \n",
       "25%       0.151092        0.0              0.0             0.0         0.0   \n",
       "50%       0.199955        0.0              0.0             0.0         0.0   \n",
       "75%       1.049650        0.0              0.0             0.0         0.0   \n",
       "max       1.099956        0.0              0.0             0.0         0.0   \n",
       "\n",
       "       CAR_mean  CAR_sigma  CAR_tau     Con   Eta_e  ...     Rcs    Skew  \\\n",
       "count    6001.0     6001.0   6001.0  6001.0  6001.0  ...  6001.0  6001.0   \n",
       "mean        0.0        0.0      0.0     0.0     0.0  ...     0.0     0.0   \n",
       "std         0.0        0.0      0.0     0.0     0.0  ...     0.0     0.0   \n",
       "min         0.0        0.0      0.0     0.0     0.0  ...     0.0     0.0   \n",
       "25%         0.0        0.0      0.0     0.0     0.0  ...     0.0     0.0   \n",
       "50%         0.0        0.0      0.0     0.0     0.0  ...     0.0     0.0   \n",
       "75%         0.0        0.0      0.0     0.0     0.0  ...     0.0     0.0   \n",
       "max         0.0        0.0      0.0     0.0     0.0  ...     0.0     0.0   \n",
       "\n",
       "       SlottedA_length  SmallKurtosis     Std  StetsonK  StetsonK_AC  \\\n",
       "count           6001.0         6001.0  6001.0    6001.0       6001.0   \n",
       "mean               0.0            0.0     0.0       0.0          0.0   \n",
       "std                0.0            0.0     0.0       0.0          0.0   \n",
       "min                0.0            0.0     0.0       0.0          0.0   \n",
       "25%                0.0            0.0     0.0       0.0          0.0   \n",
       "50%                0.0            0.0     0.0       0.0          0.0   \n",
       "75%                0.0            0.0     0.0       0.0          0.0   \n",
       "max                0.0            0.0     0.0       0.0          0.0   \n",
       "\n",
       "       StructureFunction_index_21  StructureFunction_index_31  \\\n",
       "count                      6001.0                      6001.0   \n",
       "mean                          0.0                         0.0   \n",
       "std                           0.0                         0.0   \n",
       "min                           0.0                         0.0   \n",
       "25%                           0.0                         0.0   \n",
       "50%                           0.0                         0.0   \n",
       "75%                           0.0                         0.0   \n",
       "max                           0.0                         0.0   \n",
       "\n",
       "       StructureFunction_index_32  \n",
       "count                      6001.0  \n",
       "mean                          0.0  \n",
       "std                           0.0  \n",
       "min                           0.0  \n",
       "25%                           0.0  \n",
       "50%                           0.0  \n",
       "75%                           0.0  \n",
       "max                           0.0  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prior.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_prior, val_dataset_prior = train_test_split(data_prior, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_dataset_prior['label'] = train_dataset_prior['label'].str.replace('ClassA', '1')\n",
    "train_dataset_prior['label'] = train_dataset_prior['label'].str.replace('ClassB', '0')\n",
    "train_dataset_prior['label'] = train_dataset_prior['label'].str.replace('Noise', '0.5')\n",
    "\n",
    "train_target_prior = torch.tensor(train_dataset_prior['label'].values.astype(np.float32))\n",
    "train_prior = torch.tensor(train_dataset_prior.drop('label', axis = 1).values.astype(np.float32)) \n",
    "train_prior = f.normalize(train_prior)\n",
    "train_tensor_prior = data_utils.TensorDataset(train_prior, train_target_prior) \n",
    "train_loader_prior = data_utils.DataLoader(dataset = train_tensor_prior, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeriodLS</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AndersonDarling</th>\n",
       "      <th>Autocor_length</th>\n",
       "      <th>Beyond1Std</th>\n",
       "      <th>CAR_mean</th>\n",
       "      <th>CAR_sigma</th>\n",
       "      <th>CAR_tau</th>\n",
       "      <th>Con</th>\n",
       "      <th>Eta_e</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SlottedA_length</th>\n",
       "      <th>SmallKurtosis</th>\n",
       "      <th>Std</th>\n",
       "      <th>StetsonK</th>\n",
       "      <th>StetsonK_AC</th>\n",
       "      <th>StructureFunction_index_21</th>\n",
       "      <th>StructureFunction_index_31</th>\n",
       "      <th>StructureFunction_index_32</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>0.173770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>1.029643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.107586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>0.113838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>1.048279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PeriodLS  Amplitude  AndersonDarling  Autocor_length  Beyond1Std  \\\n",
       "2602  0.173770          0                0               0           0   \n",
       "5868  1.029643          0                0               0           0   \n",
       "2157  0.107586          0                0               0           0   \n",
       "1161  0.113838          0                0               0           0   \n",
       "3574  1.048279          0                0               0           0   \n",
       "\n",
       "      CAR_mean  CAR_sigma  CAR_tau  Con  Eta_e  ...  Skew  SlottedA_length  \\\n",
       "2602         0          0        0    0      0  ...     0                0   \n",
       "5868         0          0        0    0      0  ...     0                0   \n",
       "2157         0          0        0    0      0  ...     0                0   \n",
       "1161         0          0        0    0      0  ...     0                0   \n",
       "3574         0          0        0    0      0  ...     0                0   \n",
       "\n",
       "      SmallKurtosis  Std  StetsonK  StetsonK_AC  StructureFunction_index_21  \\\n",
       "2602              0    0         0            0                           0   \n",
       "5868              0    0         0            0                           0   \n",
       "2157              0    0         0            0                           0   \n",
       "1161              0    0         0            0                           0   \n",
       "3574              0    0         0            0                           0   \n",
       "\n",
       "      StructureFunction_index_31  StructureFunction_index_32  label  \n",
       "2602                           0                           0    0.5  \n",
       "5868                           0                           0    0.5  \n",
       "2157                           0                           0    0.5  \n",
       "1161                           0                           0    0.5  \n",
       "3574                           0                           0    0.5  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_prior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "val_dataset_prior['label'] = val_dataset_prior['label'].str.replace('ClassA', '1')\n",
    "val_dataset_prior['label'] = val_dataset_prior['label'].str.replace('ClassB', '0')\n",
    "val_dataset_prior['label'] = val_dataset_prior['label'].str.replace('Noise', '0.5')\n",
    "val_target_prior = torch.tensor(val_dataset_prior['label'].values.astype(np.float32))\n",
    "val_prior = torch.tensor(val_dataset_prior.drop('label', axis = 1).values.astype(np.float32)) \n",
    "val_prior = f.normalize(val_prior)\n",
    "val_tensor_prior = data_utils.TensorDataset(val_prior, val_target_prior) \n",
    "val_loader_prior = data_utils.DataLoader(dataset = val_tensor_prior, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases using DR 1: Period $ \\in [0.2,1.0]$ days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['label'] = train_dataset['label'].str.replace('ClassA', '1')\n",
    "train_dataset['label'] = train_dataset['label'].str.replace('ClassB', '0')\n",
    "train_dataset['label'] = train_dataset['label'].str.replace('Noise', '0.5')\n",
    "train_target = torch.tensor(train_dataset['label'].values.astype(np.float32))\n",
    "train = torch.tensor(train_dataset.drop('label', axis = 1).values.astype(np.float32)) \n",
    "train = f.normalize(train)\n",
    "train_tensor = data_utils.TensorDataset(train, train_target) \n",
    "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_pred['label'] = train_dataset_pred['label'].str.replace('ClassA', '1')\n",
    "train_dataset_pred['label'] = train_dataset_pred['label'].str.replace('ClassB', '0')\n",
    "train_dataset_pred['label'] = train_dataset_pred['label'].str.replace('Noise', '0.5')\n",
    "train_target_pred = torch.tensor(train_dataset_pred['label'].values.astype(np.float32))\n",
    "train_pred = torch.tensor(train_dataset_pred.drop('label', axis = 1).values.astype(np.float32)) \n",
    "train_pred = f.normalize(train_pred)\n",
    "train_tensor_pred = data_utils.TensorDataset(train_pred, train_target_pred) \n",
    "train_loader_pred = data_utils.DataLoader(dataset = train_tensor_pred, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset['label'] = val_dataset['label'].str.replace('ClassA', '1')\n",
    "val_dataset['label'] = val_dataset['label'].str.replace('ClassB', '0')\n",
    "val_dataset['label'] = val_dataset['label'].str.replace('Noise', '0.5')\n",
    "val_target = torch.tensor(val_dataset['label'].values.astype(np.float32))\n",
    "val = torch.tensor(val_dataset.drop('label', axis = 1).values.astype(np.float32)) \n",
    "val = f.normalize(val)\n",
    "val_tensor = data_utils.TensorDataset(val, val_target) \n",
    "val_loader = data_utils.DataLoader(dataset = val_tensor, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['label'] = test_dataset['label'].str.replace('ClassA', '1')\n",
    "test_dataset['label'] = test_dataset['label'].str.replace('ClassB', '0')\n",
    "test_dataset['label'] = test_dataset['label'].str.replace('Noise', '0.5')\n",
    "test_target = torch.tensor(test_dataset['label'].values.astype(np.float32))\n",
    "test = torch.tensor(test_dataset.drop('label', axis = 1).values.astype(np.float32)) \n",
    "test = f.normalize(test)\n",
    "test_tensor = data_utils.TensorDataset(test, test_target) \n",
    "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_pred['label'] = test_dataset_pred['label'].str.replace('ClassA', '1')\n",
    "test_dataset_pred['label'] = test_dataset_pred['label'].str.replace('ClassB', '0')\n",
    "test_dataset_pred['label'] = test_dataset_pred['label'].str.replace('Noise', '0.5')\n",
    "test_target_pred = torch.tensor(test_dataset_pred['label'].values.astype(np.float32))\n",
    "test_pred = torch.tensor(test_dataset_pred.drop('label', axis = 1).values.astype(np.float32)) \n",
    "test_pred = f.normalize(test_pred)\n",
    "test_tensor_pred = data_utils.TensorDataset(test_pred, test_target_pred) \n",
    "test_loader_pred = data_utils.DataLoader(dataset = test_tensor_pred, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeriodLS</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AndersonDarling</th>\n",
       "      <th>Autocor_length</th>\n",
       "      <th>Beyond1Std</th>\n",
       "      <th>CAR_mean</th>\n",
       "      <th>CAR_sigma</th>\n",
       "      <th>CAR_tau</th>\n",
       "      <th>Con</th>\n",
       "      <th>Eta_e</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SlottedA_length</th>\n",
       "      <th>SmallKurtosis</th>\n",
       "      <th>Std</th>\n",
       "      <th>StetsonK</th>\n",
       "      <th>StetsonK_AC</th>\n",
       "      <th>StructureFunction_index_21</th>\n",
       "      <th>StructureFunction_index_31</th>\n",
       "      <th>StructureFunction_index_32</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41984</th>\n",
       "      <td>19.635540</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.262449</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.591698</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>8.051328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.655133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344293</td>\n",
       "      <td>3.70788</td>\n",
       "      <td>0.257107</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>0.808203</td>\n",
       "      <td>0.804532</td>\n",
       "      <td>1.637592</td>\n",
       "      <td>2.089499</td>\n",
       "      <td>1.347071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204853</th>\n",
       "      <td>0.480786</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>10.121280</td>\n",
       "      <td>0.042812</td>\n",
       "      <td>1.897066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.808423</td>\n",
       "      <td>...</td>\n",
       "      <td>1.378089</td>\n",
       "      <td>1.93506</td>\n",
       "      <td>5.070333</td>\n",
       "      <td>0.088089</td>\n",
       "      <td>0.748541</td>\n",
       "      <td>0.642978</td>\n",
       "      <td>2.069311</td>\n",
       "      <td>3.198984</td>\n",
       "      <td>1.564137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149015</th>\n",
       "      <td>12.649630</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.566068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313253</td>\n",
       "      <td>35.826358</td>\n",
       "      <td>0.745027</td>\n",
       "      <td>0.446029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.561501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047725</td>\n",
       "      <td>0.36124</td>\n",
       "      <td>-0.151407</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.787943</td>\n",
       "      <td>0.842451</td>\n",
       "      <td>1.614425</td>\n",
       "      <td>2.069396</td>\n",
       "      <td>1.372271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213778</th>\n",
       "      <td>1.003562</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>8</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>125.689127</td>\n",
       "      <td>0.705520</td>\n",
       "      <td>0.115639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551877</td>\n",
       "      <td>17.94500</td>\n",
       "      <td>-0.864035</td>\n",
       "      <td>0.059901</td>\n",
       "      <td>0.865837</td>\n",
       "      <td>0.861008</td>\n",
       "      <td>1.870271</td>\n",
       "      <td>2.694707</td>\n",
       "      <td>1.464120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257577</th>\n",
       "      <td>18.112277</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.199596</td>\n",
       "      <td>7</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>22.332807</td>\n",
       "      <td>0.607894</td>\n",
       "      <td>0.682910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.673598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>2.67912</td>\n",
       "      <td>-0.043808</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>0.793477</td>\n",
       "      <td>0.725107</td>\n",
       "      <td>1.946563</td>\n",
       "      <td>2.892690</td>\n",
       "      <td>1.556220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PeriodLS  Amplitude  AndersonDarling  Autocor_length  Beyond1Std  \\\n",
       "41984   19.635540     0.0345         0.262449               2    0.333333   \n",
       "204853   0.480786     0.1800         0.000000               1    0.217391   \n",
       "149015  12.649630     0.0245         0.566068               1    0.313253   \n",
       "213778   1.003562     0.0980         0.000034               8    0.342466   \n",
       "257577  18.112277     0.0210         0.199596               7    0.326667   \n",
       "\n",
       "          CAR_mean  CAR_sigma   CAR_tau  Con       Eta_e  ...      Skew  \\\n",
       "41984     1.591698   0.009575  8.051328  0.0   20.655133  ...  0.344293   \n",
       "204853   10.121280   0.042812  1.897066  0.0  158.808423  ...  1.378089   \n",
       "149015   35.826358   0.745027  0.446029  0.0   98.561501  ... -0.047725   \n",
       "213778  125.689127   0.705520  0.115639  0.0    0.186021  ...  0.551877   \n",
       "257577   22.332807   0.607894  0.682910  0.0   87.673598  ...  0.004483   \n",
       "\n",
       "        SlottedA_length  SmallKurtosis       Std  StetsonK  StetsonK_AC  \\\n",
       "41984           3.70788       0.257107  0.018518  0.808203     0.804532   \n",
       "204853          1.93506       5.070333  0.088089  0.748541     0.642978   \n",
       "149015          0.36124      -0.151407  0.012064  0.787943     0.842451   \n",
       "213778         17.94500      -0.864035  0.059901  0.865837     0.861008   \n",
       "257577          2.67912      -0.043808  0.011120  0.793477     0.725107   \n",
       "\n",
       "        StructureFunction_index_21  StructureFunction_index_31  \\\n",
       "41984                     1.637592                    2.089499   \n",
       "204853                    2.069311                    3.198984   \n",
       "149015                    1.614425                    2.069396   \n",
       "213778                    1.870271                    2.694707   \n",
       "257577                    1.946563                    2.892690   \n",
       "\n",
       "        StructureFunction_index_32  label  \n",
       "41984                     1.347071      0  \n",
       "204853                    1.564137      0  \n",
       "149015                    1.372271      0  \n",
       "213778                    1.464120      0  \n",
       "257577                    1.556220      0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=60, out_features=50, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,hidden_size2, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        #self.relu = nn.ReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size2)  \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes) \n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #self.dropout = nn.Dropout(p=0.1)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(hidden_size)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.fc1(x)\n",
    "        #out = self.batchnorm1(out)\n",
    "        #out = self.relu(out)\n",
    "        out = self.relu(out1)\n",
    "        out2 = self.fc2(out)\n",
    "        #out = self.batchnorm1(out)\n",
    "        out = self.relu2(out)\n",
    "        out3 = self.fc3(out)\n",
    "        #x = self.dropout(x)\n",
    "        #out = self.sigmoid(out)\n",
    "        return out3, out2, out1\n",
    "  \n",
    "#net_prior = Net(input_size, hidden_size, hidden_size2, num_classes)\n",
    "\n",
    "#net_prior.cuda()\n",
    "\n",
    "net = Net(input_size, hidden_size, hidden_size2, num_classes)\n",
    "\n",
    "#use_cuda = torch.cuda.is_available()\n",
    "\n",
    "net.cuda()\n",
    "net = nn.DataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "#criterion = nn.BCELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "prior_parameters = [\n",
    "    {'params': net.fc1.parameters()},\n",
    "    {'params': net.fc2.parameters()}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "optimizer_prior = torch.optim.Adam(prior_parameters, lr=learning_rate2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x): \n",
    "    return x.exp() / (x.exp().sum(-1)).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(output, labels, weigths=None, weigths_prior=None):\n",
    "    regularization_loss = 0\n",
    "    lambda_1 = 0.00001\n",
    "    if weigths is not None: \n",
    "        regularization_loss += fast_cdist(weigths, weigths_prior)\n",
    "            #print(regularization_loss)\n",
    "        loss = criterion(outputs, labels) + lambda_1*regularization_loss #nn.L1Loss()(weigths, weigths)\n",
    "    else:\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_auxiliar(output):\n",
    "    #print(softmax(output)[:,1])\n",
    "    expected_loss = softmax(output)[:,1].mean()\n",
    "    #print(expected_loss)\n",
    "    threshold = torch.tensor(0.5)\n",
    "    aux_loss = torch.tensor(expected_loss-threshold, requires_grad=True)\n",
    "    #print(aux_loss**2)\n",
    "    return aux_loss**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_cdist(x1, x2):\n",
    "    res=f.mse_loss(x1, x2, size_average=False)\n",
    "    #res=f.l1_loss(x1, x2, size_average=False)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Training----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006784588850490741\n",
      "-----------Validation----------------------------\n",
      "1 0.14292304268120415\n",
      "-----------Training----------------------------\n",
      "3.3133759283107787e-07\n",
      "-----------Validation----------------------------\n",
      "2 0.07714475627708889\n",
      "-----------Training----------------------------\n",
      "1.4580345927356707e-07\n",
      "-----------Validation----------------------------\n",
      "3 0.05530998317623847\n",
      "-----------Training----------------------------\n",
      "2.1440405420190627e-07\n",
      "-----------Validation----------------------------\n",
      "4 0.04327979013304361\n",
      "-----------Training----------------------------\n",
      "3.1824425501729493e-07\n",
      "-----------Validation----------------------------\n",
      "5 0.036237130488334095\n",
      "-----------Training----------------------------\n",
      "4.1353225984274994e-07\n",
      "-----------Validation----------------------------\n",
      "6 0.03211282545018929\n",
      "-----------Training----------------------------\n",
      "4.6113050550325995e-07\n",
      "-----------Validation----------------------------\n",
      "7 0.029564933074449847\n",
      "-----------Training----------------------------\n",
      "5.078386528328976e-07\n",
      "-----------Validation----------------------------\n",
      "8 0.027746651961630342\n",
      "-----------Training----------------------------\n",
      "5.032301708831433e-07\n",
      "-----------Validation----------------------------\n",
      "9 0.026472100608314973\n",
      "-----------Training----------------------------\n",
      "4.789160687567046e-07\n",
      "-----------Validation----------------------------\n",
      "10 0.02551430710460272\n",
      "-----------Training----------------------------\n",
      "4.48016447650737e-07\n",
      "-----------Validation----------------------------\n",
      "11 0.024719693861140386\n",
      "-----------Training----------------------------\n",
      "4.482624981107745e-07\n",
      "-----------Validation----------------------------\n",
      "12 0.0240833163222568\n",
      "-----------Training----------------------------\n",
      "4.1425400785885983e-07\n",
      "-----------Validation----------------------------\n",
      "13 0.023507072885517843\n",
      "-----------Training----------------------------\n",
      "4.499201012099742e-07\n",
      "-----------Validation----------------------------\n",
      "14 0.023091990088925495\n",
      "-----------Training----------------------------\n",
      "3.7589430947154586e-07\n",
      "-----------Validation----------------------------\n",
      "15 0.02265395245750797\n",
      "-----------Training----------------------------\n",
      "4.0846103036113575e-07\n",
      "-----------Validation----------------------------\n",
      "16 0.022074645160812967\n",
      "-----------Training----------------------------\n",
      "3.564813598420639e-07\n",
      "-----------Validation----------------------------\n",
      "17 0.02174728787848891\n",
      "-----------Training----------------------------\n",
      "3.5395265178083684e-07\n",
      "-----------Validation----------------------------\n",
      "18 0.02148579309448771\n",
      "-----------Training----------------------------\n",
      "3.0174333416573e-07\n",
      "-----------Validation----------------------------\n",
      "19 0.02121209960461937\n",
      "-----------Training----------------------------\n",
      "2.726860698377271e-07\n",
      "-----------Validation----------------------------\n",
      "20 0.02105241098632498\n",
      "-----------Training----------------------------\n",
      "2.1931988339297051e-07\n",
      "-----------Validation----------------------------\n",
      "21 0.020697981078368035\n",
      "-----------Training----------------------------\n",
      "1.7377119489782516e-07\n",
      "-----------Validation----------------------------\n",
      "22 0.020476202710654985\n",
      "-----------Training----------------------------\n",
      "1.4269804346741006e-07\n",
      "-----------Validation----------------------------\n",
      "23 0.020217940461850017\n",
      "-----------Training----------------------------\n",
      "1.246293063511854e-07\n",
      "-----------Validation----------------------------\n",
      "24 0.020030348779239357\n",
      "-----------Training----------------------------\n",
      "1.0015376058956425e-07\n",
      "-----------Validation----------------------------\n",
      "25 0.019786841523512125\n",
      "-----------Training----------------------------\n",
      "9.297081382636537e-08\n",
      "-----------Validation----------------------------\n",
      "26 0.019589535050031973\n",
      "-----------Training----------------------------\n",
      "1.0007088043460427e-07\n",
      "-----------Validation----------------------------\n",
      "27 0.019275987278029122\n",
      "-----------Training----------------------------\n",
      "7.392478154957087e-08\n",
      "-----------Validation----------------------------\n",
      "28 0.01919624517449373\n",
      "-----------Training----------------------------\n",
      "6.893384221807416e-08\n",
      "-----------Validation----------------------------\n",
      "29 0.01894221746880363\n",
      "-----------Training----------------------------\n",
      "6.842620126894423e-08\n",
      "-----------Validation----------------------------\n",
      "30 0.018795342960543502\n",
      "-----------Training----------------------------\n",
      "6.412506656049991e-08\n",
      "-----------Validation----------------------------\n",
      "31 0.018431726523613842\n",
      "-----------Training----------------------------\n",
      "5.78641615212309e-08\n",
      "-----------Validation----------------------------\n",
      "32 0.018206364766532424\n",
      "-----------Training----------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "# Train the Model   \n",
    "hist_train = []\n",
    "hist_val = []\n",
    "num_epochs_prior = 50\n",
    "for epoch in range(num_epochs_prior):\n",
    "    print('-----------Training----------------------------')\n",
    "    epoch_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    epoch_loss_prior = 0.0    \n",
    "    running_loss_prior = 0.0\n",
    "    \n",
    "    for item1, item2 in zip(train_loader, cycle(train_loader_prior)):\n",
    "        star_prior, labels_prior = item1\n",
    "        star, labels = item2\n",
    "        \n",
    "        star = Variable(star.view(-1, input_size)).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        optimizer.zero_grad()  \n",
    "        outputs, _, _ = net(star)\n",
    "        loss = criterion(outputs, labels.long())      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        star_prior = Variable(star_prior.view(-1, input_size)).cuda()\n",
    "        labels_prior = Variable(labels_prior).cuda()\n",
    "        optimizer_prior.zero_grad()  # zero the gradient buffer\n",
    "        outputs_prior, _, _ = net(star_prior)\n",
    "        loss_prior = custom_loss_auxiliar(outputs_prior)                \n",
    "        loss_prior.backward()\n",
    "        optimizer_prior.step()\n",
    "        epoch_loss_prior += outputs_prior.shape[0] * loss_prior.item()      \n",
    "        running_loss_prior += loss_prior.item()\n",
    "        \n",
    "    hist_train.append(running_loss/len(train_loader))    \n",
    "    print(running_loss/len(train_loader))\n",
    "    \n",
    "    print('-----------Validation----------------------------')\n",
    "    epoch_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    for i, (star, labels) in enumerate(val_loader):  \n",
    "        \n",
    "        star = Variable(star.view(-1, input_size)).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        optimizer.zero_grad()  \n",
    "        outputs, _, _ = net(star)\n",
    "        loss = criterion(outputs, labels.long())      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "  \n",
    "    print(epoch+1, running_loss / len(val_loader))\n",
    "    hist_val.append(running_loss / len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for star, labels in test_loader:\n",
    "    images = Variable(star.view(-1, input_size)).cuda()\n",
    "    outputs, _, _ = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels.long()).sum()\n",
    "print('Accuracy of the network on test objects: %d %%' % (100 * correct / total))\n",
    "acc_testing = 100 *correct / total\n",
    "print(np.asarray(acc_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for star, labels in train_loader:\n",
    "    images = Variable(star.view(-1, input_size)).cuda()\n",
    "    outputs, _, _ = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels.long()).sum()\n",
    "print('Accuracy of the network on train objects: %d %%' % (100 * correct / total))\n",
    "acc_training = 100 *correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "torch.save(net.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_val, label ='validation')\n",
    "plt.plot(hist_train, label ='train')\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig('images/'+str(samples)+'_'+str(epsilon)+'_'+str(n)+\"_\"+str(hidden_size)+\"_Loss_Training.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open(\"size_MLP_noise.csv\", \"a\")\n",
    "csv_file.write(str(np.asarray(acc_testing))+\",\"+str(np.asarray(acc_training))+\",\"+str(samples)+\",\"+str(epsilon)+\",\"+str(n)+\",\"+str(hidden_size)+\"\\n\")\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, intermediates, intermediates2, labels = get_representations(net, train_loader, device)\n",
    "outputs_test, intermediates_test, intermediates2_test, labels_test = get_representations(net, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_pca_data, intermediate_pca_data_test = get_pca(intermediates, data_test=intermediates_test)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,15))\n",
    "\n",
    "plot_representations(intermediate_pca_data, labels, axs[0, 0])\n",
    "plot_representations(intermediate_pca_data_test, labels_test, axs[1, 0])\n",
    "\n",
    "intermediate2_pca_data, intermediate2_pca_data_test = get_pca(intermediates2, data_test=intermediates2_test)\n",
    "plot_representations(intermediate2_pca_data, labels, axs[0, 1])\n",
    "plot_representations(intermediate2_pca_data_test, labels_test, axs[1, 1])\n",
    "\n",
    "output_pca_data, output_pca_data_test = get_pca(outputs, data_test=outputs_test)\n",
    "plot_representations(output_pca_data, labels, axs[0, 2])\n",
    "plot_representations(output_pca_data_test, labels_test, axs[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CURVES = 25000\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,15))\n",
    "intermediate_tsne_data, intermediate_tsne_data_test = get_tsne(intermediates, data_test= intermediates_test, n_curves = N_CURVES)\n",
    "plot_representations(intermediate_tsne_data, labels, axs[0, 0],  n_curves = N_CURVES)\n",
    "plot_representations(intermediate_tsne_data_test, labels_test, axs[1, 0], n_curves = N_CURVES)\n",
    "\n",
    "intermediate2_tsne_data, intermediate2_tsne_data_test = get_tsne(intermediates2, data_test=intermediates2_test, n_curves = N_CURVES)\n",
    "plot_representations(intermediate2_tsne_data, labels, axs[0, 1], n_curves = N_CURVES)\n",
    "plot_representations(intermediate2_tsne_data_test, labels_test, axs[1, 1], n_curves = N_CURVES)\n",
    "\n",
    "output_tsne_data, output2_tsne_data_test = get_tsne(outputs, data_test=outputs_test, n_curves = N_CURVES)\n",
    "plot_representations(output_tsne_data, labels, axs[0, 2], n_curves = N_CURVES)\n",
    "plot_representations(output2_tsne_data_test, labels_test, axs[1, 2], n_curves = N_CURVES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15,15))\n",
    "curves, labels, probs_train = get_predictions(net, train_loader_pred, device)\n",
    "pred_labels = torch.argmax(probs_train, 1)\n",
    "plot_confusion_matrix(np.round(labels), pred_labels, ax1)\n",
    "curves, labels, probs_test = get_predictions(net, test_loader_pred, device)\n",
    "pred_labels = torch.argmax(probs_test, 1)\n",
    "plot_confusion_matrix(np.round(labels), pred_labels, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_tensor))\n",
    "print(len(train_tensor_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves, labels, probs_train_sample = get_predictions(net, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,15))\n",
    "ax1.hist(probs_train[:,0], color='black')\n",
    "ax1.set_xlabel('training set')\n",
    "ax2.hist(probs_train_sample[:,0], color='black')\n",
    "ax2.set_xlabel('training set + samples')\n",
    "ax3.hist(probs_test[:,0], color='black')\n",
    "ax3.set_xlabel('testing set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(softmax(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WEIGHTS = 25\n",
    "weights = net.fc2.weight.data\n",
    "plot_weights(weights, N_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = net.fc1.weight.data\n",
    "w1 = weights1.cpu().numpy().reshape(-1,1)\n",
    "weights2 = net.fc2.weight.data\n",
    "w2 = weights2.cpu().numpy().reshape(-1,1)\n",
    "weights3 = net.fc3.weight.data\n",
    "w3 = weights3.cpu().numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,15))\n",
    "\n",
    "ax1.hist(w1, color='black')\n",
    "ax1.set_xlabel('Layer 1')\n",
    "ax2.hist(w2, color='black')\n",
    "ax2.set_xlabel('Layer 2')\n",
    "ax3.hist(w3, color='black')\n",
    "ax3.set_xlabel('Layer 3')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
