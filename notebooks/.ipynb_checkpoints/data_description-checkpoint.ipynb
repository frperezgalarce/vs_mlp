{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import sys\n",
    "import utilities as ut\n",
    "import matplotlib.pylab as pylab\n",
    "from utilities import *\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 25,\n",
    "         'axes.titlesize':25,\n",
    "         'xtick.labelsize':25,\n",
    "         'ytick.labelsize':25}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "PATH = ''\n",
    "PATH2 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = PATH + 'Train_rrlyr-1.csv'\n",
    "path_test = PATH +  'Test_rrlyr-1.csv'\n",
    "\n",
    "lc_test = pd.read_table(path_test, sep= ',')\n",
    "lc_test = lc_test[lc_test.label=='ClassA']\n",
    "lc_train = pd.read_table(path_train, sep= ',')\n",
    "lc_train = lc_train[lc_train.label=='ClassA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.concat([lcu.iloc[lcu.Phase.argmax():lcu.shape[0]-1] , lcu.iloc[0:lcu.Phase.argmax()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_test  = lc_test['ID'].sample(20)\n",
    "example_train = lc_train['ID'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1 \n",
    "\n",
    "for lc in example_test.unique():\n",
    "    try:\n",
    "        new_test = lc_test[lc_test.ID==lc].ID.str.split(\"-\", n = 3, expand = True)\n",
    "        \n",
    "        period = lc_test[lc_test.ID==lc].PeriodLS.values[0]\n",
    "        field = new_test[new_test.columns[1]].values[0].lower()\n",
    "        \n",
    "        lcu = pd.read_table(PATH2+field+'/'+lc.split('-')[2].lower()+'/phot/I/'+lc,sep=\" \", names=['time', 'magnitude', 'error'])\n",
    "        \n",
    "        m0 = lcu.magnitude.min()\n",
    "        t0 = lcu[lcu.magnitude==m0].time.min()\n",
    "        lcu['Phase'] = ((lcu.time-t0)/period)%1 \n",
    "        lcu = lcu.dropna()\n",
    "\n",
    "        lcu2 =  lcu.copy()\n",
    "        lcu2['Phase'] = lcu2['Phase']+1\n",
    "        lcu = pd.concat([lcu,lcu2])\n",
    "        sample = 300\n",
    "        if lcu.dropna().shape[0]<300: \n",
    "            sample=lcu.dropna().shape[0]\n",
    "        fig, ax=plt.subplots(figsize=(12, 5))\n",
    "        sns.scatterplot(x=\"Phase\", y=\"magnitude\",\n",
    "                 data=lcu.dropna().sample(sample), alpha =0.4, palette = 'colorblind')\n",
    "        plt.title( str(lc).replace('.dat', '') + ', Period ' + str(np.round(period,2)))\n",
    "        plt.ylabel('Magnitude (I band)')\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "        plt.savefig('test'+str(counter)+'.svg', format='svg', bbox_inches='tight')\n",
    "        counter = counter + 1\n",
    "\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1 \n",
    "for lc in example_train.unique():\n",
    "    print(lc)\n",
    "    new_train = lc_train[lc_train.ID==lc].ID.str.split(\"-\", n = 3, expand = True)\n",
    "    #print(new_train)\n",
    "    period = lc_train[lc_train.ID==lc].PeriodLS.values[0]\n",
    "    field = new_train[new_train.columns[1]].values[0].lower()\n",
    "    lcu = pd.read_table(PATH2+field+'/'+lc.split('-')[2].lower()+'/phot/I/'+lc,sep=\" \", names=['time', 'magnitude', 'error'])\n",
    "    #print(lc)\n",
    "    m0 = lcu.magnitude.min()\n",
    "    t0 = lcu[lcu.magnitude==m0].time.min()\n",
    "\n",
    "    lcu['Phase'] = ((lcu.time-t0)/period)%1 \n",
    "    lcu = lcu.dropna()\n",
    "\n",
    "    lcu2 =  lcu.copy()\n",
    "    lcu2['Phase'] = lcu2['Phase']+1\n",
    "    lcu = pd.concat([lcu,lcu2])\n",
    "    \n",
    "    \n",
    "    sample = 300\n",
    "    if lcu.dropna().shape[0]<300: \n",
    "        sample=lcu.dropna().shape[0]\n",
    "    fig, ax=plt.subplots(figsize=(12, 5))\n",
    "    sns.scatterplot(x=\"Phase\", y=\"magnitude\",\n",
    "             data=lcu.dropna().sample(sample), alpha =0.4, palette = 'colorblind')\n",
    "    plt.title( str(lc).replace('.dat', '') + ', Period ' + str(np.round(period,2)))\n",
    "    plt.ylabel('Magnitude (I band)')\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    #plt.show()\n",
    "    plt.savefig('train'+str(counter)+'.svg', format='svg', bbox_inches='tight')\n",
    "    \n",
    "    counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = ut.load_files(dataset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = ut.delete_outliers(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total = pd.concat([train_dataset, test_dataset])\n",
    "y = data_total['label']\n",
    "del data_total['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_total, y, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "feature_names = [data_total.columns[i] for i in range(data_total.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = forest_importances.sort_values(ascending=False)[:30].reset_index()\n",
    "\n",
    "columns_for_ranges= dfff[dfff.columns[0]].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['PeriodLS', 'Amplitude']#, 'MedianAbsDev', 'Q31', 'Mean', 'Std', 'Freq1_harmonics_amplitude_0']\n",
    "d_train = train_dataset[(train_dataset.label=='ClassA') & (train_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_test = test_dataset[(test_dataset.label=='ClassA')& (test_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_train['set'] = 'RR Lyrae training set'\n",
    "d_test['set'] = 'RR Lyrae testing set'\n",
    "data_final = pd.concat([d_train, d_test])\n",
    "data_final.columns = ['Period', 'Amplitude', 'set']\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "sns.set_context(\"paper\", rc={\"font.size\":16, \"font_scale\":1.25, \"axes.titlesize\":16,\"axes.labelsize\":16,\n",
    "                \"xtick.labelsize\":16, \"ytick.labelsize\":16, \"legend.fontsize\":16, \"legend.title_fontsize\": 16, \n",
    "                            \"legend.loc\": 'upper center', \"alpha\":0.2, \"figure.dpi\":600, 'savefig.dpi':600}) \n",
    "\n",
    "g = sns.pairplot(data_final, hue='set', palette = 'colorblind', corner=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = iter(['xkcd:red purple', 'xkcd:pale teal'])\n",
    "\n",
    "def my_scatter(x,y, **kwargs):\n",
    "    plt.scatter(x,y, alpha=0.3)\n",
    "\n",
    "def my_hist(x, **kwargs):\n",
    "    plt.hist(x, alpha=0.2)\n",
    "\n",
    "g = sns.PairGrid(data_final,  hue='set', corner=True)\n",
    "g.map_diag(my_hist)\n",
    "g.map_offdiag(my_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['PeriodLS', 'Amplitude']#, 'MedianAbsDev', 'Q31', 'Mean', 'Std', 'Freq1_harmonics_amplitude_0']\n",
    "d_train = train_dataset[(train_dataset.label=='ClassA') & (train_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_test = test_dataset[(test_dataset.label=='ClassA')& (test_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_train['set'] = 'Training set'\n",
    "d_test['set'] =  'Testing set'\n",
    "data_final = pd.concat([d_train, d_test])\n",
    "data_final.columns = ['Period', 'Amplitude', 'set']\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "sns.set_context(\"paper\", rc={\"font.size\":14, \"font_scale\":1.25, \"axes.titlesize\":14,\"axes.labelsize\":14,\n",
    "                \"xtick.labelsize\":14, \"ytick.labelsize\":14, \"legend.fontsize\":12, \"legend.title_fontsize\": 14, \n",
    "                            \"legend.loc\": 'upper center', \"alpha\":0.2, \"figure.dpi\":600, 'savefig.dpi':600}) \n",
    "\n",
    "plt.figure(figsize=(25, 25), dpi = 900) \n",
    "g = sns.PairGrid(data_final, hue='set', palette = 'colorblind', corner=True)\n",
    "g.map_diag(sns.kdeplot,  shade=True, palette = 'colorblind')\n",
    "g.map_lower(sns.kdeplot, palette = 'colorblind')\n",
    "g.map_upper(sns.kdeplot, shade=True, palette = 'colorblind', hue=None)\n",
    "g.axes[1,0].set_ylim((0,1))\n",
    "g.axes[1,0].set_ylim((0,1.2))\n",
    "\n",
    "g.axes[1,0].set_yticks([0, 0.2,0.4,0.6,0.8,1])\n",
    "g.axes[1,0].set_xticks([0, 0.5 ,1])\n",
    "\n",
    "handles = g._legend_data.values()\n",
    "labels = g._legend_data.keys()\n",
    "plt.legend(handles=handles, labels=labels, loc='upper left', bbox_to_anchor=(0, 1.8), ncol=1)\n",
    "plt.savefig('period-amplitude.svg', format='svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['PeriodLS', 'Amplitude']#, 'MedianAbsDev', 'Q31', 'Mean', 'Std', 'Freq1_harmonics_amplitude_0']\n",
    "d_train = train_dataset[(train_dataset.label=='ClassA') & (train_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_test = test_dataset[(test_dataset.label=='ClassA')& (test_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_train['set'] = 'RR Lyrae training set'\n",
    "d_test['set'] = 'RR Lyrae testing set'\n",
    "data_final = pd.concat([d_train, d_test])\n",
    "data_final.columns = ['Period', 'Amplitude', 'set']\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "sns.set_context(\"paper\", rc={\"font.size\":14, \"font_scale\":1.25, \"axes.titlesize\":14,\"axes.labelsize\":14,\n",
    "                \"xtick.labelsize\":14, \"ytick.labelsize\":14, \"legend.fontsize\":14, \"legend.title_fontsize\": 14, \n",
    "                            \"legend.loc\": 'upper center', \"alpha\":0.2, \"figure.dpi\":600, 'savefig.dpi':600}) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(25, 25), dpi = 900) \n",
    "g = sns.pairplot(data_final, palette = 'colorblind', corner=True, plot_kws=dict(s=10, edgecolor=\"blue\",\n",
    "   fc='green', linewidth=2.5, alpha=0.05))\n",
    "g.axes[1,0].set_ylim((0,1))\n",
    "g.axes[1,0].set_ylim((0,1.2))\n",
    "\n",
    "g.axes[1,0].set_yticks([0, 0.2,0.4,0.6,0.8,1])\n",
    "g.axes[1,0].set_xticks([0, 0.5 ,1])\n",
    "plt.savefig('period-amplitude-complete.svg', format='svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['PeriodLS', 'Amplitude','MedianAbsDev', 'Q31', 'Mean', 'Std', 'Freq1_harmonics_amplitude_0']\n",
    "d_train = train_dataset[(train_dataset.label=='ClassA') & (train_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_test = test_dataset[(test_dataset.label=='ClassA')& (test_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_train['set'] = 'Training set'\n",
    "d_test['set'] = 'Testing set'\n",
    "data_final = pd.concat([d_train, d_test])\n",
    "data_final.columns = ['Period', 'Amplitude','MedianAbsDev', 'Q31', 'Mean', 'Std', 'Freq1_harmonics', 'set']\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "sns.set_context(\"paper\", rc={\"font.size\":16, \"font_scale\":1.25, \"axes.titlesize\":16,\"axes.labelsize\":16,\n",
    "                \"xtick.labelsize\":16, \"ytick.labelsize\":16, \"legend.fontsize\":16, \"legend.title_fontsize\": 16, \n",
    "                            \"legend.loc\": 'upper center', \"alpha\":0.2, \"figure.dpi\":600, 'savefig.dpi':600}) \n",
    "\n",
    "plt.figure(figsize=(21, 21), dpi = 900) \n",
    "g = sns.PairGrid(data_final, hue='set', palette = 'colorblind', corner=True)\n",
    "g.map_diag(sns.kdeplot,  shade=True, palette = 'colorblind')\n",
    "g.map_lower(sns.kdeplot, palette = 'colorblind')\n",
    "g.map_upper(sns.kdeplot, shade=True, palette = 'colorblind', hue=None)\n",
    "\n",
    "handles = g._legend_data.values()\n",
    "labels = g._legend_data.keys()\n",
    "plt.legend(handles=handles, labels=labels, bbox_to_anchor=(0., 6), ncol=2, borderaxespad=0)\n",
    "\n",
    "plt.savefig('shift.svg', format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['PeriodLS', 'Amplitude','MedianAbsDev', 'Q31', 'Mean', 'Std', 'Freq1_harmonics_amplitude_0']\n",
    "d_train = train_dataset[(train_dataset.label=='ClassA') & (train_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_test = test_dataset[(test_dataset.label=='ClassA')& (test_dataset.PeriodLS<1.5)][selected_features].sample(5000)\n",
    "d_train['set'] = 'RR Lyrae training set'\n",
    "d_test['set'] = 'RR Lyrae testing set'\n",
    "data_final = pd.concat([d_train, d_test])\n",
    "data_final.columns = ['Period', 'Amplitude','MedianAbsDev', 'Q31', 'Mean', 'Std', 'Freq1_harmonics', 'set']\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "sns.set_context(\"paper\", rc={\"font.size\":16, \"font_scale\":1.25, \"axes.titlesize\":16,\"axes.labelsize\":16,\n",
    "                \"xtick.labelsize\":16, \"ytick.labelsize\":16, \"legend.fontsize\":16, \"legend.title_fontsize\": 16, \n",
    "                            \"legend.loc\": 'upper center', \"alpha\":0.2, \"figure.dpi\":600, 'savefig.dpi':600}) \n",
    "\n",
    "plt.figure(figsize=(21, 21), dpi = 900) \n",
    "g = sns.PairGrid(data_final, palette = 'colorblind', corner=True)\n",
    "g.map_diag(sns.kdeplot,  shade=True, palette = 'colorblind')\n",
    "g.map_lower(sns.scatterplot, palette = 'colorblind')\n",
    "\n",
    "plt.savefig('shift-complete.svg', format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_test = pd.read_table(path_test, sep= ',')\n",
    "lc_train = pd.read_table(path_train, sep= ',')\n",
    "lc_test['label'] = lc_test['ID']\n",
    "lc_train['label'] = lc_train['ID']\n",
    "\n",
    "lc_train =  lc_train.drop(['Pred', 'Pred2', 'h', 'e', 'u', 'ID'], axis = 1)\n",
    "lc_test =  lc_test.drop(['Pred', 'Pred2', 'h', 'e', 'u', 'ID'], axis = 1)\n",
    "\n",
    "for col in lc_train.columns:\n",
    "    if col not in ['label']:\n",
    "        if lc_train[col].var()==0:\n",
    "            print(col)\n",
    "            del lc_train[col]\n",
    "            \n",
    "for col in lc_test.columns:\n",
    "    if col not in ['label']:\n",
    "        if lc_test[col].var()==0:\n",
    "            print(col)\n",
    "            del lc_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_train, lc_test = ut.delete_outliers(lc_train, lc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_test['set'] = 'Testing'\n",
    "lc_train['set'] = 'Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = lc_train['label'].str.split(\"-\", n = 3, expand = True) \n",
    "new_test = lc_test['label'].str.split(\"-\", n = 3, expand = True) \n",
    "\n",
    "lc_train[\"Field\"]= new_train[1] \n",
    "lc_train['Class']= new_train[2]  \n",
    "\n",
    "lc_test[\"Field\"]= new_test[1] \n",
    "lc_test['Class']= new_test[2] \n",
    "\n",
    "\n",
    "total_set = pd.concat([lc_train, lc_test])\n",
    "total_set['count'] = 1\n",
    "\n",
    "total_set= total_set[['set', 'Class', 'count']].groupby(['set', 'Class']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot(total_set, index='Class', columns='set', values='count').fillna(0).astype(int).sort_values('Testing', ascending=False).to_csv('resumenclasses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = PATH\n",
    "path_test = PATH\n",
    "pd.concat([lc_test, lc_train])[['PeriodLS', 'Amplitude', 'AndersonDarling', 'Autocor_length', 'Beyond1Std',\n",
    "        'CAR_mean', 'CAR_sigma', 'CAR_tau', 'Con', 'Eta_e',\n",
    "        'FluxPercentileRatioMid20', 'FluxPercentileRatioMid35',\n",
    "        'FluxPercentileRatioMid50', 'FluxPercentileRatioMid65',\n",
    "        'FluxPercentileRatioMid80', 'Freq1_harmonics_amplitude_0',\n",
    "        'Freq1_harmonics_amplitude_1', 'Freq1_harmonics_amplitude_2',\n",
    "        'Freq1_harmonics_amplitude_3', 'Freq1_harmonics_rel_phase_1',\n",
    "        'Freq1_harmonics_rel_phase_2', 'Freq1_harmonics_rel_phase_3',\n",
    "        'Freq2_harmonics_amplitude_0', 'Freq2_harmonics_amplitude_1',\n",
    "        'Freq2_harmonics_amplitude_2', 'Freq2_harmonics_amplitude_3',\n",
    "        'Freq2_harmonics_rel_phase_1', 'Freq2_harmonics_rel_phase_2',\n",
    "        'Freq2_harmonics_rel_phase_3', 'Freq3_harmonics_amplitude_0',\n",
    "        'Freq3_harmonics_amplitude_1', 'Freq3_harmonics_amplitude_2',\n",
    "        'Freq3_harmonics_amplitude_3', 'Freq3_harmonics_rel_phase_1',\n",
    "        'Freq3_harmonics_rel_phase_2', 'Freq3_harmonics_rel_phase_3', 'Gskew',\n",
    "        'LinearTrend', 'MaxSlope', 'Mean', 'Meanvariance', 'MedianAbsDev',\n",
    "        'MedianBRP', 'PairSlopeTrend', 'PercentAmplitude',\n",
    "        'PercentDifferenceFluxPercentile', 'Period_fit', 'Psi_CS',\n",
    "        'Psi_eta', 'Q31', 'Rcs', 'Skew', 'SlottedA_length', 'SmallKurtosis',\n",
    "        'Std', 'StetsonK', 'StetsonK_AC', 'StructureFunction_index_21',\n",
    "        'StructureFunction_index_31', 'StructureFunction_index_32']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_test[lc_test.Class=='RRLYR'].Field.value_counts(normalize=True).round(4)*100\n",
    "lc_train[lc_train.Class=='RRLYR'].Field.value_counts(normalize=True).round(4)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
