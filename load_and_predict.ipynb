{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/franciscoperez/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as f \n",
    "from torch.autograd import Variable\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import random \n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import utilities as ut\n",
    "from Network import Net\n",
    "import Network as nn\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "batch_size = 256\n",
    "hidden_size = 100\n",
    "num_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>roc_train</th>\n",
       "      <th>roc_test</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>aux_loss_activated</th>\n",
       "      <th>EPS1</th>\n",
       "      <th>n</th>\n",
       "      <th>opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>99.876190</td>\n",
       "      <td>82.247920</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.888126</td>\n",
       "      <td>0.999159</td>\n",
       "      <td>0.854043</td>\n",
       "      <td>0.999124</td>\n",
       "      <td>0.892750</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>99.929070</td>\n",
       "      <td>82.139850</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.854389</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>0.837569</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.879369</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>99.907120</td>\n",
       "      <td>82.115570</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.863371</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.841734</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0.876956</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>99.867546</td>\n",
       "      <td>81.307396</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.872864</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.841909</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.873357</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>99.884705</td>\n",
       "      <td>81.280590</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.849131</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.830572</td>\n",
       "      <td>0.999119</td>\n",
       "      <td>0.870377</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  acc_train   acc_test  recall_train  recall_test  f1_train  \\\n",
       "26          26  99.876190  82.247920      0.999557     0.888126  0.999159   \n",
       "9            9  99.929070  82.139850      0.999246     0.854389  0.999269   \n",
       "20          20  99.907120  82.115570      0.999734     0.863371  0.999403   \n",
       "2            2  99.867546  81.307396      0.999558     0.872864  0.999117   \n",
       "15          15  99.884705  81.280590      0.999601     0.849131  0.999224   \n",
       "\n",
       "     f1_test  roc_train  roc_test  epsilon  batch_size  hidden_size  \\\n",
       "26  0.854043   0.999124  0.892750        0         256          100   \n",
       "9   0.837569   0.999373  0.879369        0         256          100   \n",
       "20  0.841734   0.999259  0.876956        0         256          100   \n",
       "2   0.841909   0.998952  0.873357        0         256          100   \n",
       "15  0.830572   0.999119  0.870377        0         256          100   \n",
       "\n",
       "    aux_loss_activated   EPS1      n  opt  \n",
       "26                True  0.025  50000    1  \n",
       "9                 True  0.025  50000    1  \n",
       "20                True  0.025  50000    1  \n",
       "2                 True  0.025  50000    1  \n",
       "15                True  0.025  50000    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('13_01_2023_gaussian2d.csv').sort_values('acc_test', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>roc_train</th>\n",
       "      <th>roc_test</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>aux_loss_activated</th>\n",
       "      <th>EPS1</th>\n",
       "      <th>n</th>\n",
       "      <th>opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>99.889800</td>\n",
       "      <td>81.44302</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.881992</td>\n",
       "      <td>0.999030</td>\n",
       "      <td>0.846866</td>\n",
       "      <td>0.999148</td>\n",
       "      <td>0.875753</td>\n",
       "      <td>0.2</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>99.902610</td>\n",
       "      <td>79.44064</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.898131</td>\n",
       "      <td>0.999314</td>\n",
       "      <td>0.843090</td>\n",
       "      <td>0.999293</td>\n",
       "      <td>0.866602</td>\n",
       "      <td>0.2</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>99.893870</td>\n",
       "      <td>79.36625</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>0.865123</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>0.827854</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>0.855890</td>\n",
       "      <td>0.2</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>99.907110</td>\n",
       "      <td>79.35332</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.883526</td>\n",
       "      <td>0.999248</td>\n",
       "      <td>0.836115</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.863383</td>\n",
       "      <td>0.2</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>99.920395</td>\n",
       "      <td>79.10737</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>0.864612</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.826210</td>\n",
       "      <td>0.999324</td>\n",
       "      <td>0.856055</td>\n",
       "      <td>0.2</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.025</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  acc_train  acc_test  recall_train  recall_test  f1_train  \\\n",
       "26          26  99.889800  81.44302      0.999162     0.881992  0.999030   \n",
       "18          18  99.902610  79.44064      0.999601     0.898131  0.999314   \n",
       "3            3  99.893870  79.36625      0.999469     0.865123  0.999204   \n",
       "11          11  99.907110  79.35332      0.999425     0.883526  0.999248   \n",
       "15          15  99.920395  79.10737      0.999646     0.864612  0.999425   \n",
       "\n",
       "     f1_test  roc_train  roc_test  epsilon  batch_size  hidden_size  \\\n",
       "26  0.846866   0.999148  0.875753      0.2         256          100   \n",
       "18  0.843090   0.999293  0.866602      0.2         256          100   \n",
       "3   0.827854   0.999059  0.855890      0.2         256          100   \n",
       "11  0.836115   0.999115  0.863383      0.2         256          100   \n",
       "15  0.826210   0.999324  0.856055      0.2         256          100   \n",
       "\n",
       "    aux_loss_activated   EPS1      n  opt  \n",
       "26               False  0.025  50000    2  \n",
       "18               False  0.025  50000    2  \n",
       "3                False  0.025  50000    2  \n",
       "11               False  0.025  50000    2  \n",
       "15               False  0.025  50000    2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('13_01_2023_baseline.csv').sort_values('acc_test', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datContent = [i.strip().split() for i in open(\"../paper2-pending/subclasses/ident1.dat\").readlines()]\n",
    "\n",
    "data = pd.DataFrame(datContent)\n",
    "data.columns = ['ID', 'field_a','field_b', 'sub_clase', 'ccx', 'ccy', 'd', 'e', 'f', 'g' ]\n",
    "data=data[['ID', 'field_a','field_b', 'sub_clase', 'ccx', 'ccy']]\n",
    "data.shape\n",
    "\n",
    "datContent = [i.strip().split() for i in open(\"../paper2-pending/subclasses/ident2.dat\").readlines()]\n",
    "\n",
    "data2 = pd.DataFrame(datContent)\n",
    "data2.columns = ['ID', 'field_a','field_b', 'sub_clase', 'ccx', 'ccy']\n",
    "data = data.append(data2)\n",
    "data.shape\n",
    "\n",
    "datContent = [i.strip().split() for i in open(\"../paper2-pending/subclasses/ident3.dat\").readlines()]\n",
    "\n",
    "data3 = pd.DataFrame(datContent)\n",
    "data3.columns = ['ID', 'field_a','field_b', 'sub_clase', 'ccx', 'ccy', 'd', 'e', 'f', 'g' ,'k']\n",
    "data3=data3[['ID', 'field_a','field_b', 'sub_clase', 'ccx', 'ccy']]\n",
    "data = data.append(data3)\n",
    "data.shape\n",
    "\n",
    "datContent = [i.strip().split() for i in open(\"../paper2-pending/subclasses/ident4.dat\").readlines()]\n",
    "\n",
    "data4 = pd.DataFrame(datContent)\n",
    "data4.columns = ['ID', 'field_a','field_b', 'sub_clase', 'ccx', 'ccy', 'd', 'e', 'f', 'g' ]\n",
    "data4=data4[['ID', 'field_a','field_b', 'sub_clase', 'ccx', 'ccy']]\n",
    "data = data.append(data4)\n",
    "data.shape\n",
    "\n",
    "\n",
    "data = data[data.sub_clase.isin(['RRab', 'RRd', 'RRc', 'RRe'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def filter_by_subclass(data_subclasses, subclass='RRab'): \n",
    "    path_test = '/home/franciscoperez/Documents/GitHub/data/BIASEDFATS/Test_rrlyr-1.csv'\n",
    "    lc_test = pd.read_table(path_test, sep= ',')\n",
    "    del lc_test['Unnamed: 0']\n",
    "    columns_to_export = lc_test.columns\n",
    "    lc_test['ID'] = lc_test['ID'].str.replace('.dat', '') \n",
    "    lc_test = lc_test.merge(data_subclasses, left_on='ID', right_on='ID', how = 'left')\n",
    "    lc_test = lc_test[lc_test.sub_clase==subclass]\n",
    "    return lc_test[columns_to_export]\n",
    "\n",
    "RRab_test = filter_by_subclass(data, subclass='RRab')\n",
    "RRc_test = filter_by_subclass(data, subclass='RRc')\n",
    "RRd_test = filter_by_subclass(data, subclass='RRd')\n",
    "RRe_test = filter_by_subclass(data, subclass='RRe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq1_harmonics_rel_phase_0\n",
      "Freq2_harmonics_rel_phase_0\n",
      "Freq3_harmonics_rel_phase_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AndersonDarling</th>\n",
       "      <th>Autocor_length</th>\n",
       "      <th>Beyond1Std</th>\n",
       "      <th>CAR_mean</th>\n",
       "      <th>CAR_sigma</th>\n",
       "      <th>CAR_tau</th>\n",
       "      <th>Con</th>\n",
       "      <th>Eta_e</th>\n",
       "      <th>FluxPercentileRatioMid20</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SlottedA_length</th>\n",
       "      <th>SmallKurtosis</th>\n",
       "      <th>Std</th>\n",
       "      <th>StetsonK</th>\n",
       "      <th>StetsonK_AC</th>\n",
       "      <th>StructureFunction_index_21</th>\n",
       "      <th>StructureFunction_index_31</th>\n",
       "      <th>StructureFunction_index_32</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49643</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.131166</td>\n",
       "      <td>3</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>23.686214</td>\n",
       "      <td>0.738367</td>\n",
       "      <td>0.594257</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>77.820389</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104165</td>\n",
       "      <td>0.12345</td>\n",
       "      <td>-0.098630</td>\n",
       "      <td>0.022427</td>\n",
       "      <td>0.816054</td>\n",
       "      <td>0.779717</td>\n",
       "      <td>1.644229</td>\n",
       "      <td>2.212875</td>\n",
       "      <td>1.435421</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407286</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.457675</td>\n",
       "      <td>3</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>54.028838</td>\n",
       "      <td>0.549494</td>\n",
       "      <td>0.244528</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>50.714320</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195980</td>\n",
       "      <td>2.96080</td>\n",
       "      <td>0.590754</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.781576</td>\n",
       "      <td>0.702489</td>\n",
       "      <td>1.650383</td>\n",
       "      <td>2.080388</td>\n",
       "      <td>1.284226</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106019</th>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.842306</td>\n",
       "      <td>4</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>18.163004</td>\n",
       "      <td>0.668703</td>\n",
       "      <td>0.655423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.988632</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115857</td>\n",
       "      <td>7.18960</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.015522</td>\n",
       "      <td>0.792800</td>\n",
       "      <td>0.772128</td>\n",
       "      <td>1.760809</td>\n",
       "      <td>2.357977</td>\n",
       "      <td>1.384309</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269038</th>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.113156</td>\n",
       "      <td>2</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>35.016108</td>\n",
       "      <td>0.405370</td>\n",
       "      <td>0.435593</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>36098.082750</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096889</td>\n",
       "      <td>4.04488</td>\n",
       "      <td>0.298335</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.793050</td>\n",
       "      <td>0.734278</td>\n",
       "      <td>1.879023</td>\n",
       "      <td>2.721291</td>\n",
       "      <td>1.499985</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333084</th>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273973</td>\n",
       "      <td>34.429653</td>\n",
       "      <td>0.733305</td>\n",
       "      <td>0.449642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.510326</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178951</td>\n",
       "      <td>0.11075</td>\n",
       "      <td>0.838739</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.770452</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>1.735545</td>\n",
       "      <td>2.338960</td>\n",
       "      <td>1.432837</td>\n",
       "      <td>ClassB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Amplitude  AndersonDarling  Autocor_length  Beyond1Std   CAR_mean  \\\n",
       "49643      0.0435         0.131166               3    0.326667  23.686214   \n",
       "407286     0.0205         0.457675               3    0.270000  54.028838   \n",
       "106019     0.0305         0.842306               4    0.258065  18.163004   \n",
       "269038     0.0175         0.113156               2    0.350000  35.016108   \n",
       "333084     0.0150         0.007341               1    0.273973  34.429653   \n",
       "\n",
       "        CAR_sigma   CAR_tau       Con         Eta_e  FluxPercentileRatioMid20  \\\n",
       "49643    0.738367  0.594257  0.003356     77.820389                  0.191176   \n",
       "407286   0.549494  0.244528  0.003356     50.714320                  0.171429   \n",
       "106019   0.668703  0.655423  0.000000      6.988632                  0.120690   \n",
       "269038   0.405370  0.435593  0.006711  36098.082750                  0.137931   \n",
       "333084   0.733305  0.449642  0.000000     74.510326                  0.130435   \n",
       "\n",
       "        ...      Skew  SlottedA_length  SmallKurtosis       Std  StetsonK  \\\n",
       "49643   ...  0.104165          0.12345      -0.098630  0.022427  0.816054   \n",
       "407286  ... -0.195980          2.96080       0.590754  0.010581  0.781576   \n",
       "106019  ...  0.115857          7.18960       0.061644  0.015522  0.792800   \n",
       "269038  ... -0.096889          4.04488       0.298335  0.009146  0.793050   \n",
       "333084  ... -0.178951          0.11075       0.838739  0.007203  0.770452   \n",
       "\n",
       "        StetsonK_AC  StructureFunction_index_21  StructureFunction_index_31  \\\n",
       "49643      0.779717                    1.644229                    2.212875   \n",
       "407286     0.702489                    1.650383                    2.080388   \n",
       "106019     0.772128                    1.760809                    2.357977   \n",
       "269038     0.734278                    1.879023                    2.721291   \n",
       "333084     0.706294                    1.735545                    2.338960   \n",
       "\n",
       "        StructureFunction_index_32   label  \n",
       "49643                     1.435421  ClassB  \n",
       "407286                    1.284226  ClassB  \n",
       "106019                    1.384309  ClassB  \n",
       "269038                    1.499985  ClassB  \n",
       "333084                    1.432837  ClassB  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset = ut.load_files(dataset=1)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AndersonDarling</th>\n",
       "      <th>Autocor_length</th>\n",
       "      <th>Beyond1Std</th>\n",
       "      <th>CAR_mean</th>\n",
       "      <th>CAR_sigma</th>\n",
       "      <th>CAR_tau</th>\n",
       "      <th>Con</th>\n",
       "      <th>Eta_e</th>\n",
       "      <th>FluxPercentileRatioMid20</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SlottedA_length</th>\n",
       "      <th>SmallKurtosis</th>\n",
       "      <th>Std</th>\n",
       "      <th>StetsonK</th>\n",
       "      <th>StetsonK_AC</th>\n",
       "      <th>StructureFunction_index_21</th>\n",
       "      <th>StructureFunction_index_31</th>\n",
       "      <th>StructureFunction_index_32</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.16750</td>\n",
       "      <td>0.018003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>26.158132</td>\n",
       "      <td>0.073465</td>\n",
       "      <td>0.725973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.579577</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341465</td>\n",
       "      <td>1.96797</td>\n",
       "      <td>0.198594</td>\n",
       "      <td>0.078668</td>\n",
       "      <td>0.790933</td>\n",
       "      <td>0.664890</td>\n",
       "      <td>2.078430</td>\n",
       "      <td>3.183539</td>\n",
       "      <td>1.561949</td>\n",
       "      <td>ClassA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.22550</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>129.958025</td>\n",
       "      <td>0.513429</td>\n",
       "      <td>0.148121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145609.518248</td>\n",
       "      <td>0.178660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460641</td>\n",
       "      <td>0.01650</td>\n",
       "      <td>0.551941</td>\n",
       "      <td>0.126372</td>\n",
       "      <td>0.822407</td>\n",
       "      <td>0.766745</td>\n",
       "      <td>2.038494</td>\n",
       "      <td>3.106660</td>\n",
       "      <td>1.544758</td>\n",
       "      <td>ClassA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.037791</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>40.168090</td>\n",
       "      <td>0.114340</td>\n",
       "      <td>0.468277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1161.629293</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234766</td>\n",
       "      <td>0.04988</td>\n",
       "      <td>-0.267603</td>\n",
       "      <td>0.079077</td>\n",
       "      <td>0.827947</td>\n",
       "      <td>0.863374</td>\n",
       "      <td>1.854792</td>\n",
       "      <td>2.734859</td>\n",
       "      <td>1.555903</td>\n",
       "      <td>ClassA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.22600</td>\n",
       "      <td>0.224821</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>37.115196</td>\n",
       "      <td>0.683457</td>\n",
       "      <td>0.522459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.191250</td>\n",
       "      <td>0.171662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334666</td>\n",
       "      <td>1.95611</td>\n",
       "      <td>0.296205</td>\n",
       "      <td>0.115745</td>\n",
       "      <td>0.805037</td>\n",
       "      <td>0.666054</td>\n",
       "      <td>1.565646</td>\n",
       "      <td>1.875291</td>\n",
       "      <td>1.336562</td>\n",
       "      <td>ClassA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.19975</td>\n",
       "      <td>0.084151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295302</td>\n",
       "      <td>140.819375</td>\n",
       "      <td>0.270730</td>\n",
       "      <td>0.135191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.681435</td>\n",
       "      <td>0.148485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551426</td>\n",
       "      <td>0.20806</td>\n",
       "      <td>1.326243</td>\n",
       "      <td>0.100128</td>\n",
       "      <td>0.797293</td>\n",
       "      <td>0.784578</td>\n",
       "      <td>1.978843</td>\n",
       "      <td>2.951971</td>\n",
       "      <td>1.585350</td>\n",
       "      <td>ClassA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amplitude  AndersonDarling  Autocor_length  Beyond1Std    CAR_mean  \\\n",
       "16     0.16750         0.018003               1    0.303333   26.158132   \n",
       "27     0.22550         0.011021               1    0.296667  129.958025   \n",
       "164    0.14700         0.037791               1    0.351171   40.168090   \n",
       "352    0.22600         0.224821               1    0.313333   37.115196   \n",
       "365    0.19975         0.084151               1    0.295302  140.819375   \n",
       "\n",
       "     CAR_sigma   CAR_tau  Con          Eta_e  FluxPercentileRatioMid20  ...  \\\n",
       "16    0.073465  0.725973  0.0      12.579577                  0.150000  ...   \n",
       "27    0.513429  0.148121  0.0  145609.518248                  0.178660  ...   \n",
       "164   0.114340  0.468277  0.0    1161.629293                  0.154762  ...   \n",
       "352   0.683457  0.522459  0.0      87.191250                  0.171662  ...   \n",
       "365   0.270730  0.135191  0.0     140.681435                  0.148485  ...   \n",
       "\n",
       "         Skew  SlottedA_length  SmallKurtosis       Std  StetsonK  \\\n",
       "16   0.341465          1.96797       0.198594  0.078668  0.790933   \n",
       "27   0.460641          0.01650       0.551941  0.126372  0.822407   \n",
       "164  0.234766          0.04988      -0.267603  0.079077  0.827947   \n",
       "352  0.334666          1.95611       0.296205  0.115745  0.805037   \n",
       "365  0.551426          0.20806       1.326243  0.100128  0.797293   \n",
       "\n",
       "     StetsonK_AC  StructureFunction_index_21  StructureFunction_index_31  \\\n",
       "16      0.664890                    2.078430                    3.183539   \n",
       "27      0.766745                    2.038494                    3.106660   \n",
       "164     0.863374                    1.854792                    2.734859   \n",
       "352     0.666054                    1.565646                    1.875291   \n",
       "365     0.784578                    1.978843                    2.951971   \n",
       "\n",
       "     StructureFunction_index_32   label  \n",
       "16                     1.561949  ClassA  \n",
       "27                     1.544758  ClassA  \n",
       "164                    1.555903  ClassA  \n",
       "352                    1.336562  ClassA  \n",
       "365                    1.585350  ClassA  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RRe_test[train_dataset.columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq1_harmonics_rel_phase_0\n",
      "Freq2_harmonics_rel_phase_0\n",
      "Freq3_harmonics_rel_phase_0\n",
      "(28625, 61)\n",
      "(8175, 61)\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([4800, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([1201, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([40000, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([50000, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([1201, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([7779, 60])\n",
      "____get_tensor_function____\n",
      "shape tensor:  torch.Size([7779, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1  loss:  55.31181713938713 -- aux loss:  12.8681600689888\n",
      "training: epoch:  2  loss:  50.68006780743599 -- aux loss:  11.26086476445198\n",
      "training: epoch:  3  loss:  50.49630033969879 -- aux loss:  15.60795733332634\n",
      "training: epoch:  4  loss:  50.41345092654228 -- aux loss:  8.50998169183731\n",
      "training: epoch:  5  loss:  50.353882133960724 -- aux loss:  8.438534557819366\n",
      "training: epoch:  6  loss:  50.32209497690201 -- aux loss:  7.929449677467346\n",
      "training: epoch:  7  loss:  50.34791135787964 -- aux loss:  9.707759648561478\n",
      "training: epoch:  8  loss:  50.22933980822563 -- aux loss:  7.367851048707962\n",
      "training: epoch:  9  loss:  50.23355835676193 -- aux loss:  6.8035189509391785\n",
      "training: epoch:  10  loss:  50.234985530376434 -- aux loss:  6.865957826375961\n",
      "the_last_loss:  0.0\n",
      "running_loss_val:  0.34291544556617737\n",
      "validating: epoch:  10  loss:  0.34291544556617737\n",
      "The current loss: 0.34291544556617737\n",
      "the_last_loss: 0.0\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  11  loss:  50.15166953206062 -- aux loss:  7.118582934141159\n",
      "training: epoch:  12  loss:  50.112390249967575 -- aux loss:  6.795416444540024\n",
      "training: epoch:  13  loss:  50.06781432032585 -- aux loss:  7.153526723384857\n",
      "training: epoch:  14  loss:  50.056136190891266 -- aux loss:  7.1305297911167145\n",
      "training: epoch:  15  loss:  50.05365851521492 -- aux loss:  6.868503123521805\n",
      "training: epoch:  16  loss:  49.987011432647705 -- aux loss:  6.841332852840424\n",
      "training: epoch:  17  loss:  50.060526967048645 -- aux loss:  6.805357128381729\n",
      "training: epoch:  18  loss:  49.94623222947121 -- aux loss:  6.613157898187637\n",
      "training: epoch:  19  loss:  49.856169283390045 -- aux loss:  6.544909060001373\n",
      "training: epoch:  20  loss:  49.94203871488571 -- aux loss:  6.672193706035614\n",
      "the_last_loss:  0.34291544556617737\n",
      "running_loss_val:  0.34811925888061523\n",
      "validating: epoch:  20  loss:  0.34811925888061523\n",
      "The current loss: 0.34811925888061523\n",
      "the_last_loss: 0.34291544556617737\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  21  loss:  49.910753667354584 -- aux loss:  6.259490549564362\n",
      "training: epoch:  22  loss:  49.87395426630974 -- aux loss:  6.6077426970005035\n",
      "training: epoch:  23  loss:  49.84391248226166 -- aux loss:  6.366550922393799\n",
      "training: epoch:  24  loss:  49.858608931303024 -- aux loss:  6.30205374956131\n",
      "training: epoch:  25  loss:  49.806335896253586 -- aux loss:  6.268972754478455\n",
      "training: epoch:  26  loss:  49.86157611012459 -- aux loss:  6.4278923869133\n",
      "training: epoch:  27  loss:  49.818728893995285 -- aux loss:  6.542288690805435\n",
      "training: epoch:  28  loss:  49.77635878324509 -- aux loss:  7.015334069728851\n",
      "training: epoch:  29  loss:  49.86618062853813 -- aux loss:  6.716088265180588\n",
      "training: epoch:  30  loss:  49.74619472026825 -- aux loss:  6.420624762773514\n",
      "the_last_loss:  0.34811925888061523\n",
      "running_loss_val:  0.3167805075645447\n",
      "validating: epoch:  30  loss:  0.3167805075645447\n",
      "The current loss: 0.3167805075645447\n",
      "the_last_loss: 0.34811925888061523\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  31  loss:  49.75123828649521 -- aux loss:  6.549290746450424\n",
      "training: epoch:  32  loss:  49.71015900373459 -- aux loss:  6.303758502006531\n",
      "training: epoch:  33  loss:  49.80160203576088 -- aux loss:  6.448304980993271\n",
      "training: epoch:  34  loss:  49.70061668753624 -- aux loss:  6.15557724237442\n",
      "training: epoch:  35  loss:  49.741661459207535 -- aux loss:  6.98152557015419\n",
      "training: epoch:  36  loss:  49.72728577256203 -- aux loss:  6.1491270661354065\n",
      "training: epoch:  37  loss:  49.67834460735321 -- aux loss:  6.308184951543808\n",
      "training: epoch:  38  loss:  49.69064950942993 -- aux loss:  6.186242431402206\n",
      "training: epoch:  39  loss:  49.611859768629074 -- aux loss:  6.11098849773407\n",
      "training: epoch:  40  loss:  49.65539234876633 -- aux loss:  6.118044376373291\n",
      "the_last_loss:  0.3167805075645447\n",
      "running_loss_val:  0.3265599012374878\n",
      "validating: epoch:  40  loss:  0.3265599012374878\n",
      "The current loss: 0.3265599012374878\n",
      "the_last_loss: 0.3167805075645447\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  41  loss:  49.59284308552742 -- aux loss:  6.184698611497879\n",
      "training: epoch:  42  loss:  49.66174817085266 -- aux loss:  6.225971579551697\n",
      "training: epoch:  43  loss:  49.646515876054764 -- aux loss:  6.172539710998535\n",
      "training: epoch:  44  loss:  49.628590285778046 -- aux loss:  6.0818600952625275\n",
      "training: epoch:  45  loss:  49.64135852456093 -- aux loss:  6.059265047311783\n",
      "training: epoch:  46  loss:  49.647194147109985 -- aux loss:  6.202745348215103\n",
      "training: epoch:  47  loss:  49.60487198829651 -- aux loss:  6.24473175406456\n",
      "training: epoch:  48  loss:  49.57864251732826 -- aux loss:  6.250653713941574\n",
      "training: epoch:  49  loss:  49.59109354019165 -- aux loss:  6.185520738363266\n",
      "training: epoch:  50  loss:  49.57664766907692 -- aux loss:  6.233278930187225\n",
      "the_last_loss:  0.3265599012374878\n",
      "running_loss_val:  0.3202211260795593\n",
      "validating: epoch:  50  loss:  0.3202211260795593\n",
      "The current loss: 0.3202211260795593\n",
      "the_last_loss: 0.3265599012374878\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  51  loss:  49.60552451014519 -- aux loss:  6.342279940843582\n",
      "training: epoch:  52  loss:  49.701918333768845 -- aux loss:  6.141652971506119\n",
      "training: epoch:  53  loss:  49.5960499048233 -- aux loss:  6.1598318219184875\n",
      "training: epoch:  54  loss:  49.61712446808815 -- aux loss:  6.270496606826782\n",
      "training: epoch:  55  loss:  49.53768900036812 -- aux loss:  6.091660439968109\n",
      "training: epoch:  56  loss:  49.56686359643936 -- aux loss:  6.228283762931824\n",
      "training: epoch:  57  loss:  49.52961736917496 -- aux loss:  6.0550119280815125\n",
      "training: epoch:  58  loss:  49.53431433439255 -- aux loss:  6.03336638212204\n",
      "training: epoch:  59  loss:  49.53423631191254 -- aux loss:  5.984334886074066\n",
      "training: epoch:  60  loss:  49.54292756319046 -- aux loss:  6.165493935346603\n",
      "the_last_loss:  0.3202211260795593\n",
      "running_loss_val:  0.33070108294487\n",
      "validating: epoch:  60  loss:  0.33070108294487\n",
      "The current loss: 0.33070108294487\n",
      "the_last_loss: 0.3202211260795593\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  61  loss:  49.54553911089897 -- aux loss:  6.06192547082901\n",
      "training: epoch:  62  loss:  49.489680767059326 -- aux loss:  6.13656610250473\n",
      "training: epoch:  63  loss:  49.55053076148033 -- aux loss:  6.320084095001221\n",
      "training: epoch:  64  loss:  49.49044519662857 -- aux loss:  6.33291220664978\n",
      "training: epoch:  65  loss:  49.54756346344948 -- aux loss:  6.079677075147629\n",
      "training: epoch:  66  loss:  49.49135863780975 -- aux loss:  6.119547814130783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  67  loss:  49.51362207531929 -- aux loss:  6.060617208480835\n",
      "training: epoch:  68  loss:  49.51307433843613 -- aux loss:  6.1396417915821075\n",
      "training: epoch:  69  loss:  49.512084275484085 -- aux loss:  6.146182596683502\n",
      "training: epoch:  70  loss:  49.49605077505112 -- aux loss:  6.058685153722763\n",
      "the_last_loss:  0.33070108294487\n",
      "running_loss_val:  0.3154873251914978\n",
      "validating: epoch:  70  loss:  0.3154873251914978\n",
      "The current loss: 0.3154873251914978\n",
      "the_last_loss: 0.33070108294487\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  71  loss:  49.53608164191246 -- aux loss:  6.312272429466248\n",
      "training: epoch:  72  loss:  49.503575295209885 -- aux loss:  6.034740567207336\n",
      "training: epoch:  73  loss:  49.50386682152748 -- aux loss:  6.094726353883743\n",
      "training: epoch:  74  loss:  49.54128471016884 -- aux loss:  6.055193334817886\n",
      "training: epoch:  75  loss:  49.6031956076622 -- aux loss:  6.167444556951523\n",
      "training: epoch:  76  loss:  49.53542372584343 -- aux loss:  6.147887736558914\n",
      "training: epoch:  77  loss:  49.509406358003616 -- aux loss:  6.095039457082748\n",
      "training: epoch:  78  loss:  49.462564557790756 -- aux loss:  6.351955235004425\n",
      "training: epoch:  79  loss:  49.48102796077728 -- aux loss:  6.042777210474014\n",
      "training: epoch:  80  loss:  49.48045688867569 -- aux loss:  6.008759468793869\n",
      "the_last_loss:  0.3154873251914978\n",
      "running_loss_val:  0.3148230314254761\n",
      "validating: epoch:  80  loss:  0.3148230314254761\n",
      "The current loss: 0.3148230314254761\n",
      "the_last_loss: 0.3154873251914978\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  81  loss:  49.480915784835815 -- aux loss:  6.168973028659821\n",
      "training: epoch:  82  loss:  49.4829303920269 -- aux loss:  6.124468296766281\n",
      "training: epoch:  83  loss:  49.45505002140999 -- aux loss:  6.0508690774440765\n",
      "training: epoch:  84  loss:  49.43434861302376 -- aux loss:  6.098964095115662\n",
      "training: epoch:  85  loss:  49.480133056640625 -- aux loss:  6.121918857097626\n",
      "training: epoch:  86  loss:  49.48679107427597 -- aux loss:  6.096100926399231\n",
      "training: epoch:  87  loss:  49.479528963565826 -- aux loss:  6.707646757364273\n",
      "training: epoch:  88  loss:  49.44264364242554 -- aux loss:  6.151198089122772\n",
      "training: epoch:  89  loss:  49.4566510617733 -- aux loss:  5.9836655259132385\n",
      "training: epoch:  90  loss:  49.452140778303146 -- aux loss:  6.002379149198532\n",
      "the_last_loss:  0.3148230314254761\n",
      "running_loss_val:  0.31429389119148254\n",
      "validating: epoch:  90  loss:  0.31429389119148254\n",
      "The current loss: 0.31429389119148254\n",
      "the_last_loss: 0.3148230314254761\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  91  loss:  49.54166918992996 -- aux loss:  6.075081288814545\n",
      "training: epoch:  92  loss:  49.46614369750023 -- aux loss:  6.098642289638519\n",
      "training: epoch:  93  loss:  49.44011080265045 -- aux loss:  6.02338433265686\n",
      "training: epoch:  94  loss:  49.43657299876213 -- aux loss:  6.006545156240463\n",
      "training: epoch:  95  loss:  49.48955348134041 -- aux loss:  6.020537763834\n",
      "training: epoch:  96  loss:  49.46069619059563 -- aux loss:  6.0212099850177765\n",
      "training: epoch:  97  loss:  49.4430710375309 -- aux loss:  6.047446370124817\n",
      "training: epoch:  98  loss:  49.422486543655396 -- aux loss:  6.04205995798111\n",
      "training: epoch:  99  loss:  49.42325332760811 -- aux loss:  6.01988360285759\n",
      "training: epoch:  100  loss:  49.496143221855164 -- aux loss:  6.084080398082733\n",
      "the_last_loss:  0.31429389119148254\n",
      "running_loss_val:  0.3216751515865326\n",
      "validating: epoch:  100  loss:  0.3216751515865326\n",
      "The current loss: 0.3216751515865326\n",
      "the_last_loss: 0.31429389119148254\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  101  loss:  49.468141824007034 -- aux loss:  6.077883183956146\n",
      "training: epoch:  102  loss:  49.44713404774666 -- aux loss:  6.092908829450607\n",
      "training: epoch:  103  loss:  49.44420504570007 -- aux loss:  6.066553920507431\n",
      "training: epoch:  104  loss:  49.43269392848015 -- aux loss:  6.009661048650742\n",
      "training: epoch:  105  loss:  49.426663011312485 -- aux loss:  6.102907598018646\n",
      "training: epoch:  106  loss:  49.42908254265785 -- aux loss:  6.199387788772583\n",
      "training: epoch:  107  loss:  49.431397438049316 -- aux loss:  6.0124621987342834\n",
      "training: epoch:  108  loss:  49.44170853495598 -- aux loss:  6.004772186279297\n",
      "training: epoch:  109  loss:  49.40820303559303 -- aux loss:  6.0438646376132965\n",
      "training: epoch:  110  loss:  49.39626586437225 -- aux loss:  6.002255320549011\n",
      "the_last_loss:  0.3216751515865326\n",
      "running_loss_val:  0.31326356530189514\n",
      "validating: epoch:  110  loss:  0.31326356530189514\n",
      "The current loss: 0.31326356530189514\n",
      "the_last_loss: 0.3216751515865326\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  111  loss:  49.442793130874634 -- aux loss:  6.005096584558487\n",
      "training: epoch:  112  loss:  49.44117972254753 -- aux loss:  6.011622130870819\n",
      "training: epoch:  113  loss:  49.4223906993866 -- aux loss:  6.130977928638458\n",
      "training: epoch:  114  loss:  49.419735968112946 -- aux loss:  6.011242568492889\n",
      "training: epoch:  115  loss:  49.500665456056595 -- aux loss:  5.995945543050766\n",
      "training: epoch:  116  loss:  49.479706943035126 -- aux loss:  5.987596213817596\n",
      "training: epoch:  117  loss:  49.38824597001076 -- aux loss:  5.991054207086563\n",
      "training: epoch:  118  loss:  49.39443510770798 -- aux loss:  5.972877681255341\n",
      "training: epoch:  119  loss:  49.47798466682434 -- aux loss:  6.023882120847702\n",
      "training: epoch:  120  loss:  49.43132624030113 -- aux loss:  6.043265342712402\n",
      "the_last_loss:  0.31326356530189514\n",
      "running_loss_val:  0.3437040448188782\n",
      "validating: epoch:  120  loss:  0.3437040448188782\n",
      "The current loss: 0.3437040448188782\n",
      "the_last_loss: 0.31326356530189514\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  121  loss:  49.40114742517471 -- aux loss:  6.01464056968689\n",
      "training: epoch:  122  loss:  49.38777983188629 -- aux loss:  6.009758949279785\n",
      "training: epoch:  123  loss:  49.39735019207001 -- aux loss:  6.099793612957001\n",
      "training: epoch:  124  loss:  49.39730903506279 -- aux loss:  6.056882560253143\n",
      "training: epoch:  125  loss:  49.42191830277443 -- aux loss:  6.07371187210083\n",
      "training: epoch:  126  loss:  49.3958603143692 -- aux loss:  5.989524215459824\n",
      "training: epoch:  127  loss:  49.39614337682724 -- aux loss:  5.9650276601314545\n",
      "training: epoch:  128  loss:  49.394856840372086 -- aux loss:  6.0080811977386475\n",
      "training: epoch:  129  loss:  49.43303281068802 -- aux loss:  6.100151509046555\n",
      "training: epoch:  130  loss:  49.392493426799774 -- aux loss:  5.976852625608444\n",
      "the_last_loss:  0.3437040448188782\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  130  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3437040448188782\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  131  loss:  49.414283722639084 -- aux loss:  5.975222080945969\n",
      "training: epoch:  132  loss:  49.3851113319397 -- aux loss:  6.025577425956726\n",
      "training: epoch:  133  loss:  49.365787357091904 -- aux loss:  5.984868407249451\n",
      "training: epoch:  134  loss:  49.37168130278587 -- aux loss:  5.999543726444244\n",
      "training: epoch:  135  loss:  49.44443389773369 -- aux loss:  5.999437481164932\n",
      "training: epoch:  136  loss:  49.407061725854874 -- aux loss:  6.0286173820495605\n",
      "training: epoch:  137  loss:  49.37589627504349 -- aux loss:  6.011619567871094\n",
      "training: epoch:  138  loss:  49.41946169734001 -- aux loss:  5.997465401887894\n",
      "training: epoch:  139  loss:  49.4143206179142 -- aux loss:  6.03023424744606\n",
      "training: epoch:  140  loss:  49.3808736205101 -- aux loss:  6.201944410800934\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3146775960922241\n",
      "validating: epoch:  140  loss:  0.3146775960922241\n",
      "The current loss: 0.3146775960922241\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  141  loss:  49.38821765780449 -- aux loss:  6.000963479280472\n",
      "training: epoch:  142  loss:  49.363467663526535 -- aux loss:  6.006223618984222\n",
      "training: epoch:  143  loss:  49.34815111756325 -- aux loss:  5.988948106765747\n",
      "training: epoch:  144  loss:  49.380526930093765 -- aux loss:  5.967548102140427\n",
      "training: epoch:  145  loss:  49.38263550400734 -- aux loss:  5.963203459978104\n",
      "training: epoch:  146  loss:  49.375012159347534 -- aux loss:  5.965601056814194\n",
      "training: epoch:  147  loss:  49.39507734775543 -- aux loss:  5.988907277584076\n",
      "training: epoch:  148  loss:  49.378482818603516 -- aux loss:  6.049803704023361\n",
      "training: epoch:  149  loss:  49.429258584976196 -- aux loss:  6.00903657078743\n",
      "training: epoch:  150  loss:  49.37881815433502 -- aux loss:  6.016077607870102\n",
      "the_last_loss:  0.3146775960922241\n",
      "running_loss_val:  0.31769034266471863\n",
      "validating: epoch:  150  loss:  0.31769034266471863\n",
      "The current loss: 0.31769034266471863\n",
      "the_last_loss: 0.3146775960922241\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  151  loss:  49.399370700120926 -- aux loss:  6.043741315603256\n",
      "training: epoch:  152  loss:  49.3705595433712 -- aux loss:  6.007139146327972\n",
      "training: epoch:  153  loss:  49.39155527949333 -- aux loss:  6.0237869918346405\n",
      "training: epoch:  154  loss:  49.40081638097763 -- aux loss:  5.981211006641388\n",
      "training: epoch:  155  loss:  49.3865080177784 -- aux loss:  6.021175861358643\n",
      "training: epoch:  156  loss:  49.36322748661041 -- aux loss:  5.98495876789093\n",
      "training: epoch:  157  loss:  49.355558812618256 -- aux loss:  5.9624247550964355\n",
      "training: epoch:  158  loss:  49.368664503097534 -- aux loss:  5.977957457304001\n",
      "training: epoch:  159  loss:  49.38355502486229 -- aux loss:  6.025295853614807\n",
      "training: epoch:  160  loss:  49.380937188863754 -- aux loss:  5.994674474000931\n",
      "the_last_loss:  0.31769034266471863\n",
      "running_loss_val:  0.3151933550834656\n",
      "validating: epoch:  160  loss:  0.3151933550834656\n",
      "The current loss: 0.3151933550834656\n",
      "the_last_loss: 0.31769034266471863\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  161  loss:  49.36287611722946 -- aux loss:  5.965049684047699\n",
      "training: epoch:  162  loss:  49.380182921886444 -- aux loss:  5.984518438577652\n",
      "training: epoch:  163  loss:  49.39804622530937 -- aux loss:  5.993667185306549\n",
      "training: epoch:  164  loss:  49.41043567657471 -- aux loss:  6.08456090092659\n",
      "training: epoch:  165  loss:  49.3759229183197 -- aux loss:  6.003850281238556\n",
      "training: epoch:  166  loss:  49.40421524643898 -- aux loss:  6.057262033224106\n",
      "training: epoch:  167  loss:  49.362723886966705 -- aux loss:  6.027777582406998\n",
      "training: epoch:  168  loss:  49.40611532330513 -- aux loss:  6.004866749048233\n",
      "training: epoch:  169  loss:  49.38373786211014 -- aux loss:  5.9959240555763245\n",
      "training: epoch:  170  loss:  49.36426627635956 -- aux loss:  5.992011070251465\n",
      "the_last_loss:  0.3151933550834656\n",
      "running_loss_val:  0.31975871324539185\n",
      "validating: epoch:  170  loss:  0.31975871324539185\n",
      "The current loss: 0.31975871324539185\n",
      "the_last_loss: 0.3151933550834656\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  171  loss:  49.360398679971695 -- aux loss:  5.985658347606659\n",
      "training: epoch:  172  loss:  49.40763410925865 -- aux loss:  5.971691161394119\n",
      "training: epoch:  173  loss:  49.329948127269745 -- aux loss:  5.984432697296143\n",
      "training: epoch:  174  loss:  49.3421613574028 -- aux loss:  6.00094535946846\n",
      "training: epoch:  175  loss:  49.344833076000214 -- aux loss:  5.956082731485367\n",
      "training: epoch:  176  loss:  49.36416682600975 -- aux loss:  6.048585057258606\n",
      "training: epoch:  177  loss:  49.352030813694 -- aux loss:  6.0087451338768005\n",
      "training: epoch:  178  loss:  49.35893848538399 -- aux loss:  5.976743131875992\n",
      "training: epoch:  179  loss:  49.34853160381317 -- aux loss:  5.975680291652679\n",
      "training: epoch:  180  loss:  49.37357312440872 -- aux loss:  5.972874820232391\n",
      "the_last_loss:  0.31975871324539185\n",
      "running_loss_val:  0.3132617473602295\n",
      "validating: epoch:  180  loss:  0.3132617473602295\n",
      "The current loss: 0.3132617473602295\n",
      "the_last_loss: 0.31975871324539185\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  181  loss:  49.32684490084648 -- aux loss:  5.974457114934921\n",
      "training: epoch:  182  loss:  49.34965980052948 -- aux loss:  5.953129261732101\n",
      "training: epoch:  183  loss:  49.367941707372665 -- aux loss:  5.980565369129181\n",
      "training: epoch:  184  loss:  49.43897384405136 -- aux loss:  6.000323981046677\n",
      "training: epoch:  185  loss:  49.34597432613373 -- aux loss:  6.005975961685181\n",
      "training: epoch:  186  loss:  49.36665990948677 -- aux loss:  5.983506858348846\n",
      "training: epoch:  187  loss:  49.37780103087425 -- aux loss:  5.9965313374996185\n",
      "training: epoch:  188  loss:  49.36784127354622 -- aux loss:  5.971574366092682\n",
      "training: epoch:  189  loss:  49.35515674948692 -- aux loss:  5.9850567281246185\n",
      "training: epoch:  190  loss:  49.36013105511665 -- aux loss:  5.962223798036575\n",
      "the_last_loss:  0.3132617473602295\n",
      "running_loss_val:  0.31541088223457336\n",
      "validating: epoch:  190  loss:  0.31541088223457336\n",
      "The current loss: 0.31541088223457336\n",
      "the_last_loss: 0.3132617473602295\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  191  loss:  49.37508100271225 -- aux loss:  5.973957717418671\n",
      "training: epoch:  192  loss:  49.35594689846039 -- aux loss:  5.977149307727814\n",
      "training: epoch:  193  loss:  49.34636381268501 -- aux loss:  5.975282460451126\n",
      "training: epoch:  194  loss:  49.35093745589256 -- aux loss:  5.97582346200943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  195  loss:  49.36129415035248 -- aux loss:  5.975635647773743\n",
      "training: epoch:  196  loss:  49.356673419475555 -- aux loss:  5.974980533123016\n",
      "training: epoch:  197  loss:  49.35935717821121 -- aux loss:  5.989080101251602\n",
      "training: epoch:  198  loss:  49.334797233343124 -- aux loss:  5.984167665243149\n",
      "training: epoch:  199  loss:  49.3408522605896 -- aux loss:  6.04657581448555\n",
      "training: epoch:  200  loss:  49.32088503241539 -- aux loss:  6.011716067790985\n",
      "the_last_loss:  0.31541088223457336\n",
      "running_loss_val:  0.3134627044200897\n",
      "validating: epoch:  200  loss:  0.3134627044200897\n",
      "The current loss: 0.3134627044200897\n",
      "the_last_loss: 0.31541088223457336\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  201  loss:  49.344240725040436 -- aux loss:  5.972157597541809\n",
      "training: epoch:  202  loss:  49.352675169706345 -- aux loss:  6.1019158363342285\n",
      "training: epoch:  203  loss:  49.34370654821396 -- aux loss:  5.967400163412094\n",
      "training: epoch:  204  loss:  49.35389065742493 -- aux loss:  5.968761742115021\n",
      "training: epoch:  205  loss:  49.46553647518158 -- aux loss:  5.978056162595749\n",
      "training: epoch:  206  loss:  49.37874695658684 -- aux loss:  5.994405895471573\n",
      "training: epoch:  207  loss:  49.348217368125916 -- aux loss:  5.983660131692886\n",
      "training: epoch:  208  loss:  49.347827702760696 -- aux loss:  5.993562072515488\n",
      "training: epoch:  209  loss:  49.353219628334045 -- aux loss:  6.0080094039440155\n",
      "training: epoch:  210  loss:  49.352804124355316 -- aux loss:  5.970013409852982\n",
      "the_last_loss:  0.3134627044200897\n",
      "running_loss_val:  0.31434810161590576\n",
      "validating: epoch:  210  loss:  0.31434810161590576\n",
      "The current loss: 0.31434810161590576\n",
      "the_last_loss: 0.3134627044200897\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  211  loss:  49.333537846803665 -- aux loss:  5.9674530029296875\n",
      "training: epoch:  212  loss:  49.32512176036835 -- aux loss:  5.984956532716751\n",
      "training: epoch:  213  loss:  49.32213148474693 -- aux loss:  5.962557137012482\n",
      "training: epoch:  214  loss:  49.34612229466438 -- aux loss:  5.966218948364258\n",
      "training: epoch:  215  loss:  49.35411727428436 -- aux loss:  5.996442675590515\n",
      "training: epoch:  216  loss:  49.35864645242691 -- aux loss:  5.980013012886047\n",
      "training: epoch:  217  loss:  49.346871972084045 -- aux loss:  6.00166928768158\n",
      "training: epoch:  218  loss:  49.3346351981163 -- aux loss:  5.993838429450989\n",
      "training: epoch:  219  loss:  49.327592968940735 -- aux loss:  5.9788181483745575\n",
      "training: epoch:  220  loss:  49.35021850466728 -- aux loss:  5.955983608961105\n",
      "the_last_loss:  0.31434810161590576\n",
      "running_loss_val:  0.3132675588130951\n",
      "validating: epoch:  220  loss:  0.3132675588130951\n",
      "The current loss: 0.3132675588130951\n",
      "the_last_loss: 0.31434810161590576\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  221  loss:  49.328982919454575 -- aux loss:  5.958146810531616\n",
      "training: epoch:  222  loss:  49.320445626974106 -- aux loss:  5.955528408288956\n",
      "training: epoch:  223  loss:  49.33330059051514 -- aux loss:  5.9619103372097015\n",
      "training: epoch:  224  loss:  49.40587967634201 -- aux loss:  5.987305164337158\n",
      "training: epoch:  225  loss:  49.35257214307785 -- aux loss:  5.974333584308624\n",
      "training: epoch:  226  loss:  49.33759316802025 -- aux loss:  5.963339596986771\n",
      "training: epoch:  227  loss:  49.336913138628006 -- aux loss:  5.964771538972855\n",
      "training: epoch:  228  loss:  49.34704765677452 -- aux loss:  5.9579804837703705\n",
      "training: epoch:  229  loss:  49.39417093992233 -- aux loss:  5.960084944963455\n",
      "training: epoch:  230  loss:  49.37750133872032 -- aux loss:  5.9922952353954315\n",
      "the_last_loss:  0.3132675588130951\n",
      "running_loss_val:  0.31326720118522644\n",
      "validating: epoch:  230  loss:  0.31326720118522644\n",
      "The current loss: 0.31326720118522644\n",
      "the_last_loss: 0.3132675588130951\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  231  loss:  49.32233598828316 -- aux loss:  5.970889240503311\n",
      "training: epoch:  232  loss:  49.32428130507469 -- aux loss:  5.96577388048172\n",
      "training: epoch:  233  loss:  49.3266464471817 -- aux loss:  5.95574626326561\n",
      "training: epoch:  234  loss:  49.31275141239166 -- aux loss:  5.962362736463547\n",
      "training: epoch:  235  loss:  49.30792656540871 -- aux loss:  5.959860414266586\n",
      "training: epoch:  236  loss:  49.33086431026459 -- aux loss:  5.972333997488022\n",
      "training: epoch:  237  loss:  49.34230321645737 -- aux loss:  5.959424614906311\n",
      "training: epoch:  238  loss:  49.353782922029495 -- aux loss:  5.952237576246262\n",
      "training: epoch:  239  loss:  49.35894176363945 -- aux loss:  5.957082748413086\n",
      "training: epoch:  240  loss:  49.34744167327881 -- aux loss:  5.961561322212219\n",
      "the_last_loss:  0.31326720118522644\n",
      "running_loss_val:  0.3132617473602295\n",
      "validating: epoch:  240  loss:  0.3132617473602295\n",
      "The current loss: 0.3132617473602295\n",
      "the_last_loss: 0.31326720118522644\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  241  loss:  49.3639732003212 -- aux loss:  5.972725182771683\n",
      "training: epoch:  242  loss:  49.34360221028328 -- aux loss:  5.966032326221466\n",
      "training: epoch:  243  loss:  49.34357309341431 -- aux loss:  5.962150394916534\n",
      "training: epoch:  244  loss:  49.31638675928116 -- aux loss:  5.964336037635803\n",
      "training: epoch:  245  loss:  49.30805945396423 -- aux loss:  5.959219604730606\n",
      "training: epoch:  246  loss:  49.31536349654198 -- aux loss:  5.9640384912490845\n",
      "training: epoch:  247  loss:  49.33049434423447 -- aux loss:  5.982895761728287\n",
      "training: epoch:  248  loss:  49.319359332323074 -- aux loss:  5.965768456459045\n",
      "training: epoch:  249  loss:  49.32381862401962 -- aux loss:  5.980845600366592\n",
      "training: epoch:  250  loss:  49.339828461408615 -- aux loss:  5.965598464012146\n",
      "the_last_loss:  0.3132617473602295\n",
      "running_loss_val:  0.31514066457748413\n",
      "validating: epoch:  250  loss:  0.31514066457748413\n",
      "The current loss: 0.31514066457748413\n",
      "the_last_loss: 0.3132617473602295\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  251  loss:  49.33312049508095 -- aux loss:  5.955864191055298\n",
      "training: epoch:  252  loss:  49.38232725858688 -- aux loss:  5.955934137105942\n",
      "training: epoch:  253  loss:  49.36805349588394 -- aux loss:  6.143119245767593\n",
      "training: epoch:  254  loss:  49.34955617785454 -- aux loss:  5.966419041156769\n",
      "training: epoch:  255  loss:  49.360747426748276 -- aux loss:  5.9520028829574585\n",
      "training: epoch:  256  loss:  49.31559598445892 -- aux loss:  5.957660138607025\n",
      "training: epoch:  257  loss:  49.314160376787186 -- aux loss:  5.956017971038818\n",
      "training: epoch:  258  loss:  49.321985721588135 -- aux loss:  5.981082558631897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  259  loss:  49.35487565398216 -- aux loss:  5.9641015231609344\n",
      "training: epoch:  260  loss:  49.341176599264145 -- aux loss:  5.957704693078995\n",
      "the_last_loss:  0.31514066457748413\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  260  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31514066457748413\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  261  loss:  49.31725761294365 -- aux loss:  5.976097911596298\n",
      "training: epoch:  262  loss:  49.321007162332535 -- aux loss:  5.958495259284973\n",
      "training: epoch:  263  loss:  49.320115834474564 -- aux loss:  5.968172311782837\n",
      "training: epoch:  264  loss:  49.309657603502274 -- aux loss:  5.973153114318848\n",
      "training: epoch:  265  loss:  49.32298821210861 -- aux loss:  5.959585577249527\n",
      "training: epoch:  266  loss:  49.354164838790894 -- aux loss:  5.970345675945282\n",
      "training: epoch:  267  loss:  49.364385575056076 -- aux loss:  5.965334564447403\n",
      "training: epoch:  268  loss:  49.34832298755646 -- aux loss:  5.979999005794525\n",
      "training: epoch:  269  loss:  49.340170323848724 -- aux loss:  5.976607084274292\n",
      "training: epoch:  270  loss:  49.348675191402435 -- aux loss:  6.021689176559448\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3182172477245331\n",
      "validating: epoch:  270  loss:  0.3182172477245331\n",
      "The current loss: 0.3182172477245331\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  271  loss:  49.37075901031494 -- aux loss:  5.992611974477768\n",
      "training: epoch:  272  loss:  49.35700339078903 -- aux loss:  5.9588339030742645\n",
      "training: epoch:  273  loss:  49.33688202500343 -- aux loss:  5.967907696962357\n",
      "training: epoch:  274  loss:  49.328677624464035 -- aux loss:  5.985436499118805\n",
      "training: epoch:  275  loss:  49.31995451450348 -- aux loss:  5.96685391664505\n",
      "training: epoch:  276  loss:  49.318813025951385 -- aux loss:  5.985833078622818\n",
      "training: epoch:  277  loss:  49.315457224845886 -- aux loss:  5.981278359889984\n",
      "training: epoch:  278  loss:  49.37712833285332 -- aux loss:  5.971445977687836\n",
      "training: epoch:  279  loss:  49.32861593365669 -- aux loss:  5.960334956645966\n",
      "training: epoch:  280  loss:  49.33905404806137 -- aux loss:  5.97959503531456\n",
      "the_last_loss:  0.3182172477245331\n",
      "running_loss_val:  0.31364762783050537\n",
      "validating: epoch:  280  loss:  0.31364762783050537\n",
      "The current loss: 0.31364762783050537\n",
      "the_last_loss: 0.3182172477245331\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  281  loss:  49.357502430677414 -- aux loss:  5.9711481630802155\n",
      "training: epoch:  282  loss:  49.406953513622284 -- aux loss:  5.9863821268081665\n",
      "training: epoch:  283  loss:  49.375384747982025 -- aux loss:  6.050061643123627\n",
      "training: epoch:  284  loss:  49.35879120230675 -- aux loss:  5.958282768726349\n",
      "training: epoch:  285  loss:  49.33836081624031 -- aux loss:  5.959359228610992\n",
      "training: epoch:  286  loss:  49.326378643512726 -- aux loss:  5.970720291137695\n",
      "training: epoch:  287  loss:  49.336102336645126 -- aux loss:  5.982052683830261\n",
      "training: epoch:  288  loss:  49.34206676483154 -- aux loss:  5.9719981253147125\n",
      "training: epoch:  289  loss:  49.34565672278404 -- aux loss:  5.966216146945953\n",
      "training: epoch:  290  loss:  49.33063396811485 -- aux loss:  5.981882840394974\n",
      "the_last_loss:  0.31364762783050537\n",
      "running_loss_val:  0.3132931590080261\n",
      "validating: epoch:  290  loss:  0.3132931590080261\n",
      "The current loss: 0.3132931590080261\n",
      "the_last_loss: 0.31364762783050537\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  291  loss:  49.326629877090454 -- aux loss:  5.959818601608276\n",
      "training: epoch:  292  loss:  49.36132422089577 -- aux loss:  5.975008696317673\n",
      "training: epoch:  293  loss:  49.35343909263611 -- aux loss:  5.9798887968063354\n",
      "training: epoch:  294  loss:  49.351521253585815 -- aux loss:  5.96753466129303\n",
      "training: epoch:  295  loss:  49.34462723135948 -- aux loss:  5.9938152730464935\n",
      "training: epoch:  296  loss:  49.3365304172039 -- aux loss:  5.985973030328751\n",
      "training: epoch:  297  loss:  49.36700186133385 -- aux loss:  5.994327694177628\n",
      "training: epoch:  298  loss:  49.33205157518387 -- aux loss:  5.972797185182571\n",
      "training: epoch:  299  loss:  49.31819471716881 -- aux loss:  5.954122394323349\n",
      "training: epoch:  300  loss:  49.31175661087036 -- aux loss:  5.974020302295685\n",
      "the_last_loss:  0.3132931590080261\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  300  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.3132931590080261\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  301  loss:  49.310591131448746 -- aux loss:  5.964564114809036\n",
      "training: epoch:  302  loss:  49.31740456819534 -- aux loss:  5.969239979982376\n",
      "training: epoch:  303  loss:  49.32025822997093 -- aux loss:  5.956521242856979\n",
      "training: epoch:  304  loss:  49.40170428156853 -- aux loss:  5.953507602214813\n",
      "training: epoch:  305  loss:  49.38676369190216 -- aux loss:  5.965976059436798\n",
      "training: epoch:  306  loss:  49.35506650805473 -- aux loss:  5.953511863946915\n",
      "training: epoch:  307  loss:  49.332696944475174 -- aux loss:  5.958736956119537\n",
      "training: epoch:  308  loss:  49.3511081635952 -- aux loss:  5.96808722615242\n",
      "training: epoch:  309  loss:  49.34173545241356 -- aux loss:  5.955725282430649\n",
      "training: epoch:  310  loss:  49.32819139957428 -- aux loss:  5.959619790315628\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.3132675290107727\n",
      "validating: epoch:  310  loss:  0.3132675290107727\n",
      "The current loss: 0.3132675290107727\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  311  loss:  49.35043168067932 -- aux loss:  5.98037588596344\n",
      "training: epoch:  312  loss:  49.341857463121414 -- aux loss:  5.964535355567932\n",
      "training: epoch:  313  loss:  49.33344683051109 -- aux loss:  5.956841021776199\n",
      "training: epoch:  314  loss:  49.32821798324585 -- aux loss:  5.966268956661224\n",
      "training: epoch:  315  loss:  49.312808096408844 -- aux loss:  5.975408315658569\n",
      "training: epoch:  316  loss:  49.32970502972603 -- aux loss:  5.9567371010780334\n",
      "training: epoch:  317  loss:  49.32941868901253 -- aux loss:  5.958193928003311\n",
      "training: epoch:  318  loss:  49.328448086977005 -- aux loss:  5.95647394657135\n",
      "training: epoch:  319  loss:  49.322102785110474 -- aux loss:  5.952013701200485\n",
      "training: epoch:  320  loss:  49.32532021403313 -- aux loss:  5.957192242145538\n",
      "the_last_loss:  0.3132675290107727\n",
      "running_loss_val:  0.31485214829444885\n",
      "validating: epoch:  320  loss:  0.31485214829444885\n",
      "The current loss: 0.31485214829444885\n",
      "the_last_loss: 0.3132675290107727\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  321  loss:  49.33899676799774 -- aux loss:  5.960903137922287\n",
      "training: epoch:  322  loss:  49.362468957901 -- aux loss:  5.981045097112656\n",
      "training: epoch:  323  loss:  49.337361097335815 -- aux loss:  5.963645905256271\n",
      "training: epoch:  324  loss:  49.3140384554863 -- aux loss:  5.972156465053558\n",
      "training: epoch:  325  loss:  49.318373918533325 -- aux loss:  5.968446671962738\n",
      "training: epoch:  326  loss:  49.33861663937569 -- aux loss:  5.9818583726882935\n",
      "training: epoch:  327  loss:  49.34175544977188 -- aux loss:  5.969108819961548\n",
      "training: epoch:  328  loss:  49.35194730758667 -- aux loss:  5.997670471668243\n",
      "training: epoch:  329  loss:  49.3235148191452 -- aux loss:  5.995514065027237\n",
      "training: epoch:  330  loss:  49.335461258888245 -- aux loss:  6.011224240064621\n",
      "the_last_loss:  0.31485214829444885\n",
      "running_loss_val:  0.3281118869781494\n",
      "validating: epoch:  330  loss:  0.3281118869781494\n",
      "The current loss: 0.3281118869781494\n",
      "the_last_loss: 0.31485214829444885\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  331  loss:  49.31591734290123 -- aux loss:  5.964268743991852\n",
      "training: epoch:  332  loss:  49.30744010210037 -- aux loss:  5.958424925804138\n",
      "training: epoch:  333  loss:  49.33825308084488 -- aux loss:  5.9598265290260315\n",
      "training: epoch:  334  loss:  49.3375149667263 -- aux loss:  5.97028386592865\n",
      "training: epoch:  335  loss:  49.34250172972679 -- aux loss:  6.002925366163254\n",
      "training: epoch:  336  loss:  49.38168227672577 -- aux loss:  5.991630256175995\n",
      "training: epoch:  337  loss:  49.335117518901825 -- aux loss:  5.961316257715225\n",
      "training: epoch:  338  loss:  49.32402142882347 -- aux loss:  5.962793618440628\n",
      "training: epoch:  339  loss:  49.34216120839119 -- aux loss:  5.9809576869010925\n",
      "training: epoch:  340  loss:  49.3296785056591 -- aux loss:  5.966892123222351\n",
      "the_last_loss:  0.3281118869781494\n",
      "running_loss_val:  0.3189336359500885\n",
      "validating: epoch:  340  loss:  0.3189336359500885\n",
      "The current loss: 0.3189336359500885\n",
      "the_last_loss: 0.3281118869781494\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  341  loss:  49.33737063407898 -- aux loss:  5.958860337734222\n",
      "training: epoch:  342  loss:  49.32983237504959 -- aux loss:  5.960673153400421\n",
      "training: epoch:  343  loss:  49.31865409016609 -- aux loss:  5.967847108840942\n",
      "training: epoch:  344  loss:  49.32148739695549 -- aux loss:  5.956747800111771\n",
      "training: epoch:  345  loss:  49.3294492661953 -- aux loss:  5.957413762807846\n",
      "training: epoch:  346  loss:  49.323487132787704 -- aux loss:  5.955277651548386\n",
      "training: epoch:  347  loss:  49.323531836271286 -- aux loss:  5.965228110551834\n",
      "training: epoch:  348  loss:  49.308927685022354 -- aux loss:  5.951975703239441\n",
      "training: epoch:  349  loss:  49.31134748458862 -- aux loss:  5.952472567558289\n",
      "training: epoch:  350  loss:  49.30855914950371 -- aux loss:  5.959860384464264\n",
      "the_last_loss:  0.3189336359500885\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  350  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3189336359500885\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  351  loss:  49.31008991599083 -- aux loss:  5.957475066184998\n",
      "training: epoch:  352  loss:  49.30641087889671 -- aux loss:  5.955775290727615\n",
      "training: epoch:  353  loss:  49.311892956495285 -- aux loss:  5.955882221460342\n",
      "training: epoch:  354  loss:  49.3151319026947 -- aux loss:  5.957277715206146\n",
      "training: epoch:  355  loss:  49.3340630531311 -- aux loss:  5.958952218294144\n",
      "training: epoch:  356  loss:  49.33939588069916 -- aux loss:  5.956842422485352\n",
      "training: epoch:  357  loss:  49.41155922412872 -- aux loss:  5.976520389318466\n",
      "training: epoch:  358  loss:  49.350254595279694 -- aux loss:  5.952623873949051\n",
      "training: epoch:  359  loss:  49.37580242753029 -- aux loss:  5.952169269323349\n",
      "training: epoch:  360  loss:  49.319684445858 -- aux loss:  5.954680383205414\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  360  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  361  loss:  49.30450391769409 -- aux loss:  5.951971054077148\n",
      "training: epoch:  362  loss:  49.30907103419304 -- aux loss:  5.95197919011116\n",
      "training: epoch:  363  loss:  49.323111176490784 -- aux loss:  5.955909758806229\n",
      "training: epoch:  364  loss:  49.32658526301384 -- aux loss:  5.969934731721878\n",
      "training: epoch:  365  loss:  49.3516580760479 -- aux loss:  5.953754007816315\n",
      "training: epoch:  366  loss:  49.340643376111984 -- aux loss:  5.9573951959609985\n",
      "training: epoch:  367  loss:  49.33378967642784 -- aux loss:  5.957053989171982\n",
      "training: epoch:  368  loss:  49.369426012039185 -- aux loss:  5.95733967423439\n",
      "training: epoch:  369  loss:  49.33827766776085 -- aux loss:  5.952718079090118\n",
      "training: epoch:  370  loss:  49.31544056534767 -- aux loss:  5.9521699249744415\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  370  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  371  loss:  49.328101843595505 -- aux loss:  5.957280397415161\n",
      "training: epoch:  372  loss:  49.31162065267563 -- aux loss:  5.9628355503082275\n",
      "training: epoch:  373  loss:  49.32245373725891 -- aux loss:  5.9519729018211365\n",
      "training: epoch:  374  loss:  49.32274913787842 -- aux loss:  5.968854308128357\n",
      "training: epoch:  375  loss:  49.337141156196594 -- aux loss:  5.954369068145752\n",
      "training: epoch:  376  loss:  49.32323357462883 -- aux loss:  5.963648170232773\n",
      "training: epoch:  377  loss:  49.31327039003372 -- aux loss:  5.956120401620865\n",
      "training: epoch:  378  loss:  49.30750298500061 -- aux loss:  5.9530467092990875\n",
      "training: epoch:  379  loss:  49.37978333234787 -- aux loss:  5.9639787673950195\n",
      "training: epoch:  380  loss:  49.31436103582382 -- aux loss:  5.952030926942825\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  380  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  381  loss:  49.3088096678257 -- aux loss:  5.966925352811813\n",
      "training: epoch:  382  loss:  49.30742284655571 -- aux loss:  5.955622732639313\n",
      "training: epoch:  383  loss:  49.30361965298653 -- aux loss:  5.953293293714523\n",
      "training: epoch:  384  loss:  49.321355164051056 -- aux loss:  5.952766507863998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  385  loss:  49.323754996061325 -- aux loss:  5.953822702169418\n",
      "training: epoch:  386  loss:  49.356912821531296 -- aux loss:  5.966967523097992\n",
      "training: epoch:  387  loss:  49.38155606389046 -- aux loss:  5.986583054065704\n",
      "training: epoch:  388  loss:  49.353640019893646 -- aux loss:  5.973502427339554\n",
      "training: epoch:  389  loss:  49.31331068277359 -- aux loss:  5.954778015613556\n",
      "training: epoch:  390  loss:  49.31481283903122 -- aux loss:  5.953184396028519\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  390  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  391  loss:  49.311997056007385 -- aux loss:  5.952967166900635\n",
      "training: epoch:  392  loss:  49.33980715274811 -- aux loss:  5.953190892934799\n",
      "training: epoch:  393  loss:  49.33247393369675 -- aux loss:  5.955055773258209\n",
      "training: epoch:  394  loss:  49.334333926439285 -- aux loss:  5.960068553686142\n",
      "training: epoch:  395  loss:  49.3284769654274 -- aux loss:  5.990368038415909\n",
      "training: epoch:  396  loss:  49.30671513080597 -- aux loss:  5.953455984592438\n",
      "training: epoch:  397  loss:  49.31825801730156 -- aux loss:  5.95466274023056\n",
      "training: epoch:  398  loss:  49.315070420503616 -- aux loss:  5.951982229948044\n",
      "training: epoch:  399  loss:  49.316360145807266 -- aux loss:  5.951975375413895\n",
      "training: epoch:  400  loss:  49.344664961099625 -- aux loss:  5.952013522386551\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  400  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 5\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  401  loss:  49.33171045780182 -- aux loss:  5.952422171831131\n",
      "training: epoch:  402  loss:  49.30866855382919 -- aux loss:  5.953761726617813\n",
      "training: epoch:  403  loss:  49.3114287853241 -- aux loss:  5.9519736766815186\n",
      "training: epoch:  404  loss:  49.31551951169968 -- aux loss:  5.9519736766815186\n",
      "training: epoch:  405  loss:  49.33344301581383 -- aux loss:  5.951971799135208\n",
      "training: epoch:  406  loss:  49.3126502931118 -- aux loss:  5.958924800157547\n",
      "training: epoch:  407  loss:  49.37690594792366 -- aux loss:  5.956357508897781\n",
      "training: epoch:  408  loss:  49.33053478598595 -- aux loss:  5.96219339966774\n",
      "training: epoch:  409  loss:  49.310910761356354 -- aux loss:  5.952511131763458\n",
      "training: epoch:  410  loss:  49.322332978248596 -- aux loss:  5.9535326063632965\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  410  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 6\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  411  loss:  49.34406632184982 -- aux loss:  5.9519772827625275\n",
      "training: epoch:  412  loss:  49.309434443712234 -- aux loss:  5.952242732048035\n",
      "training: epoch:  413  loss:  49.33609202504158 -- aux loss:  5.951971083879471\n",
      "training: epoch:  414  loss:  49.3084080517292 -- aux loss:  5.955893397331238\n",
      "training: epoch:  415  loss:  49.30919551849365 -- aux loss:  5.956068992614746\n",
      "training: epoch:  416  loss:  49.31199982762337 -- aux loss:  5.95708566904068\n",
      "training: epoch:  417  loss:  49.30890116095543 -- aux loss:  5.953860729932785\n",
      "training: epoch:  418  loss:  49.30566802620888 -- aux loss:  5.953498691320419\n",
      "training: epoch:  419  loss:  49.31411638855934 -- aux loss:  5.952494651079178\n",
      "training: epoch:  420  loss:  49.30915832519531 -- aux loss:  5.954162985086441\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31329333782196045\n",
      "validating: epoch:  420  loss:  0.31329333782196045\n",
      "The current loss: 0.31329333782196045\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 7\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  421  loss:  49.31111595034599 -- aux loss:  5.952980250120163\n",
      "training: epoch:  422  loss:  49.315204083919525 -- aux loss:  5.957048207521439\n",
      "training: epoch:  423  loss:  49.339562237262726 -- aux loss:  5.966559827327728\n",
      "training: epoch:  424  loss:  49.35379812121391 -- aux loss:  5.973074287176132\n",
      "training: epoch:  425  loss:  49.348623156547546 -- aux loss:  5.959749639034271\n",
      "training: epoch:  426  loss:  49.32557189464569 -- aux loss:  5.9582580626010895\n",
      "training: epoch:  427  loss:  49.35633158683777 -- aux loss:  5.955485582351685\n",
      "training: epoch:  428  loss:  49.37802278995514 -- aux loss:  5.951971143484116\n",
      "training: epoch:  429  loss:  49.33124351501465 -- aux loss:  5.953514188528061\n",
      "training: epoch:  430  loss:  49.32806769013405 -- aux loss:  5.951972246170044\n",
      "the_last_loss:  0.31329333782196045\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  430  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31329333782196045\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  431  loss:  49.335596829652786 -- aux loss:  5.952319324016571\n",
      "training: epoch:  432  loss:  49.31507721543312 -- aux loss:  5.956455111503601\n",
      "training: epoch:  433  loss:  49.314423590898514 -- aux loss:  5.953107416629791\n",
      "training: epoch:  434  loss:  49.31834653019905 -- aux loss:  5.951983034610748\n",
      "training: epoch:  435  loss:  49.320139676332474 -- aux loss:  5.952453106641769\n",
      "training: epoch:  436  loss:  49.3147674202919 -- aux loss:  5.951976776123047\n",
      "training: epoch:  437  loss:  49.3074486553669 -- aux loss:  5.95197406411171\n",
      "training: epoch:  438  loss:  49.307147681713104 -- aux loss:  5.951971471309662\n",
      "training: epoch:  439  loss:  49.307562321424484 -- aux loss:  5.954186916351318\n",
      "training: epoch:  440  loss:  49.30766847729683 -- aux loss:  5.956406772136688\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  440  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  441  loss:  49.31973496079445 -- aux loss:  5.956779211759567\n",
      "training: epoch:  442  loss:  49.31283941864967 -- aux loss:  5.95198717713356\n",
      "training: epoch:  443  loss:  49.32403326034546 -- aux loss:  5.95302227139473\n",
      "training: epoch:  444  loss:  49.34678277373314 -- aux loss:  5.955269753932953\n",
      "training: epoch:  445  loss:  49.391281485557556 -- aux loss:  5.9546878933906555\n",
      "training: epoch:  446  loss:  49.33136835694313 -- aux loss:  5.953522443771362\n",
      "training: epoch:  447  loss:  49.331546664237976 -- aux loss:  5.952459394931793\n",
      "training: epoch:  448  loss:  49.31146419048309 -- aux loss:  5.953746438026428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  449  loss:  49.32238578796387 -- aux loss:  5.951971709728241\n",
      "training: epoch:  450  loss:  49.3159958422184 -- aux loss:  5.951971590518951\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891128420829773\n",
      "validating: epoch:  450  loss:  0.31891128420829773\n",
      "The current loss: 0.31891128420829773\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  451  loss:  49.32608726620674 -- aux loss:  5.9522687792778015\n",
      "training: epoch:  452  loss:  49.31910252571106 -- aux loss:  5.95252650976181\n",
      "training: epoch:  453  loss:  49.327381670475006 -- aux loss:  5.9534182250499725\n",
      "training: epoch:  454  loss:  49.31559166312218 -- aux loss:  5.951974391937256\n",
      "training: epoch:  455  loss:  49.34494400024414 -- aux loss:  5.955612987279892\n",
      "training: epoch:  456  loss:  49.345751255750656 -- aux loss:  5.951985538005829\n",
      "training: epoch:  457  loss:  49.33171218633652 -- aux loss:  5.953182011842728\n",
      "training: epoch:  458  loss:  49.3369245827198 -- aux loss:  5.955147057771683\n",
      "training: epoch:  459  loss:  49.336473286151886 -- aux loss:  5.964028030633926\n",
      "training: epoch:  460  loss:  49.31260359287262 -- aux loss:  5.956760972738266\n",
      "the_last_loss:  0.31891128420829773\n",
      "running_loss_val:  0.3189120888710022\n",
      "validating: epoch:  460  loss:  0.3189120888710022\n",
      "The current loss: 0.3189120888710022\n",
      "the_last_loss: 0.31891128420829773\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  461  loss:  49.310718923807144 -- aux loss:  5.952037811279297\n",
      "training: epoch:  462  loss:  49.31208312511444 -- aux loss:  5.952606379985809\n",
      "training: epoch:  463  loss:  49.324197471141815 -- aux loss:  5.951989322900772\n",
      "training: epoch:  464  loss:  49.31347894668579 -- aux loss:  5.955928474664688\n",
      "training: epoch:  465  loss:  49.319301158189774 -- aux loss:  5.952309221029282\n",
      "training: epoch:  466  loss:  49.31149673461914 -- aux loss:  5.951972275972366\n",
      "training: epoch:  467  loss:  49.33199641108513 -- aux loss:  5.954749673604965\n",
      "training: epoch:  468  loss:  49.33553895354271 -- aux loss:  5.961307227611542\n",
      "training: epoch:  469  loss:  49.33249381184578 -- aux loss:  5.952300578355789\n",
      "training: epoch:  470  loss:  49.31824576854706 -- aux loss:  5.955281108617783\n",
      "the_last_loss:  0.3189120888710022\n",
      "running_loss_val:  0.31326159834861755\n",
      "validating: epoch:  470  loss:  0.31326159834861755\n",
      "The current loss: 0.31326159834861755\n",
      "the_last_loss: 0.3189120888710022\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  471  loss:  49.31339377164841 -- aux loss:  5.951971113681793\n",
      "training: epoch:  472  loss:  49.31265199184418 -- aux loss:  5.959791719913483\n",
      "training: epoch:  473  loss:  49.319594979286194 -- aux loss:  5.955939948558807\n",
      "training: epoch:  474  loss:  49.31887945532799 -- aux loss:  5.953646808862686\n",
      "training: epoch:  475  loss:  49.32269439101219 -- aux loss:  5.953273355960846\n",
      "training: epoch:  476  loss:  49.33705720305443 -- aux loss:  5.954768031835556\n",
      "training: epoch:  477  loss:  49.33145287632942 -- aux loss:  5.952778697013855\n",
      "training: epoch:  478  loss:  49.35410541296005 -- aux loss:  5.957148104906082\n",
      "training: epoch:  479  loss:  49.3136630654335 -- aux loss:  5.959989994764328\n",
      "training: epoch:  480  loss:  49.31889954209328 -- aux loss:  5.954905807971954\n",
      "the_last_loss:  0.31326159834861755\n",
      "running_loss_val:  0.31891128420829773\n",
      "validating: epoch:  480  loss:  0.31891128420829773\n",
      "The current loss: 0.31891128420829773\n",
      "the_last_loss: 0.31326159834861755\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  481  loss:  49.304728388786316 -- aux loss:  5.955933839082718\n",
      "training: epoch:  482  loss:  49.31899902224541 -- aux loss:  5.951987832784653\n",
      "training: epoch:  483  loss:  49.31464064121246 -- aux loss:  5.953494340181351\n",
      "training: epoch:  484  loss:  49.31214028596878 -- aux loss:  5.954935669898987\n",
      "training: epoch:  485  loss:  49.309163093566895 -- aux loss:  5.954618871212006\n",
      "training: epoch:  486  loss:  49.315839260816574 -- aux loss:  5.951977729797363\n",
      "training: epoch:  487  loss:  49.317344188690186 -- aux loss:  5.951977074146271\n",
      "training: epoch:  488  loss:  49.30715161561966 -- aux loss:  5.952054470777512\n",
      "training: epoch:  489  loss:  49.306974619627 -- aux loss:  5.953716427087784\n",
      "training: epoch:  490  loss:  49.313059628009796 -- aux loss:  5.9613882303237915\n",
      "the_last_loss:  0.31891128420829773\n",
      "running_loss_val:  0.3134412169456482\n",
      "validating: epoch:  490  loss:  0.3134412169456482\n",
      "The current loss: 0.3134412169456482\n",
      "the_last_loss: 0.31891128420829773\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  491  loss:  49.320078641176224 -- aux loss:  5.959241151809692\n",
      "training: epoch:  492  loss:  49.31548514962196 -- aux loss:  5.951970994472504\n",
      "training: epoch:  493  loss:  49.32548928260803 -- aux loss:  5.952314168214798\n",
      "training: epoch:  494  loss:  49.57570478320122 -- aux loss:  5.967311322689056\n",
      "training: epoch:  495  loss:  49.36079454421997 -- aux loss:  5.953455001115799\n",
      "training: epoch:  496  loss:  49.328462809324265 -- aux loss:  5.953728199005127\n",
      "training: epoch:  497  loss:  49.31699654459953 -- aux loss:  5.952173560857773\n",
      "training: epoch:  498  loss:  49.31798154115677 -- aux loss:  5.952305495738983\n",
      "training: epoch:  499  loss:  49.34229511022568 -- aux loss:  5.955907493829727\n",
      "training: epoch:  500  loss:  49.3451706469059 -- aux loss:  5.951987087726593\n",
      "the_last_loss:  0.3134412169456482\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  500  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3134412169456482\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  501  loss:  49.32710599899292 -- aux loss:  5.9519738256931305\n",
      "training: epoch:  502  loss:  49.325454115867615 -- aux loss:  5.953455001115799\n",
      "training: epoch:  503  loss:  49.32651484012604 -- aux loss:  5.953587502241135\n",
      "training: epoch:  504  loss:  49.31259083747864 -- aux loss:  5.955171853303909\n",
      "training: epoch:  505  loss:  49.308837711811066 -- aux loss:  5.954432278871536\n",
      "training: epoch:  506  loss:  49.30372813344002 -- aux loss:  5.952019840478897\n",
      "training: epoch:  507  loss:  49.30617842078209 -- aux loss:  5.951970964670181\n",
      "training: epoch:  508  loss:  49.30660089850426 -- aux loss:  5.951973378658295\n",
      "training: epoch:  509  loss:  49.318894654512405 -- aux loss:  5.955629736185074\n",
      "training: epoch:  510  loss:  49.306330502033234 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  510  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  511  loss:  49.30944636464119 -- aux loss:  5.956045180559158\n",
      "training: epoch:  512  loss:  49.308292508125305 -- aux loss:  5.954277008771896\n",
      "training: epoch:  513  loss:  49.34230265021324 -- aux loss:  5.95406186580658\n",
      "training: epoch:  514  loss:  49.32411062717438 -- aux loss:  5.953115403652191\n",
      "training: epoch:  515  loss:  49.307489573955536 -- aux loss:  5.951972097158432\n",
      "training: epoch:  516  loss:  49.30448627471924 -- aux loss:  5.953403413295746\n",
      "training: epoch:  517  loss:  49.31335410475731 -- aux loss:  5.95197120308876\n",
      "training: epoch:  518  loss:  49.32391706109047 -- aux loss:  5.951976537704468\n",
      "training: epoch:  519  loss:  49.30747231841087 -- aux loss:  5.952574759721756\n",
      "training: epoch:  520  loss:  49.33040118217468 -- aux loss:  5.9684978723526\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3154090642929077\n",
      "validating: epoch:  520  loss:  0.3154090642929077\n",
      "The current loss: 0.3154090642929077\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  521  loss:  49.32582488656044 -- aux loss:  5.992860376834869\n",
      "training: epoch:  522  loss:  49.31153669953346 -- aux loss:  5.964004307985306\n",
      "training: epoch:  523  loss:  49.30450722575188 -- aux loss:  5.953512579202652\n",
      "training: epoch:  524  loss:  49.30484738945961 -- aux loss:  5.96560600399971\n",
      "training: epoch:  525  loss:  49.306610226631165 -- aux loss:  5.951972156763077\n",
      "training: epoch:  526  loss:  49.30742409825325 -- aux loss:  5.957302361726761\n",
      "training: epoch:  527  loss:  49.338023006916046 -- aux loss:  5.96300807595253\n",
      "training: epoch:  528  loss:  49.367207020521164 -- aux loss:  5.953410297632217\n",
      "training: epoch:  529  loss:  49.41136944293976 -- aux loss:  5.957569122314453\n",
      "training: epoch:  530  loss:  49.317830324172974 -- aux loss:  5.952007442712784\n",
      "the_last_loss:  0.3154090642929077\n",
      "running_loss_val:  0.3132621943950653\n",
      "validating: epoch:  530  loss:  0.3132621943950653\n",
      "The current loss: 0.3132621943950653\n",
      "the_last_loss: 0.3154090642929077\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  531  loss:  49.30916714668274 -- aux loss:  5.95197132229805\n",
      "training: epoch:  532  loss:  49.31674420833588 -- aux loss:  5.952033042907715\n",
      "training: epoch:  533  loss:  49.31306046247482 -- aux loss:  5.953451871871948\n",
      "training: epoch:  534  loss:  49.32382199168205 -- aux loss:  5.953460365533829\n",
      "training: epoch:  535  loss:  49.329655319452286 -- aux loss:  5.951971352100372\n",
      "training: epoch:  536  loss:  49.309093564748764 -- aux loss:  5.951973974704742\n",
      "training: epoch:  537  loss:  49.3124637901783 -- aux loss:  5.953394830226898\n",
      "training: epoch:  538  loss:  49.309012085199356 -- aux loss:  5.9532149732112885\n",
      "training: epoch:  539  loss:  49.30459985136986 -- aux loss:  5.956306159496307\n",
      "training: epoch:  540  loss:  49.32811090350151 -- aux loss:  5.953586250543594\n",
      "the_last_loss:  0.3132621943950653\n",
      "running_loss_val:  0.3132616877555847\n",
      "validating: epoch:  540  loss:  0.3132616877555847\n",
      "The current loss: 0.3132616877555847\n",
      "the_last_loss: 0.3132621943950653\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  541  loss:  49.315201580524445 -- aux loss:  5.951972723007202\n",
      "training: epoch:  542  loss:  49.32848560810089 -- aux loss:  5.952064752578735\n",
      "training: epoch:  543  loss:  49.320289850234985 -- aux loss:  5.951970964670181\n",
      "training: epoch:  544  loss:  49.32353776693344 -- aux loss:  5.954088121652603\n",
      "training: epoch:  545  loss:  49.305792927742004 -- aux loss:  5.951971769332886\n",
      "training: epoch:  546  loss:  49.317880898714066 -- aux loss:  5.9536775052547455\n",
      "training: epoch:  547  loss:  49.30407512187958 -- aux loss:  5.953803062438965\n",
      "training: epoch:  548  loss:  49.310385316610336 -- aux loss:  5.9534695744514465\n",
      "training: epoch:  549  loss:  49.30583843588829 -- aux loss:  5.955155551433563\n",
      "training: epoch:  550  loss:  49.308201879262924 -- aux loss:  5.951971471309662\n",
      "the_last_loss:  0.3132616877555847\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  550  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3132616877555847\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  551  loss:  49.326127767562866 -- aux loss:  5.957499146461487\n",
      "training: epoch:  552  loss:  49.35234957933426 -- aux loss:  5.953514456748962\n",
      "training: epoch:  553  loss:  49.31068828701973 -- aux loss:  5.957463711500168\n",
      "training: epoch:  554  loss:  49.35123661160469 -- aux loss:  5.9524164497852325\n",
      "training: epoch:  555  loss:  49.312417685985565 -- aux loss:  5.951974540948868\n",
      "training: epoch:  556  loss:  49.309531420469284 -- aux loss:  5.952894508838654\n",
      "training: epoch:  557  loss:  49.30358564853668 -- aux loss:  5.953453481197357\n",
      "training: epoch:  558  loss:  49.33227223157883 -- aux loss:  5.957637697458267\n",
      "training: epoch:  559  loss:  49.31518715620041 -- aux loss:  5.953893005847931\n",
      "training: epoch:  560  loss:  49.3104607462883 -- aux loss:  5.954697132110596\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3133637607097626\n",
      "validating: epoch:  560  loss:  0.3133637607097626\n",
      "The current loss: 0.3133637607097626\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  561  loss:  49.32775837182999 -- aux loss:  5.953455418348312\n",
      "training: epoch:  562  loss:  49.311671793460846 -- aux loss:  5.956765383481979\n",
      "training: epoch:  563  loss:  49.33052712678909 -- aux loss:  5.95941299200058\n",
      "training: epoch:  564  loss:  49.3149551153183 -- aux loss:  5.953960567712784\n",
      "training: epoch:  565  loss:  49.3023299574852 -- aux loss:  5.955216825008392\n",
      "training: epoch:  566  loss:  49.303684771060944 -- aux loss:  5.95497652888298\n",
      "training: epoch:  567  loss:  49.313282161951065 -- aux loss:  5.96129497885704\n",
      "training: epoch:  568  loss:  49.30791425704956 -- aux loss:  5.955925107002258\n",
      "training: epoch:  569  loss:  49.304782539606094 -- aux loss:  5.951983034610748\n",
      "training: epoch:  570  loss:  49.323902904987335 -- aux loss:  5.951971054077148\n",
      "the_last_loss:  0.3133637607097626\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  570  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3133637607097626\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  571  loss:  49.32847937941551 -- aux loss:  5.952079504728317\n",
      "training: epoch:  572  loss:  49.3319374024868 -- aux loss:  5.9546582996845245\n",
      "training: epoch:  573  loss:  49.304621785879135 -- aux loss:  5.951971024274826\n",
      "training: epoch:  574  loss:  49.30041924118996 -- aux loss:  5.952038049697876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  575  loss:  49.33090114593506 -- aux loss:  5.991093337535858\n",
      "training: epoch:  576  loss:  49.322305768728256 -- aux loss:  5.958890408277512\n",
      "training: epoch:  577  loss:  49.31602790951729 -- aux loss:  5.959685832262039\n",
      "training: epoch:  578  loss:  49.309037894010544 -- aux loss:  5.953432738780975\n",
      "training: epoch:  579  loss:  49.30515214800835 -- aux loss:  5.952144414186478\n",
      "training: epoch:  580  loss:  49.31937766075134 -- aux loss:  5.951989829540253\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3161192536354065\n",
      "validating: epoch:  580  loss:  0.3161192536354065\n",
      "The current loss: 0.3161192536354065\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  581  loss:  49.30631300806999 -- aux loss:  5.9553278386592865\n",
      "training: epoch:  582  loss:  49.322928160429 -- aux loss:  5.951975882053375\n",
      "training: epoch:  583  loss:  49.31135952472687 -- aux loss:  5.951971054077148\n",
      "training: epoch:  584  loss:  49.300981253385544 -- aux loss:  5.9524752497673035\n",
      "training: epoch:  585  loss:  49.317747712135315 -- aux loss:  5.9703050553798676\n",
      "training: epoch:  586  loss:  49.323054015636444 -- aux loss:  5.952883452177048\n",
      "training: epoch:  587  loss:  49.33785316348076 -- aux loss:  5.9526472091674805\n",
      "training: epoch:  588  loss:  49.332973659038544 -- aux loss:  5.953275054693222\n",
      "training: epoch:  589  loss:  49.3374328315258 -- aux loss:  5.961022883653641\n",
      "training: epoch:  590  loss:  49.31041556596756 -- aux loss:  5.959040522575378\n",
      "the_last_loss:  0.3161192536354065\n",
      "running_loss_val:  0.31326255202293396\n",
      "validating: epoch:  590  loss:  0.31326255202293396\n",
      "The current loss: 0.31326255202293396\n",
      "the_last_loss: 0.3161192536354065\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  591  loss:  49.30181539058685 -- aux loss:  5.951990693807602\n",
      "training: epoch:  592  loss:  49.31053912639618 -- aux loss:  5.951970994472504\n",
      "training: epoch:  593  loss:  49.307727456092834 -- aux loss:  5.952754944562912\n",
      "training: epoch:  594  loss:  49.31104275584221 -- aux loss:  5.951971024274826\n",
      "training: epoch:  595  loss:  49.30825713276863 -- aux loss:  5.951971054077148\n",
      "training: epoch:  596  loss:  49.30812242627144 -- aux loss:  5.951970964670181\n",
      "training: epoch:  597  loss:  49.29970034956932 -- aux loss:  5.953305631875992\n",
      "training: epoch:  598  loss:  49.31546479463577 -- aux loss:  5.952295660972595\n",
      "training: epoch:  599  loss:  49.311360478401184 -- aux loss:  5.952485293149948\n",
      "training: epoch:  600  loss:  49.30244308710098 -- aux loss:  5.95197120308876\n",
      "the_last_loss:  0.31326255202293396\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  600  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326255202293396\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  601  loss:  49.316916823387146 -- aux loss:  5.951978832483292\n",
      "training: epoch:  602  loss:  49.303501933813095 -- aux loss:  5.952173203229904\n",
      "training: epoch:  603  loss:  49.34108975529671 -- aux loss:  5.9521437883377075\n",
      "training: epoch:  604  loss:  49.317015528678894 -- aux loss:  5.952029794454575\n",
      "training: epoch:  605  loss:  49.307015508413315 -- aux loss:  5.954103320837021\n",
      "training: epoch:  606  loss:  49.318861961364746 -- aux loss:  5.952080726623535\n",
      "training: epoch:  607  loss:  49.35091704130173 -- aux loss:  5.952022761106491\n",
      "training: epoch:  608  loss:  49.30639144778252 -- aux loss:  5.951970964670181\n",
      "training: epoch:  609  loss:  49.300432443618774 -- aux loss:  5.952031522989273\n",
      "training: epoch:  610  loss:  49.33431449532509 -- aux loss:  5.95342019200325\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  610  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  611  loss:  49.31529939174652 -- aux loss:  5.952866822481155\n",
      "training: epoch:  612  loss:  49.31023398041725 -- aux loss:  5.951971381902695\n",
      "training: epoch:  613  loss:  49.303364396095276 -- aux loss:  5.9519712924957275\n",
      "training: epoch:  614  loss:  49.3072047829628 -- aux loss:  5.951970994472504\n",
      "training: epoch:  615  loss:  49.30359345674515 -- aux loss:  5.951970964670181\n",
      "training: epoch:  616  loss:  49.347778260707855 -- aux loss:  5.951970964670181\n",
      "training: epoch:  617  loss:  49.325942784547806 -- aux loss:  5.951970964670181\n",
      "training: epoch:  618  loss:  49.31907546520233 -- aux loss:  5.953456938266754\n",
      "training: epoch:  619  loss:  49.31083819270134 -- aux loss:  5.951970994472504\n",
      "training: epoch:  620  loss:  49.33414128422737 -- aux loss:  5.952171593904495\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  620  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  621  loss:  49.31730097532272 -- aux loss:  5.95197206735611\n",
      "training: epoch:  622  loss:  49.30875325202942 -- aux loss:  5.951970964670181\n",
      "training: epoch:  623  loss:  49.305007100105286 -- aux loss:  5.952884793281555\n",
      "training: epoch:  624  loss:  49.305228024721146 -- aux loss:  5.951971024274826\n",
      "training: epoch:  625  loss:  49.32284888625145 -- aux loss:  5.955877214670181\n",
      "training: epoch:  626  loss:  49.32514068484306 -- aux loss:  5.952523559331894\n",
      "training: epoch:  627  loss:  49.31199833750725 -- aux loss:  5.951970964670181\n",
      "training: epoch:  628  loss:  49.33177676796913 -- aux loss:  5.951970964670181\n",
      "training: epoch:  629  loss:  49.30474692583084 -- aux loss:  5.951970964670181\n",
      "training: epoch:  630  loss:  49.3129643201828 -- aux loss:  5.951970994472504\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  630  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  631  loss:  49.32421913743019 -- aux loss:  5.951970994472504\n",
      "training: epoch:  632  loss:  49.32105427980423 -- aux loss:  5.951971858739853\n",
      "training: epoch:  633  loss:  49.29980581998825 -- aux loss:  5.951978832483292\n",
      "training: epoch:  634  loss:  49.311563193798065 -- aux loss:  5.9528400003910065\n",
      "training: epoch:  635  loss:  49.31153056025505 -- aux loss:  5.951971083879471\n",
      "training: epoch:  636  loss:  49.29965540766716 -- aux loss:  5.952123910188675\n",
      "training: epoch:  637  loss:  49.3100383579731 -- aux loss:  5.951976150274277\n",
      "training: epoch:  638  loss:  49.30714729428291 -- aux loss:  5.951971799135208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  639  loss:  49.30297812819481 -- aux loss:  5.952268332242966\n",
      "training: epoch:  640  loss:  49.31106460094452 -- aux loss:  5.951970994472504\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  640  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  641  loss:  49.309042155742645 -- aux loss:  5.951970964670181\n",
      "training: epoch:  642  loss:  49.32866445183754 -- aux loss:  5.9522766172885895\n",
      "training: epoch:  643  loss:  49.3391250371933 -- aux loss:  5.956846088171005\n",
      "training: epoch:  644  loss:  49.32198441028595 -- aux loss:  5.951971173286438\n",
      "training: epoch:  645  loss:  49.30935072898865 -- aux loss:  5.95450422167778\n",
      "training: epoch:  646  loss:  49.326911956071854 -- aux loss:  5.953579425811768\n",
      "training: epoch:  647  loss:  49.31240913271904 -- aux loss:  5.953530728816986\n",
      "training: epoch:  648  loss:  49.30367839336395 -- aux loss:  5.9519719779491425\n",
      "training: epoch:  649  loss:  49.30091133713722 -- aux loss:  5.952016085386276\n",
      "training: epoch:  650  loss:  49.30938321352005 -- aux loss:  5.959124654531479\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  650  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 5\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  651  loss:  49.31183451414108 -- aux loss:  5.962892234325409\n",
      "training: epoch:  652  loss:  49.3118049800396 -- aux loss:  5.9556244015693665\n",
      "training: epoch:  653  loss:  49.29937705397606 -- aux loss:  5.952120274305344\n",
      "training: epoch:  654  loss:  49.3051563501358 -- aux loss:  5.9527594447135925\n",
      "training: epoch:  655  loss:  49.320389837026596 -- aux loss:  5.952016085386276\n",
      "training: epoch:  656  loss:  49.32979169487953 -- aux loss:  5.960940629243851\n",
      "training: epoch:  657  loss:  49.339365899562836 -- aux loss:  5.951999932527542\n",
      "training: epoch:  658  loss:  49.309177070856094 -- aux loss:  5.953443884849548\n",
      "training: epoch:  659  loss:  49.315264612436295 -- aux loss:  5.952296584844589\n",
      "training: epoch:  660  loss:  49.31009662151337 -- aux loss:  5.9520140290260315\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  660  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 6\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  661  loss:  49.33335441350937 -- aux loss:  5.963495284318924\n",
      "training: epoch:  662  loss:  49.30678141117096 -- aux loss:  5.951971262693405\n",
      "training: epoch:  663  loss:  49.32270631194115 -- aux loss:  5.951970994472504\n",
      "training: epoch:  664  loss:  49.30725601315498 -- aux loss:  5.951971769332886\n",
      "training: epoch:  665  loss:  49.32569918036461 -- aux loss:  5.953026384115219\n",
      "training: epoch:  666  loss:  49.328982174396515 -- aux loss:  5.951970994472504\n",
      "training: epoch:  667  loss:  49.31727895140648 -- aux loss:  5.95292267203331\n",
      "training: epoch:  668  loss:  49.305655509233475 -- aux loss:  5.955382734537125\n",
      "training: epoch:  669  loss:  49.30891427397728 -- aux loss:  5.953551858663559\n",
      "training: epoch:  670  loss:  49.30302619934082 -- aux loss:  5.95197206735611\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  670  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 7\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  671  loss:  49.30003926157951 -- aux loss:  5.952071487903595\n",
      "training: epoch:  672  loss:  49.33812230825424 -- aux loss:  5.951970964670181\n",
      "training: epoch:  673  loss:  49.319169491529465 -- aux loss:  5.953119367361069\n",
      "training: epoch:  674  loss:  49.31621965765953 -- aux loss:  5.951970964670181\n",
      "training: epoch:  675  loss:  49.31833079457283 -- aux loss:  5.951970994472504\n",
      "training: epoch:  676  loss:  49.303198128938675 -- aux loss:  5.951970964670181\n",
      "training: epoch:  677  loss:  49.299493968486786 -- aux loss:  5.951970964670181\n",
      "training: epoch:  678  loss:  49.30583080649376 -- aux loss:  5.951970964670181\n",
      "training: epoch:  679  loss:  49.33207440376282 -- aux loss:  5.951970994472504\n",
      "training: epoch:  680  loss:  49.30241033434868 -- aux loss:  5.953489810228348\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  680  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 8\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  681  loss:  49.312792122364044 -- aux loss:  5.951971024274826\n",
      "training: epoch:  682  loss:  49.30391976237297 -- aux loss:  5.95301479101181\n",
      "training: epoch:  683  loss:  49.30207586288452 -- aux loss:  5.951970964670181\n",
      "training: epoch:  684  loss:  49.343901842832565 -- aux loss:  5.9519712924957275\n",
      "training: epoch:  685  loss:  49.323539316654205 -- aux loss:  5.953464388847351\n",
      "training: epoch:  686  loss:  49.3338398039341 -- aux loss:  5.9555642902851105\n",
      "training: epoch:  687  loss:  49.32153728604317 -- aux loss:  5.953623116016388\n",
      "training: epoch:  688  loss:  49.31792080402374 -- aux loss:  5.960342288017273\n",
      "training: epoch:  689  loss:  49.30354142189026 -- aux loss:  5.951970994472504\n",
      "training: epoch:  690  loss:  49.30068302154541 -- aux loss:  5.952135652303696\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  690  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 9\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  691  loss:  49.302904427051544 -- aux loss:  5.953621476888657\n",
      "training: epoch:  692  loss:  49.30197608470917 -- aux loss:  5.95474898815155\n",
      "training: epoch:  693  loss:  49.34268692135811 -- aux loss:  5.953454911708832\n",
      "training: epoch:  694  loss:  49.331540644168854 -- aux loss:  5.9545718133449554\n",
      "training: epoch:  695  loss:  49.31973287463188 -- aux loss:  5.953788697719574\n",
      "training: epoch:  696  loss:  49.33973801136017 -- aux loss:  5.953471750020981\n",
      "training: epoch:  697  loss:  49.30105873942375 -- aux loss:  5.955130159854889\n",
      "training: epoch:  698  loss:  49.31885635852814 -- aux loss:  5.951970964670181\n",
      "training: epoch:  699  loss:  49.32155269384384 -- aux loss:  5.951971352100372\n",
      "training: epoch:  700  loss:  49.34037721157074 -- aux loss:  5.961022078990936\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.3132798671722412\n",
      "validating: epoch:  700  loss:  0.3132798671722412\n",
      "The current loss: 0.3132798671722412\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  701  loss:  49.32383951544762 -- aux loss:  5.951970994472504\n",
      "training: epoch:  702  loss:  49.30345484614372 -- aux loss:  5.957582980394363\n",
      "training: epoch:  703  loss:  49.304549276828766 -- aux loss:  5.951970964670181\n",
      "training: epoch:  704  loss:  49.30054634809494 -- aux loss:  5.951971143484116\n",
      "training: epoch:  705  loss:  49.30115678906441 -- aux loss:  5.951970964670181\n",
      "training: epoch:  706  loss:  49.303417801856995 -- aux loss:  5.951981544494629\n",
      "training: epoch:  707  loss:  49.305460810661316 -- aux loss:  5.953406363725662\n",
      "training: epoch:  708  loss:  49.3048554956913 -- aux loss:  5.951974600553513\n",
      "training: epoch:  709  loss:  49.36521250009537 -- aux loss:  5.952584803104401\n",
      "training: epoch:  710  loss:  49.32271474599838 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.3132798671722412\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  710  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.3132798671722412\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  711  loss:  49.330344051122665 -- aux loss:  5.951971530914307\n",
      "training: epoch:  712  loss:  49.32297170162201 -- aux loss:  5.955095708370209\n",
      "training: epoch:  713  loss:  49.30371552705765 -- aux loss:  5.9549762308597565\n",
      "training: epoch:  714  loss:  49.299688160419464 -- aux loss:  5.957365393638611\n",
      "training: epoch:  715  loss:  49.29956728219986 -- aux loss:  5.953601092100143\n",
      "training: epoch:  716  loss:  49.31855967640877 -- aux loss:  5.9530839920043945\n",
      "training: epoch:  717  loss:  49.30101317167282 -- aux loss:  5.952157199382782\n",
      "training: epoch:  718  loss:  49.34002500772476 -- aux loss:  5.952547013759613\n",
      "training: epoch:  719  loss:  49.36382368206978 -- aux loss:  5.952718913555145\n",
      "training: epoch:  720  loss:  49.31640934944153 -- aux loss:  5.9534744918346405\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  720  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  721  loss:  49.320573568344116 -- aux loss:  5.951970964670181\n",
      "training: epoch:  722  loss:  49.30010262131691 -- aux loss:  5.953334867954254\n",
      "training: epoch:  723  loss:  49.30129224061966 -- aux loss:  5.951971739530563\n",
      "training: epoch:  724  loss:  49.307956248521805 -- aux loss:  5.951970964670181\n",
      "training: epoch:  725  loss:  49.3230094909668 -- aux loss:  5.951970964670181\n",
      "training: epoch:  726  loss:  49.31794756650925 -- aux loss:  5.951970964670181\n",
      "training: epoch:  727  loss:  49.31517779827118 -- aux loss:  5.951970964670181\n",
      "training: epoch:  728  loss:  49.307180762290955 -- aux loss:  5.9519718289375305\n",
      "training: epoch:  729  loss:  49.30976605415344 -- aux loss:  5.951970994472504\n",
      "training: epoch:  730  loss:  49.30078288912773 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  730  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  731  loss:  49.299452632665634 -- aux loss:  5.951970964670181\n",
      "training: epoch:  732  loss:  49.30011534690857 -- aux loss:  5.951971024274826\n",
      "training: epoch:  733  loss:  49.312219232320786 -- aux loss:  5.951970964670181\n",
      "training: epoch:  734  loss:  49.31736779212952 -- aux loss:  5.952170550823212\n",
      "training: epoch:  735  loss:  49.30530947446823 -- aux loss:  5.951971471309662\n",
      "training: epoch:  736  loss:  49.33850660920143 -- aux loss:  5.951975584030151\n",
      "training: epoch:  737  loss:  49.30502864718437 -- aux loss:  5.951971054077148\n",
      "training: epoch:  738  loss:  49.30094042420387 -- aux loss:  5.951972424983978\n",
      "training: epoch:  739  loss:  49.30004367232323 -- aux loss:  5.951973706483841\n",
      "training: epoch:  740  loss:  49.30377623438835 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3189418911933899\n",
      "validating: epoch:  740  loss:  0.3189418911933899\n",
      "The current loss: 0.3189418911933899\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  741  loss:  49.335350185632706 -- aux loss:  5.952550560235977\n",
      "training: epoch:  742  loss:  49.311210453510284 -- aux loss:  5.95430189371109\n",
      "training: epoch:  743  loss:  49.313622176647186 -- aux loss:  5.959327876567841\n",
      "training: epoch:  744  loss:  49.33270686864853 -- aux loss:  5.951970964670181\n",
      "training: epoch:  745  loss:  49.309030294418335 -- aux loss:  5.953585654497147\n",
      "training: epoch:  746  loss:  49.30561977624893 -- aux loss:  5.951970994472504\n",
      "training: epoch:  747  loss:  49.303101658821106 -- aux loss:  5.951979249715805\n",
      "training: epoch:  748  loss:  49.311503410339355 -- aux loss:  5.95251128077507\n",
      "training: epoch:  749  loss:  49.309942185878754 -- aux loss:  5.951970964670181\n",
      "training: epoch:  750  loss:  49.30596122145653 -- aux loss:  5.952634871006012\n",
      "the_last_loss:  0.3189418911933899\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  750  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3189418911933899\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  751  loss:  49.30726057291031 -- aux loss:  5.9572997987270355\n",
      "training: epoch:  752  loss:  49.326123893260956 -- aux loss:  5.955361783504486\n",
      "training: epoch:  753  loss:  49.309512197971344 -- aux loss:  5.9569331407547\n",
      "training: epoch:  754  loss:  49.30055832862854 -- aux loss:  6.015702337026596\n",
      "training: epoch:  755  loss:  49.30524855852127 -- aux loss:  5.951970964670181\n",
      "training: epoch:  756  loss:  49.32785138487816 -- aux loss:  5.951971054077148\n",
      "training: epoch:  757  loss:  49.32681706547737 -- aux loss:  5.953428089618683\n",
      "training: epoch:  758  loss:  49.30580046772957 -- aux loss:  5.951970964670181\n",
      "training: epoch:  759  loss:  49.332174211740494 -- aux loss:  5.951970964670181\n",
      "training: epoch:  760  loss:  49.32263112068176 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  760  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  761  loss:  49.31150075793266 -- aux loss:  5.951971024274826\n",
      "training: epoch:  762  loss:  49.324005752801895 -- aux loss:  5.952167272567749\n",
      "training: epoch:  763  loss:  49.307048082351685 -- aux loss:  5.951970964670181\n",
      "training: epoch:  764  loss:  49.30875891447067 -- aux loss:  5.9534545838832855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  765  loss:  49.30455240607262 -- aux loss:  5.951970964670181\n",
      "training: epoch:  766  loss:  49.3002824485302 -- aux loss:  5.951970964670181\n",
      "training: epoch:  767  loss:  49.30469897389412 -- aux loss:  5.9519825875759125\n",
      "training: epoch:  768  loss:  49.31934577226639 -- aux loss:  5.951970964670181\n",
      "training: epoch:  769  loss:  49.32395142316818 -- aux loss:  5.951970964670181\n",
      "training: epoch:  770  loss:  49.332703441381454 -- aux loss:  5.951974540948868\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  770  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  771  loss:  49.32686883211136 -- aux loss:  5.951970964670181\n",
      "training: epoch:  772  loss:  49.30603325366974 -- aux loss:  5.951970964670181\n",
      "training: epoch:  773  loss:  49.338828444480896 -- aux loss:  5.951970964670181\n",
      "training: epoch:  774  loss:  49.34545364975929 -- aux loss:  5.952254444360733\n",
      "training: epoch:  775  loss:  49.321883738040924 -- aux loss:  5.951971054077148\n",
      "training: epoch:  776  loss:  49.321769684553146 -- aux loss:  5.9526384472846985\n",
      "training: epoch:  777  loss:  49.31562614440918 -- aux loss:  5.954193979501724\n",
      "training: epoch:  778  loss:  49.315507262945175 -- aux loss:  5.9520226418972015\n",
      "training: epoch:  779  loss:  49.309099823236465 -- aux loss:  5.9519714415073395\n",
      "training: epoch:  780  loss:  49.31938895583153 -- aux loss:  5.956437051296234\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3153512477874756\n",
      "validating: epoch:  780  loss:  0.3153512477874756\n",
      "The current loss: 0.3153512477874756\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  781  loss:  49.32082036137581 -- aux loss:  5.9532131254673\n",
      "training: epoch:  782  loss:  49.30255129933357 -- aux loss:  5.953557968139648\n",
      "training: epoch:  783  loss:  49.316429138183594 -- aux loss:  5.953696608543396\n",
      "training: epoch:  784  loss:  49.30990043282509 -- aux loss:  5.952590823173523\n",
      "training: epoch:  785  loss:  49.32450753450394 -- aux loss:  5.955808728933334\n",
      "training: epoch:  786  loss:  49.30070984363556 -- aux loss:  5.957269906997681\n",
      "training: epoch:  787  loss:  49.29908990859985 -- aux loss:  5.951981216669083\n",
      "training: epoch:  788  loss:  49.29645988345146 -- aux loss:  5.952159494161606\n",
      "training: epoch:  789  loss:  49.300339341163635 -- aux loss:  5.951972097158432\n",
      "training: epoch:  790  loss:  49.30408030748367 -- aux loss:  5.951971024274826\n",
      "the_last_loss:  0.3153512477874756\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  790  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3153512477874756\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  791  loss:  49.30233356356621 -- aux loss:  5.952635437250137\n",
      "training: epoch:  792  loss:  49.297866970300674 -- aux loss:  5.951970964670181\n",
      "training: epoch:  793  loss:  49.29536762833595 -- aux loss:  5.951970994472504\n",
      "training: epoch:  794  loss:  49.3058525621891 -- aux loss:  5.951970964670181\n",
      "training: epoch:  795  loss:  49.32166510820389 -- aux loss:  5.951970994472504\n",
      "training: epoch:  796  loss:  49.32886791229248 -- aux loss:  5.951971024274826\n",
      "training: epoch:  797  loss:  49.335010439157486 -- aux loss:  5.951987057924271\n",
      "training: epoch:  798  loss:  49.32449713349342 -- aux loss:  5.953657448291779\n",
      "training: epoch:  799  loss:  49.303803980350494 -- aux loss:  5.951970964670181\n",
      "training: epoch:  800  loss:  49.31625232100487 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  800  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  801  loss:  49.29536655545235 -- aux loss:  5.951971083879471\n",
      "training: epoch:  802  loss:  49.31188988685608 -- aux loss:  5.95197132229805\n",
      "training: epoch:  803  loss:  49.326824218034744 -- aux loss:  5.951970994472504\n",
      "training: epoch:  804  loss:  49.30266001820564 -- aux loss:  5.951970994472504\n",
      "training: epoch:  805  loss:  49.3015453517437 -- aux loss:  5.951970994472504\n",
      "training: epoch:  806  loss:  49.29595708847046 -- aux loss:  5.951970994472504\n",
      "training: epoch:  807  loss:  49.29974156618118 -- aux loss:  5.951970964670181\n",
      "training: epoch:  808  loss:  49.304860323667526 -- aux loss:  5.952045172452927\n",
      "training: epoch:  809  loss:  49.303854167461395 -- aux loss:  5.951973646879196\n",
      "training: epoch:  810  loss:  49.335091918706894 -- aux loss:  5.951974332332611\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  810  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  811  loss:  49.353062123060226 -- aux loss:  5.951970964670181\n",
      "training: epoch:  812  loss:  49.346958696842194 -- aux loss:  5.951973617076874\n",
      "training: epoch:  813  loss:  49.31509903073311 -- aux loss:  5.951971024274826\n",
      "training: epoch:  814  loss:  49.300247728824615 -- aux loss:  5.953918844461441\n",
      "training: epoch:  815  loss:  49.31285181641579 -- aux loss:  5.952487826347351\n",
      "training: epoch:  816  loss:  49.3081878721714 -- aux loss:  5.951970964670181\n",
      "training: epoch:  817  loss:  49.29928958415985 -- aux loss:  5.951971650123596\n",
      "training: epoch:  818  loss:  49.30781814455986 -- aux loss:  5.951970964670181\n",
      "training: epoch:  819  loss:  49.30992525815964 -- aux loss:  5.951971054077148\n",
      "training: epoch:  820  loss:  49.29701682925224 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326180696487427\n",
      "validating: epoch:  820  loss:  0.31326180696487427\n",
      "The current loss: 0.31326180696487427\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  821  loss:  49.299664914608 -- aux loss:  5.952542930841446\n",
      "training: epoch:  822  loss:  49.29718527197838 -- aux loss:  5.951970964670181\n",
      "training: epoch:  823  loss:  49.29707047343254 -- aux loss:  5.951970964670181\n",
      "training: epoch:  824  loss:  49.305261731147766 -- aux loss:  5.951970994472504\n",
      "training: epoch:  825  loss:  49.300445050001144 -- aux loss:  5.951971143484116\n",
      "training: epoch:  826  loss:  49.30847641825676 -- aux loss:  5.95197132229805\n",
      "training: epoch:  827  loss:  49.33384269475937 -- aux loss:  5.953498959541321\n",
      "training: epoch:  828  loss:  49.32229942083359 -- aux loss:  5.95197257399559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  829  loss:  49.31653395295143 -- aux loss:  5.951970994472504\n",
      "training: epoch:  830  loss:  49.31448581814766 -- aux loss:  5.95197132229805\n",
      "the_last_loss:  0.31326180696487427\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  830  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326180696487427\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  831  loss:  49.302359223365784 -- aux loss:  5.951971709728241\n",
      "training: epoch:  832  loss:  49.29665410518646 -- aux loss:  5.951972037553787\n",
      "training: epoch:  833  loss:  49.29841563105583 -- aux loss:  5.951974242925644\n",
      "training: epoch:  834  loss:  49.29561394453049 -- aux loss:  5.951993703842163\n",
      "training: epoch:  835  loss:  49.295707792043686 -- aux loss:  5.951987594366074\n",
      "training: epoch:  836  loss:  49.297245502471924 -- aux loss:  5.951970964670181\n",
      "training: epoch:  837  loss:  49.307632625103 -- aux loss:  5.951970964670181\n",
      "training: epoch:  838  loss:  49.303212344646454 -- aux loss:  5.95346000790596\n",
      "training: epoch:  839  loss:  49.30777123570442 -- aux loss:  5.953540712594986\n",
      "training: epoch:  840  loss:  49.321586817502975 -- aux loss:  5.9519772827625275\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  840  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  841  loss:  49.3008014857769 -- aux loss:  5.953414022922516\n",
      "training: epoch:  842  loss:  49.29729589819908 -- aux loss:  5.952033251523972\n",
      "training: epoch:  843  loss:  49.29671949148178 -- aux loss:  5.951970964670181\n",
      "training: epoch:  844  loss:  49.332998871803284 -- aux loss:  5.952440112829208\n",
      "training: epoch:  845  loss:  49.30206713080406 -- aux loss:  5.9534521996974945\n",
      "training: epoch:  846  loss:  49.30137223005295 -- aux loss:  5.954479306936264\n",
      "training: epoch:  847  loss:  49.29744076728821 -- aux loss:  5.952021479606628\n",
      "training: epoch:  848  loss:  49.33156242966652 -- aux loss:  5.951970994472504\n",
      "training: epoch:  849  loss:  49.32480338215828 -- aux loss:  5.9524922370910645\n",
      "training: epoch:  850  loss:  49.3032785654068 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  850  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  851  loss:  49.30016049742699 -- aux loss:  5.951970994472504\n",
      "training: epoch:  852  loss:  49.3096039891243 -- aux loss:  5.951971739530563\n",
      "training: epoch:  853  loss:  49.31077802181244 -- aux loss:  5.951970964670181\n",
      "training: epoch:  854  loss:  49.32460889220238 -- aux loss:  5.954785227775574\n",
      "training: epoch:  855  loss:  49.31337329745293 -- aux loss:  5.953465610742569\n",
      "training: epoch:  856  loss:  49.3520093858242 -- aux loss:  5.9579057693481445\n",
      "training: epoch:  857  loss:  49.31245082616806 -- aux loss:  5.9547799825668335\n",
      "training: epoch:  858  loss:  49.30779269337654 -- aux loss:  5.951984912157059\n",
      "training: epoch:  859  loss:  49.29880174994469 -- aux loss:  5.951979845762253\n",
      "training: epoch:  860  loss:  49.29580622911453 -- aux loss:  5.955877363681793\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  860  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  861  loss:  49.295375645160675 -- aux loss:  5.952918767929077\n",
      "training: epoch:  862  loss:  49.29756075143814 -- aux loss:  5.951971143484116\n",
      "training: epoch:  863  loss:  49.301042318344116 -- aux loss:  5.9520865976810455\n",
      "training: epoch:  864  loss:  49.29950371384621 -- aux loss:  5.951970964670181\n",
      "training: epoch:  865  loss:  49.30403754115105 -- aux loss:  5.951970964670181\n",
      "training: epoch:  866  loss:  49.30978348851204 -- aux loss:  5.951970964670181\n",
      "training: epoch:  867  loss:  49.30176794528961 -- aux loss:  5.953401625156403\n",
      "training: epoch:  868  loss:  49.30758383870125 -- aux loss:  5.951973557472229\n",
      "training: epoch:  869  loss:  49.324030458927155 -- aux loss:  5.9519738256931305\n",
      "training: epoch:  870  loss:  49.297931373119354 -- aux loss:  5.951971918344498\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3132699728012085\n",
      "validating: epoch:  870  loss:  0.3132699728012085\n",
      "The current loss: 0.3132699728012085\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  871  loss:  49.313263177871704 -- aux loss:  5.951988965272903\n",
      "training: epoch:  872  loss:  49.316193878650665 -- aux loss:  5.951970964670181\n",
      "training: epoch:  873  loss:  49.308833569288254 -- aux loss:  5.951971739530563\n",
      "training: epoch:  874  loss:  49.31791543960571 -- aux loss:  5.952066510915756\n",
      "training: epoch:  875  loss:  49.321800231933594 -- aux loss:  5.953732937574387\n",
      "training: epoch:  876  loss:  49.30490642786026 -- aux loss:  5.951971024274826\n",
      "training: epoch:  877  loss:  49.305928856134415 -- aux loss:  5.951970964670181\n",
      "training: epoch:  878  loss:  49.299952298402786 -- aux loss:  5.951977998018265\n",
      "training: epoch:  879  loss:  49.296848833560944 -- aux loss:  5.95199579000473\n",
      "training: epoch:  880  loss:  49.29710328578949 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.3132699728012085\n",
      "running_loss_val:  0.31540605425834656\n",
      "validating: epoch:  880  loss:  0.31540605425834656\n",
      "The current loss: 0.31540605425834656\n",
      "the_last_loss: 0.3132699728012085\n",
      "trigger times: 5\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  881  loss:  49.301032304763794 -- aux loss:  5.951978951692581\n",
      "training: epoch:  882  loss:  49.29740345478058 -- aux loss:  5.951970964670181\n",
      "training: epoch:  883  loss:  49.308456897735596 -- aux loss:  5.952552020549774\n",
      "training: epoch:  884  loss:  49.314148128032684 -- aux loss:  5.951970964670181\n",
      "training: epoch:  885  loss:  49.29680335521698 -- aux loss:  5.955875933170319\n",
      "training: epoch:  886  loss:  49.29591381549835 -- aux loss:  5.95197319984436\n",
      "training: epoch:  887  loss:  49.3051922917366 -- aux loss:  5.953450113534927\n",
      "training: epoch:  888  loss:  49.33381950855255 -- aux loss:  5.954101890325546\n",
      "training: epoch:  889  loss:  49.319900542497635 -- aux loss:  5.95517960190773\n",
      "training: epoch:  890  loss:  49.331181317567825 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31540605425834656\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  890  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31540605425834656\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  891  loss:  49.30699363350868 -- aux loss:  5.951970964670181\n",
      "training: epoch:  892  loss:  49.29880130290985 -- aux loss:  5.951970964670181\n",
      "training: epoch:  893  loss:  49.31373572349548 -- aux loss:  5.952278882265091\n",
      "training: epoch:  894  loss:  49.308066576719284 -- aux loss:  5.951990216970444\n",
      "training: epoch:  895  loss:  49.30546808242798 -- aux loss:  5.951970964670181\n",
      "training: epoch:  896  loss:  49.32839968800545 -- aux loss:  5.951970964670181\n",
      "training: epoch:  897  loss:  49.313358187675476 -- aux loss:  5.953175961971283\n",
      "training: epoch:  898  loss:  49.31537199020386 -- aux loss:  5.9534540474414825\n",
      "training: epoch:  899  loss:  49.29980644583702 -- aux loss:  5.951970994472504\n",
      "training: epoch:  900  loss:  49.299602180719376 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  900  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  901  loss:  49.30383512377739 -- aux loss:  5.951970964670181\n",
      "training: epoch:  902  loss:  49.31164667010307 -- aux loss:  5.951970964670181\n",
      "training: epoch:  903  loss:  49.3124004304409 -- aux loss:  5.951970964670181\n",
      "training: epoch:  904  loss:  49.299706280231476 -- aux loss:  5.95338961482048\n",
      "training: epoch:  905  loss:  49.30550229549408 -- aux loss:  5.9519712924957275\n",
      "training: epoch:  906  loss:  49.31565022468567 -- aux loss:  5.956339985132217\n",
      "training: epoch:  907  loss:  49.29898875951767 -- aux loss:  5.953841477632523\n",
      "training: epoch:  908  loss:  49.30240985751152 -- aux loss:  5.951971054077148\n",
      "training: epoch:  909  loss:  49.30376839637756 -- aux loss:  5.951971054077148\n",
      "training: epoch:  910  loss:  49.297893434762955 -- aux loss:  5.951970994472504\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3132616877555847\n",
      "validating: epoch:  910  loss:  0.3132616877555847\n",
      "The current loss: 0.3132616877555847\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  911  loss:  49.3253630399704 -- aux loss:  5.951971054077148\n",
      "training: epoch:  912  loss:  49.31656190752983 -- aux loss:  5.9533595740795135\n",
      "training: epoch:  913  loss:  49.319219678640366 -- aux loss:  5.951970964670181\n",
      "training: epoch:  914  loss:  49.30365565419197 -- aux loss:  5.953657627105713\n",
      "training: epoch:  915  loss:  49.32532224059105 -- aux loss:  5.954076558351517\n",
      "training: epoch:  916  loss:  49.315091371536255 -- aux loss:  5.955829828977585\n",
      "training: epoch:  917  loss:  49.31474384665489 -- aux loss:  5.951970964670181\n",
      "training: epoch:  918  loss:  49.30865079164505 -- aux loss:  5.951970964670181\n",
      "training: epoch:  919  loss:  49.296796679496765 -- aux loss:  5.951970964670181\n",
      "training: epoch:  920  loss:  49.31314814090729 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.3132616877555847\n",
      "running_loss_val:  0.31331801414489746\n",
      "validating: epoch:  920  loss:  0.31331801414489746\n",
      "The current loss: 0.31331801414489746\n",
      "the_last_loss: 0.3132616877555847\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  921  loss:  49.297373324632645 -- aux loss:  5.951970964670181\n",
      "training: epoch:  922  loss:  49.29572305083275 -- aux loss:  5.951970964670181\n",
      "training: epoch:  923  loss:  49.323354959487915 -- aux loss:  5.951970964670181\n",
      "training: epoch:  924  loss:  49.31155902147293 -- aux loss:  5.9519718289375305\n",
      "training: epoch:  925  loss:  49.29942658543587 -- aux loss:  5.951970964670181\n",
      "training: epoch:  926  loss:  49.29720398783684 -- aux loss:  5.951970964670181\n",
      "training: epoch:  927  loss:  49.324108600616455 -- aux loss:  5.954433381557465\n",
      "training: epoch:  928  loss:  49.313879162073135 -- aux loss:  5.953732132911682\n",
      "training: epoch:  929  loss:  49.31057679653168 -- aux loss:  5.9520998895168304\n",
      "training: epoch:  930  loss:  49.31504634022713 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31331801414489746\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  930  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31331801414489746\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  931  loss:  49.308452010154724 -- aux loss:  5.951970964670181\n",
      "training: epoch:  932  loss:  49.30985361337662 -- aux loss:  5.951979070901871\n",
      "training: epoch:  933  loss:  49.31517559289932 -- aux loss:  5.952705591917038\n",
      "training: epoch:  934  loss:  49.30559131503105 -- aux loss:  5.956129103899002\n",
      "training: epoch:  935  loss:  49.33610734343529 -- aux loss:  5.952289581298828\n",
      "training: epoch:  936  loss:  49.33747601509094 -- aux loss:  5.951970964670181\n",
      "training: epoch:  937  loss:  49.29710340499878 -- aux loss:  5.9528027176856995\n",
      "training: epoch:  938  loss:  49.298262536525726 -- aux loss:  5.951970964670181\n",
      "training: epoch:  939  loss:  49.30561998486519 -- aux loss:  5.951971024274826\n",
      "training: epoch:  940  loss:  49.317877769470215 -- aux loss:  5.951986908912659\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31540846824645996\n",
      "validating: epoch:  940  loss:  0.31540846824645996\n",
      "The current loss: 0.31540846824645996\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  941  loss:  49.33834370970726 -- aux loss:  5.951970964670181\n",
      "training: epoch:  942  loss:  49.303348153829575 -- aux loss:  5.951970964670181\n",
      "training: epoch:  943  loss:  49.300508201122284 -- aux loss:  5.951970994472504\n",
      "training: epoch:  944  loss:  49.335539072752 -- aux loss:  5.951997518539429\n",
      "training: epoch:  945  loss:  49.30378895998001 -- aux loss:  5.971560060977936\n",
      "training: epoch:  946  loss:  49.30740749835968 -- aux loss:  5.954335659742355\n",
      "training: epoch:  947  loss:  49.30088150501251 -- aux loss:  5.951970964670181\n",
      "training: epoch:  948  loss:  49.302499294281006 -- aux loss:  5.951970964670181\n",
      "training: epoch:  949  loss:  49.30412834882736 -- aux loss:  5.951970964670181\n",
      "training: epoch:  950  loss:  49.33177134394646 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31540846824645996\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  950  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31540846824645996\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  951  loss:  49.317150950431824 -- aux loss:  5.953105837106705\n",
      "training: epoch:  952  loss:  49.30183187127113 -- aux loss:  5.951971471309662\n",
      "training: epoch:  953  loss:  49.307554960250854 -- aux loss:  5.951972216367722\n",
      "training: epoch:  954  loss:  49.30597162246704 -- aux loss:  5.952001631259918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  955  loss:  49.301567792892456 -- aux loss:  5.951970964670181\n",
      "training: epoch:  956  loss:  49.31779092550278 -- aux loss:  5.951970964670181\n",
      "training: epoch:  957  loss:  49.32216939330101 -- aux loss:  5.951971739530563\n",
      "training: epoch:  958  loss:  49.30278703570366 -- aux loss:  5.9584746062755585\n",
      "training: epoch:  959  loss:  49.30387753248215 -- aux loss:  5.957281619310379\n",
      "training: epoch:  960  loss:  49.29595109820366 -- aux loss:  5.952810555696487\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  960  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  961  loss:  49.29581180214882 -- aux loss:  5.963359355926514\n",
      "training: epoch:  962  loss:  49.33918523788452 -- aux loss:  5.951970964670181\n",
      "training: epoch:  963  loss:  49.30406466126442 -- aux loss:  5.951981842517853\n",
      "training: epoch:  964  loss:  49.2953662276268 -- aux loss:  5.951971143484116\n",
      "training: epoch:  965  loss:  49.30261504650116 -- aux loss:  5.952267020940781\n",
      "training: epoch:  966  loss:  49.31232863664627 -- aux loss:  5.9519765973091125\n",
      "training: epoch:  967  loss:  49.30012369155884 -- aux loss:  5.951970964670181\n",
      "training: epoch:  968  loss:  49.29743933677673 -- aux loss:  5.951970964670181\n",
      "training: epoch:  969  loss:  49.2953699529171 -- aux loss:  5.951970964670181\n",
      "training: epoch:  970  loss:  49.29674145579338 -- aux loss:  5.952104806900024\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  970  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  971  loss:  49.32727888226509 -- aux loss:  5.952700555324554\n",
      "training: epoch:  972  loss:  49.314068377017975 -- aux loss:  5.951970964670181\n",
      "training: epoch:  973  loss:  49.30348399281502 -- aux loss:  5.951970964670181\n",
      "training: epoch:  974  loss:  49.3004512488842 -- aux loss:  5.951970964670181\n",
      "training: epoch:  975  loss:  49.3127838075161 -- aux loss:  5.952008932828903\n",
      "training: epoch:  976  loss:  49.29800298810005 -- aux loss:  5.951970964670181\n",
      "training: epoch:  977  loss:  49.29905357956886 -- aux loss:  5.951970964670181\n",
      "training: epoch:  978  loss:  49.338093250989914 -- aux loss:  5.961538016796112\n",
      "training: epoch:  979  loss:  49.301753491163254 -- aux loss:  5.95339161157608\n",
      "training: epoch:  980  loss:  49.31005507707596 -- aux loss:  5.953432232141495\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  980  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  981  loss:  49.325809985399246 -- aux loss:  5.951970964670181\n",
      "training: epoch:  982  loss:  49.30668380856514 -- aux loss:  5.952633053064346\n",
      "training: epoch:  983  loss:  49.3093478679657 -- aux loss:  5.951970994472504\n",
      "training: epoch:  984  loss:  49.30864682793617 -- aux loss:  5.951970964670181\n",
      "training: epoch:  985  loss:  49.299366503953934 -- aux loss:  5.951970994472504\n",
      "training: epoch:  986  loss:  49.31455954909325 -- aux loss:  5.951970994472504\n",
      "training: epoch:  987  loss:  49.363339960575104 -- aux loss:  5.95209726691246\n",
      "training: epoch:  988  loss:  49.33204174041748 -- aux loss:  5.951970964670181\n",
      "training: epoch:  989  loss:  49.30329966545105 -- aux loss:  5.952120095491409\n",
      "training: epoch:  990  loss:  49.2979097366333 -- aux loss:  5.953530013561249\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  990  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  991  loss:  49.295773446559906 -- aux loss:  5.952080249786377\n",
      "training: epoch:  992  loss:  49.29740223288536 -- aux loss:  5.953478991985321\n",
      "training: epoch:  993  loss:  49.29689285159111 -- aux loss:  5.951970964670181\n",
      "training: epoch:  994  loss:  49.299273401498795 -- aux loss:  5.951970964670181\n",
      "training: epoch:  995  loss:  49.29597306251526 -- aux loss:  5.951970994472504\n",
      "training: epoch:  996  loss:  49.29544743895531 -- aux loss:  5.951970964670181\n",
      "training: epoch:  997  loss:  49.29613795876503 -- aux loss:  5.951970964670181\n",
      "training: epoch:  998  loss:  49.29547107219696 -- aux loss:  5.951970964670181\n",
      "training: epoch:  999  loss:  49.3129478096962 -- aux loss:  5.9534421265125275\n",
      "training: epoch:  1000  loss:  49.310844004154205 -- aux loss:  5.951980173587799\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1000  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1001  loss:  49.3043712079525 -- aux loss:  5.953448414802551\n",
      "training: epoch:  1002  loss:  49.337481528520584 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1003  loss:  49.313948571681976 -- aux loss:  5.953504115343094\n",
      "training: epoch:  1004  loss:  49.31883496046066 -- aux loss:  5.953946471214294\n",
      "training: epoch:  1005  loss:  49.324652284383774 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1006  loss:  49.304231971502304 -- aux loss:  5.951975107192993\n",
      "training: epoch:  1007  loss:  49.3000051677227 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1008  loss:  49.30148956179619 -- aux loss:  5.952045828104019\n",
      "training: epoch:  1009  loss:  49.301906526088715 -- aux loss:  5.952071666717529\n",
      "training: epoch:  1010  loss:  49.30583941936493 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1010  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1011  loss:  49.34962520003319 -- aux loss:  5.954935818910599\n",
      "training: epoch:  1012  loss:  49.30588722229004 -- aux loss:  5.951990932226181\n",
      "training: epoch:  1013  loss:  49.300692051649094 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1014  loss:  49.32369539141655 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1015  loss:  49.30253937840462 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1016  loss:  49.302639812231064 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1017  loss:  49.295573353767395 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1018  loss:  49.310176342725754 -- aux loss:  5.951970964670181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1019  loss:  49.38538148999214 -- aux loss:  5.9519714415073395\n",
      "training: epoch:  1020  loss:  49.31202632188797 -- aux loss:  5.951970994472504\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3150889575481415\n",
      "validating: epoch:  1020  loss:  0.3150889575481415\n",
      "The current loss: 0.3150889575481415\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1021  loss:  49.30421060323715 -- aux loss:  5.951975584030151\n",
      "training: epoch:  1022  loss:  49.31506124138832 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1023  loss:  49.31388118863106 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1024  loss:  49.29807910323143 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1025  loss:  49.30055356025696 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1026  loss:  49.2954186797142 -- aux loss:  5.952971190214157\n",
      "training: epoch:  1027  loss:  49.304780930280685 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1028  loss:  49.320158034563065 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1029  loss:  49.32052171230316 -- aux loss:  5.956552058458328\n",
      "training: epoch:  1030  loss:  49.30499130487442 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.3150889575481415\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1030  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3150889575481415\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1031  loss:  49.30149617791176 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1032  loss:  49.304146856069565 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1033  loss:  49.315083622932434 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1034  loss:  49.29567167162895 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1035  loss:  49.29724386334419 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1036  loss:  49.295857310295105 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1037  loss:  49.29593840241432 -- aux loss:  5.9519712924957275\n",
      "training: epoch:  1038  loss:  49.2994187772274 -- aux loss:  5.953245520591736\n",
      "training: epoch:  1039  loss:  49.29548513889313 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1040  loss:  49.29729896783829 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.315571665763855\n",
      "validating: epoch:  1040  loss:  0.315571665763855\n",
      "The current loss: 0.315571665763855\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1041  loss:  49.309996753931046 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1042  loss:  49.30210891366005 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1043  loss:  49.29900377988815 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1044  loss:  49.31210371851921 -- aux loss:  5.951986640691757\n",
      "training: epoch:  1045  loss:  49.304062247276306 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1046  loss:  49.300766319036484 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1047  loss:  49.30826371908188 -- aux loss:  5.953623443841934\n",
      "training: epoch:  1048  loss:  49.29712951183319 -- aux loss:  5.952846169471741\n",
      "training: epoch:  1049  loss:  49.297320395708084 -- aux loss:  5.951992630958557\n",
      "training: epoch:  1050  loss:  49.30543667078018 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.315571665763855\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  1050  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.315571665763855\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1051  loss:  49.3082774579525 -- aux loss:  5.951999098062515\n",
      "training: epoch:  1052  loss:  49.31438520550728 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1053  loss:  49.30567720532417 -- aux loss:  5.958801984786987\n",
      "training: epoch:  1054  loss:  49.30299672484398 -- aux loss:  5.952097237110138\n",
      "training: epoch:  1055  loss:  49.303178280591965 -- aux loss:  5.951982885599136\n",
      "training: epoch:  1056  loss:  49.2994322180748 -- aux loss:  5.951971173286438\n",
      "training: epoch:  1057  loss:  49.331407964229584 -- aux loss:  5.958753317594528\n",
      "training: epoch:  1058  loss:  49.31471610069275 -- aux loss:  5.954612344503403\n",
      "training: epoch:  1059  loss:  49.30067455768585 -- aux loss:  5.953105181455612\n",
      "training: epoch:  1060  loss:  49.30334144830704 -- aux loss:  5.953738838434219\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1060  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1061  loss:  49.32159298658371 -- aux loss:  5.954866737127304\n",
      "training: epoch:  1062  loss:  49.3027882874012 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1063  loss:  49.3047094643116 -- aux loss:  5.955245405435562\n",
      "training: epoch:  1064  loss:  49.3007755279541 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1065  loss:  49.300656884908676 -- aux loss:  5.952340662479401\n",
      "training: epoch:  1066  loss:  49.295494556427 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1067  loss:  49.296547651290894 -- aux loss:  5.951988071203232\n",
      "training: epoch:  1068  loss:  49.30300781130791 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1069  loss:  49.29537373781204 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1070  loss:  49.30012673139572 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3288660943508148\n",
      "validating: epoch:  1070  loss:  0.3288660943508148\n",
      "The current loss: 0.3288660943508148\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1071  loss:  49.29950615763664 -- aux loss:  5.958351224660873\n",
      "training: epoch:  1072  loss:  49.30007991194725 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1073  loss:  49.30786466598511 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1074  loss:  49.29875126481056 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1075  loss:  49.29796251654625 -- aux loss:  5.951972603797913\n",
      "training: epoch:  1076  loss:  49.29936993122101 -- aux loss:  5.953454911708832\n",
      "training: epoch:  1077  loss:  49.305242478847504 -- aux loss:  5.954934000968933\n",
      "training: epoch:  1078  loss:  49.32031485438347 -- aux loss:  5.952073752880096\n",
      "training: epoch:  1079  loss:  49.307874858379364 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1080  loss:  49.301093846559525 -- aux loss:  5.9534390568733215\n",
      "the_last_loss:  0.3288660943508148\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  1080  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.3288660943508148\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1081  loss:  49.3210728764534 -- aux loss:  5.951971530914307\n",
      "training: epoch:  1082  loss:  49.343472480773926 -- aux loss:  5.954673379659653\n",
      "training: epoch:  1083  loss:  49.31194460391998 -- aux loss:  5.953455179929733\n",
      "training: epoch:  1084  loss:  49.31547263264656 -- aux loss:  5.954403936862946\n",
      "training: epoch:  1085  loss:  49.30346414446831 -- aux loss:  5.951971054077148\n",
      "training: epoch:  1086  loss:  49.32292765378952 -- aux loss:  5.952145665884018\n",
      "training: epoch:  1087  loss:  49.31190922856331 -- aux loss:  5.952561736106873\n",
      "training: epoch:  1088  loss:  49.31204813718796 -- aux loss:  5.952972859144211\n",
      "training: epoch:  1089  loss:  49.30631756782532 -- aux loss:  5.951971501111984\n",
      "training: epoch:  1090  loss:  49.30373227596283 -- aux loss:  5.951971143484116\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.3132709562778473\n",
      "validating: epoch:  1090  loss:  0.3132709562778473\n",
      "The current loss: 0.3132709562778473\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1091  loss:  49.315927892923355 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1092  loss:  49.30435973405838 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1093  loss:  49.295522302389145 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1094  loss:  49.30830097198486 -- aux loss:  5.951971262693405\n",
      "training: epoch:  1095  loss:  49.30556267499924 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1096  loss:  49.29702207446098 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1097  loss:  49.2953616976738 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1098  loss:  49.30458804965019 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1099  loss:  49.32374542951584 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1100  loss:  49.30117726325989 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.3132709562778473\n",
      "running_loss_val:  0.3132616877555847\n",
      "validating: epoch:  1100  loss:  0.3132616877555847\n",
      "The current loss: 0.3132616877555847\n",
      "the_last_loss: 0.3132709562778473\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1101  loss:  49.30315601825714 -- aux loss:  5.953448861837387\n",
      "training: epoch:  1102  loss:  49.30924978852272 -- aux loss:  5.954456210136414\n",
      "training: epoch:  1103  loss:  49.3000753223896 -- aux loss:  5.953453838825226\n",
      "training: epoch:  1104  loss:  49.30212131142616 -- aux loss:  5.9535737335681915\n",
      "training: epoch:  1105  loss:  49.29770702123642 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1106  loss:  49.29746529459953 -- aux loss:  5.954011559486389\n",
      "training: epoch:  1107  loss:  49.30515718460083 -- aux loss:  5.951971143484116\n",
      "training: epoch:  1108  loss:  49.32964417338371 -- aux loss:  5.952012658119202\n",
      "training: epoch:  1109  loss:  49.308561354875565 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1110  loss:  49.3000690639019 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.3132616877555847\n",
      "running_loss_val:  0.3163168728351593\n",
      "validating: epoch:  1110  loss:  0.3163168728351593\n",
      "The current loss: 0.3163168728351593\n",
      "the_last_loss: 0.3132616877555847\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1111  loss:  49.296814769506454 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1112  loss:  49.296817660331726 -- aux loss:  5.951971739530563\n",
      "training: epoch:  1113  loss:  49.30126655101776 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1114  loss:  49.30084192752838 -- aux loss:  5.951972842216492\n",
      "training: epoch:  1115  loss:  49.297003626823425 -- aux loss:  5.953452795743942\n",
      "training: epoch:  1116  loss:  49.29752418398857 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1117  loss:  49.30492156744003 -- aux loss:  5.952851980924606\n",
      "training: epoch:  1118  loss:  49.3196180164814 -- aux loss:  5.955832272768021\n",
      "training: epoch:  1119  loss:  49.317476600408554 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1120  loss:  49.301866948604584 -- aux loss:  5.953610867261887\n",
      "the_last_loss:  0.3163168728351593\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1120  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3163168728351593\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1121  loss:  49.2991027534008 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1122  loss:  49.295364290475845 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1123  loss:  49.29679948091507 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1124  loss:  49.29684820771217 -- aux loss:  5.9520043432712555\n",
      "training: epoch:  1125  loss:  49.295367658138275 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1126  loss:  49.36112064123154 -- aux loss:  5.992871820926666\n",
      "training: epoch:  1127  loss:  49.31685796380043 -- aux loss:  5.954939991235733\n",
      "training: epoch:  1128  loss:  49.31579625606537 -- aux loss:  5.957105308771133\n",
      "training: epoch:  1129  loss:  49.30180233716965 -- aux loss:  5.9536353051662445\n",
      "training: epoch:  1130  loss:  49.30828130245209 -- aux loss:  5.9574815928936005\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1130  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1131  loss:  49.310420989990234 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1132  loss:  49.32196816802025 -- aux loss:  5.9519785940647125\n",
      "training: epoch:  1133  loss:  49.31481513381004 -- aux loss:  5.953478157520294\n",
      "training: epoch:  1134  loss:  49.311941266059875 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1135  loss:  49.30579650402069 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1136  loss:  49.29814863204956 -- aux loss:  5.951973557472229\n",
      "training: epoch:  1137  loss:  49.30819234251976 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1138  loss:  49.307470351457596 -- aux loss:  5.951971352100372\n",
      "training: epoch:  1139  loss:  49.30278566479683 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1140  loss:  49.29915243387222 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  1140  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1141  loss:  49.29550126194954 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1142  loss:  49.30042806267738 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1143  loss:  49.3019976913929 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1144  loss:  49.313491970300674 -- aux loss:  5.951970964670181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1145  loss:  49.32570534944534 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1146  loss:  49.29788213968277 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1147  loss:  49.30223071575165 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1148  loss:  49.29661679267883 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1149  loss:  49.30222538113594 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1150  loss:  49.29888904094696 -- aux loss:  5.951980471611023\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1150  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1151  loss:  49.309916615486145 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1152  loss:  49.33503746986389 -- aux loss:  5.952086836099625\n",
      "training: epoch:  1153  loss:  49.30719757080078 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1154  loss:  49.29540678858757 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1155  loss:  49.29597023129463 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1156  loss:  49.31051388382912 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1157  loss:  49.32348281145096 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1158  loss:  49.31402799487114 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1159  loss:  49.307572722435 -- aux loss:  5.953168421983719\n",
      "training: epoch:  1160  loss:  49.303148448467255 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1160  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1161  loss:  49.301742017269135 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1162  loss:  49.304910093545914 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1163  loss:  49.303165316581726 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1164  loss:  49.308831572532654 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1165  loss:  49.296792805194855 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1166  loss:  49.30470219254494 -- aux loss:  5.952034056186676\n",
      "training: epoch:  1167  loss:  49.29856985807419 -- aux loss:  5.951980262994766\n",
      "training: epoch:  1168  loss:  49.302616596221924 -- aux loss:  5.951971352100372\n",
      "training: epoch:  1169  loss:  49.300964027643204 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1170  loss:  49.317531645298004 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1170  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1171  loss:  49.30733686685562 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1172  loss:  49.30050215125084 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1173  loss:  49.29894548654556 -- aux loss:  5.9520004987716675\n",
      "training: epoch:  1174  loss:  49.306982189416885 -- aux loss:  5.952316373586655\n",
      "training: epoch:  1175  loss:  49.31353071331978 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1176  loss:  49.30642867088318 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1177  loss:  49.29850152134895 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1178  loss:  49.292972564697266 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1179  loss:  49.32871901988983 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1180  loss:  49.327666252851486 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1180  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1181  loss:  49.31408101320267 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1182  loss:  49.31209897994995 -- aux loss:  5.953029662370682\n",
      "training: epoch:  1183  loss:  49.31346908211708 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1184  loss:  49.29776009917259 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1185  loss:  49.300401985645294 -- aux loss:  5.953446239233017\n",
      "training: epoch:  1186  loss:  49.30310046672821 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1187  loss:  49.31088402867317 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1188  loss:  49.294379740953445 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1189  loss:  49.31016141176224 -- aux loss:  5.951971054077148\n",
      "training: epoch:  1190  loss:  49.32361710071564 -- aux loss:  5.951970994472504\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  1190  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1191  loss:  49.31986355781555 -- aux loss:  5.951973021030426\n",
      "training: epoch:  1192  loss:  49.30605399608612 -- aux loss:  5.951971054077148\n",
      "training: epoch:  1193  loss:  49.3156424164772 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1194  loss:  49.29979380965233 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1195  loss:  49.291727900505066 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1196  loss:  49.300443053245544 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1197  loss:  49.29808819293976 -- aux loss:  5.951971501111984\n",
      "training: epoch:  1198  loss:  49.29791370034218 -- aux loss:  5.951974093914032\n",
      "training: epoch:  1199  loss:  49.30342420935631 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1200  loss:  49.294902950525284 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1200  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1201  loss:  49.29187625646591 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1202  loss:  49.29295837879181 -- aux loss:  5.951971054077148\n",
      "training: epoch:  1203  loss:  49.2973769903183 -- aux loss:  5.953454911708832\n",
      "training: epoch:  1204  loss:  49.29842323064804 -- aux loss:  5.953427225351334\n",
      "training: epoch:  1205  loss:  49.291458517313 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1206  loss:  49.296990394592285 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1207  loss:  49.30277958512306 -- aux loss:  5.954004883766174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1208  loss:  49.2922445833683 -- aux loss:  5.951971352100372\n",
      "training: epoch:  1209  loss:  49.303370267152786 -- aux loss:  5.952847480773926\n",
      "training: epoch:  1210  loss:  49.31828501820564 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1210  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1211  loss:  49.299402356147766 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1212  loss:  49.2939767241478 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1213  loss:  49.31140583753586 -- aux loss:  5.951971590518951\n",
      "training: epoch:  1214  loss:  49.29676714539528 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1215  loss:  49.30153578519821 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1216  loss:  49.29541638493538 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1217  loss:  49.29656746983528 -- aux loss:  5.951971113681793\n",
      "training: epoch:  1218  loss:  49.346365720033646 -- aux loss:  5.955692410469055\n",
      "training: epoch:  1219  loss:  49.3019058406353 -- aux loss:  5.951992928981781\n",
      "training: epoch:  1220  loss:  49.29467275738716 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31327304244041443\n",
      "validating: epoch:  1220  loss:  0.31327304244041443\n",
      "The current loss: 0.31327304244041443\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1221  loss:  49.29151892662048 -- aux loss:  5.951986610889435\n",
      "training: epoch:  1222  loss:  49.292253375053406 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1223  loss:  49.29147484898567 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1224  loss:  49.30283737182617 -- aux loss:  5.9554232358932495\n",
      "training: epoch:  1225  loss:  49.325835049152374 -- aux loss:  5.954585373401642\n",
      "training: epoch:  1226  loss:  49.300983518362045 -- aux loss:  5.951972216367722\n",
      "training: epoch:  1227  loss:  49.291919499635696 -- aux loss:  5.951971352100372\n",
      "training: epoch:  1228  loss:  49.294265389442444 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1229  loss:  49.29299086332321 -- aux loss:  5.951972037553787\n",
      "training: epoch:  1230  loss:  49.291904389858246 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31327304244041443\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  1230  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.31327304244041443\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1231  loss:  49.30525702238083 -- aux loss:  6.055167227983475\n",
      "training: epoch:  1232  loss:  49.3079474568367 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1233  loss:  49.30896615982056 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1234  loss:  49.30572712421417 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1235  loss:  49.32650810480118 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1236  loss:  49.30470362305641 -- aux loss:  5.957361161708832\n",
      "training: epoch:  1237  loss:  49.30076736211777 -- aux loss:  5.953454852104187\n",
      "training: epoch:  1238  loss:  49.312021881341934 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1239  loss:  49.30076876282692 -- aux loss:  5.953455299139023\n",
      "training: epoch:  1240  loss:  49.29687339067459 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31891125440597534\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1240  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891125440597534\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1241  loss:  49.29884150624275 -- aux loss:  5.951972216367722\n",
      "training: epoch:  1242  loss:  49.295729488134384 -- aux loss:  5.952430009841919\n",
      "training: epoch:  1243  loss:  49.304125279188156 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1244  loss:  49.31492134928703 -- aux loss:  5.953432381153107\n",
      "training: epoch:  1245  loss:  49.29957774281502 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1246  loss:  49.29193937778473 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1247  loss:  49.29565009474754 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1248  loss:  49.2947638630867 -- aux loss:  5.953467100858688\n",
      "training: epoch:  1249  loss:  49.30441978573799 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1250  loss:  49.29154595732689 -- aux loss:  5.951970994472504\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1250  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1251  loss:  49.296743243932724 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1252  loss:  49.32680270075798 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1253  loss:  49.29869058728218 -- aux loss:  5.95345476269722\n",
      "training: epoch:  1254  loss:  49.31098321080208 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1255  loss:  49.29674610495567 -- aux loss:  5.953466981649399\n",
      "training: epoch:  1256  loss:  49.29665631055832 -- aux loss:  5.952810049057007\n",
      "training: epoch:  1257  loss:  49.31572246551514 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1258  loss:  49.311022371053696 -- aux loss:  5.951973497867584\n",
      "training: epoch:  1259  loss:  49.30074808001518 -- aux loss:  5.955982357263565\n",
      "training: epoch:  1260  loss:  49.313072979450226 -- aux loss:  5.951973468065262\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326353549957275\n",
      "validating: epoch:  1260  loss:  0.31326353549957275\n",
      "The current loss: 0.31326353549957275\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1261  loss:  49.303121238946915 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1262  loss:  49.303221970796585 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1263  loss:  49.30767351388931 -- aux loss:  5.953446537256241\n",
      "training: epoch:  1264  loss:  49.29243865609169 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1265  loss:  49.291392773389816 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1266  loss:  49.29190519452095 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1267  loss:  49.29564547538757 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1268  loss:  49.29137644171715 -- aux loss:  5.951971113681793\n",
      "training: epoch:  1269  loss:  49.30733013153076 -- aux loss:  5.953403264284134\n",
      "training: epoch:  1270  loss:  49.29576563835144 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326353549957275\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1270  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326353549957275\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1271  loss:  49.29160872101784 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1272  loss:  49.29441174864769 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1273  loss:  49.29145374894142 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1274  loss:  49.30193141102791 -- aux loss:  5.951975345611572\n",
      "training: epoch:  1275  loss:  49.33631759881973 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1276  loss:  49.303616553545 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1277  loss:  49.29568362236023 -- aux loss:  5.957079648971558\n",
      "training: epoch:  1278  loss:  49.31065449118614 -- aux loss:  5.955865859985352\n",
      "training: epoch:  1279  loss:  49.3060427904129 -- aux loss:  5.951971113681793\n",
      "training: epoch:  1280  loss:  49.29992213845253 -- aux loss:  5.951971173286438\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1280  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1281  loss:  49.29679951071739 -- aux loss:  5.952195078134537\n",
      "training: epoch:  1282  loss:  49.30196264386177 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1283  loss:  49.29511457681656 -- aux loss:  5.95406574010849\n",
      "training: epoch:  1284  loss:  49.308651596307755 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1285  loss:  49.3215189576149 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1286  loss:  49.32723197340965 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1287  loss:  49.31630501151085 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1288  loss:  49.294376224279404 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1289  loss:  49.29741019010544 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1290  loss:  49.29681420326233 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1290  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1291  loss:  49.309072613716125 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1292  loss:  49.294353008270264 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1293  loss:  49.29548969864845 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1294  loss:  49.292349964380264 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1295  loss:  49.2936007976532 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1296  loss:  49.29211524128914 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1297  loss:  49.293173760175705 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1298  loss:  49.314980655908585 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1299  loss:  49.30256175994873 -- aux loss:  5.955958813428879\n",
      "training: epoch:  1300  loss:  49.29939264059067 -- aux loss:  5.952471107244492\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1300  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1301  loss:  49.30468273162842 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1302  loss:  49.29566910862923 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1303  loss:  49.29297459125519 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1304  loss:  49.30182695388794 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1305  loss:  49.28755906224251 -- aux loss:  5.952794462442398\n",
      "training: epoch:  1306  loss:  49.28869193792343 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1307  loss:  49.31317153573036 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1308  loss:  49.290331572294235 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1309  loss:  49.305141031742096 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1310  loss:  49.300748735666275 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1310  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1311  loss:  49.293221205472946 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1312  loss:  49.28795200586319 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1313  loss:  49.29128688573837 -- aux loss:  5.95197120308876\n",
      "training: epoch:  1314  loss:  49.30917942523956 -- aux loss:  5.953406602144241\n",
      "training: epoch:  1315  loss:  49.299818962812424 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1316  loss:  49.313888639211655 -- aux loss:  5.951971054077148\n",
      "training: epoch:  1317  loss:  49.289038479328156 -- aux loss:  5.9526567459106445\n",
      "training: epoch:  1318  loss:  49.30066329240799 -- aux loss:  5.954318135976791\n",
      "training: epoch:  1319  loss:  49.28958708047867 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1320  loss:  49.29457578063011 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1320  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 5\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1321  loss:  49.30089098215103 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1322  loss:  49.29401385784149 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1323  loss:  49.30027797818184 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1324  loss:  49.318696200847626 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1325  loss:  49.30826976895332 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1326  loss:  49.29359048604965 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1327  loss:  49.29198458790779 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1328  loss:  49.294974982738495 -- aux loss:  5.951972872018814\n",
      "training: epoch:  1329  loss:  49.28963789343834 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1330  loss:  49.29463490843773 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891128420829773\n",
      "validating: epoch:  1330  loss:  0.31891128420829773\n",
      "The current loss: 0.31891128420829773\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 6\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1331  loss:  49.29077082872391 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1332  loss:  49.2954221367836 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1333  loss:  49.29146295785904 -- aux loss:  5.951970964670181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1334  loss:  49.29160684347153 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1335  loss:  49.28890374302864 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1336  loss:  49.291494369506836 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1337  loss:  49.28921088576317 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1338  loss:  49.30595490336418 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1339  loss:  49.292356848716736 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1340  loss:  49.294190406799316 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31891128420829773\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1340  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891128420829773\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1341  loss:  49.29599595069885 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1342  loss:  49.297198325395584 -- aux loss:  5.953256547451019\n",
      "training: epoch:  1343  loss:  49.29528418183327 -- aux loss:  5.954633176326752\n",
      "training: epoch:  1344  loss:  49.305969178676605 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1345  loss:  49.31840538978577 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1346  loss:  49.31094151735306 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1347  loss:  49.300387352705 -- aux loss:  5.951971262693405\n",
      "training: epoch:  1348  loss:  49.292789459228516 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1349  loss:  49.29318231344223 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1350  loss:  49.28805419802666 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1350  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1351  loss:  49.28778791427612 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1352  loss:  49.29792773723602 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1353  loss:  49.30061915516853 -- aux loss:  5.954052984714508\n",
      "training: epoch:  1354  loss:  49.29292634129524 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1355  loss:  49.2907809317112 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1356  loss:  49.299218744039536 -- aux loss:  5.952935010194778\n",
      "training: epoch:  1357  loss:  49.28910434246063 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1358  loss:  49.298790246248245 -- aux loss:  5.9519718289375305\n",
      "training: epoch:  1359  loss:  49.296783447265625 -- aux loss:  5.953326404094696\n",
      "training: epoch:  1360  loss:  49.31172654032707 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1360  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1361  loss:  49.32976144552231 -- aux loss:  5.952149957418442\n",
      "training: epoch:  1362  loss:  49.30740666389465 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1363  loss:  49.30499118566513 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1364  loss:  49.29186072945595 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1365  loss:  49.289421290159225 -- aux loss:  5.952014923095703\n",
      "training: epoch:  1366  loss:  49.288945853710175 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1367  loss:  49.30972668528557 -- aux loss:  5.955331206321716\n",
      "training: epoch:  1368  loss:  49.31771498918533 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1369  loss:  49.304754704236984 -- aux loss:  5.95736038684845\n",
      "training: epoch:  1370  loss:  49.29349011182785 -- aux loss:  5.951979756355286\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1370  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1371  loss:  49.32453137636185 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1372  loss:  49.29461884498596 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1373  loss:  49.30265247821808 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1374  loss:  49.297569036483765 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1375  loss:  49.2912013232708 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1376  loss:  49.2913361787796 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1377  loss:  49.28820511698723 -- aux loss:  5.953374981880188\n",
      "training: epoch:  1378  loss:  49.30045613646507 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1379  loss:  49.29312714934349 -- aux loss:  5.951971143484116\n",
      "training: epoch:  1380  loss:  49.291561514139175 -- aux loss:  5.951971054077148\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891128420829773\n",
      "validating: epoch:  1380  loss:  0.31891128420829773\n",
      "The current loss: 0.31891128420829773\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1381  loss:  49.29087507724762 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1382  loss:  49.30040928721428 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1383  loss:  49.303566575050354 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1384  loss:  49.3020681142807 -- aux loss:  5.951971024274826\n",
      "training: epoch:  1385  loss:  49.29411432147026 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1386  loss:  49.29643693566322 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1387  loss:  49.29574775695801 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1388  loss:  49.2997262775898 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1389  loss:  49.298472851514816 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1390  loss:  49.291296631097794 -- aux loss:  5.951971262693405\n",
      "the_last_loss:  0.31891128420829773\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1390  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31891128420829773\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1391  loss:  49.295094311237335 -- aux loss:  5.956014305353165\n",
      "training: epoch:  1392  loss:  49.29737263917923 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1393  loss:  49.28763809800148 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1394  loss:  49.28761467337608 -- aux loss:  5.952066659927368\n",
      "training: epoch:  1395  loss:  49.30355888605118 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1396  loss:  49.28927579522133 -- aux loss:  5.951970964670181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1397  loss:  49.28774678707123 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1398  loss:  49.30132406949997 -- aux loss:  5.951971650123596\n",
      "training: epoch:  1399  loss:  49.28921639919281 -- aux loss:  5.9573363065719604\n",
      "training: epoch:  1400  loss:  49.29957517981529 -- aux loss:  5.959830701351166\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1400  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1401  loss:  49.31060978770256 -- aux loss:  5.953454554080963\n",
      "training: epoch:  1402  loss:  49.31864219903946 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1403  loss:  49.302176624536514 -- aux loss:  5.952297657728195\n",
      "training: epoch:  1404  loss:  49.303901344537735 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1405  loss:  49.28784358501434 -- aux loss:  5.9519743621349335\n",
      "training: epoch:  1406  loss:  49.29261600971222 -- aux loss:  5.951988220214844\n",
      "training: epoch:  1407  loss:  49.28767955303192 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1408  loss:  49.289899289608 -- aux loss:  5.956871300935745\n",
      "training: epoch:  1409  loss:  49.311204880476 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1410  loss:  49.28937044739723 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1410  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1411  loss:  49.289272248744965 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1412  loss:  49.291021943092346 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1413  loss:  49.29318332672119 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1414  loss:  49.29243916273117 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1415  loss:  49.28830263018608 -- aux loss:  5.952516704797745\n",
      "training: epoch:  1416  loss:  49.29321309924126 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1417  loss:  49.30075317621231 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1418  loss:  49.28980177640915 -- aux loss:  5.951971590518951\n",
      "training: epoch:  1419  loss:  49.29337081313133 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1420  loss:  49.32115897536278 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1420  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 3\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1421  loss:  49.30942094326019 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1422  loss:  49.29322353005409 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1423  loss:  49.29692882299423 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1424  loss:  49.29636761546135 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1425  loss:  49.31605714559555 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1426  loss:  49.301166236400604 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1427  loss:  49.29136177897453 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1428  loss:  49.29722887277603 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1429  loss:  49.2925990819931 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1430  loss:  49.29691353440285 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1430  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 4\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1431  loss:  49.2936170399189 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1432  loss:  49.28776118159294 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1433  loss:  49.287608325481415 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1434  loss:  49.30962085723877 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1435  loss:  49.289185374975204 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1436  loss:  49.287926971912384 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1437  loss:  49.29472479224205 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1438  loss:  49.3085061609745 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1439  loss:  49.29272797703743 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1440  loss:  49.30070525407791 -- aux loss:  5.951971530914307\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1440  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 5\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1441  loss:  49.290308356285095 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1442  loss:  49.28914061188698 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1443  loss:  49.28774780035019 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1444  loss:  49.29240396618843 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1445  loss:  49.30317580699921 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1446  loss:  49.29208329319954 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1447  loss:  49.328644186258316 -- aux loss:  5.951971083879471\n",
      "training: epoch:  1448  loss:  49.28823047876358 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1449  loss:  49.29870027303696 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1450  loss:  49.31009975075722 -- aux loss:  5.9533199071884155\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1450  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 6\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1451  loss:  49.30024433135986 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1452  loss:  49.29058909416199 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1453  loss:  49.287844985723495 -- aux loss:  5.951982706785202\n",
      "training: epoch:  1454  loss:  49.291574627161026 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1455  loss:  49.31359592080116 -- aux loss:  5.953453898429871\n",
      "training: epoch:  1456  loss:  49.298520505428314 -- aux loss:  5.953338831663132\n",
      "training: epoch:  1457  loss:  49.29353687167168 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1458  loss:  49.28757831454277 -- aux loss:  5.951975017786026\n",
      "training: epoch:  1459  loss:  49.292402654886246 -- aux loss:  5.95495542883873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: epoch:  1460  loss:  49.292927980422974 -- aux loss:  5.951998084783554\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1460  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 7\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1461  loss:  49.33111613988876 -- aux loss:  5.952334016561508\n",
      "training: epoch:  1462  loss:  49.300769209861755 -- aux loss:  5.9519723653793335\n",
      "training: epoch:  1463  loss:  49.29300621151924 -- aux loss:  5.955202519893646\n",
      "training: epoch:  1464  loss:  49.29470458626747 -- aux loss:  5.953115910291672\n",
      "training: epoch:  1465  loss:  49.29141807556152 -- aux loss:  5.951979041099548\n",
      "training: epoch:  1466  loss:  49.29445245862007 -- aux loss:  5.951982080936432\n",
      "training: epoch:  1467  loss:  49.300547420978546 -- aux loss:  5.951970994472504\n",
      "training: epoch:  1468  loss:  49.29109886288643 -- aux loss:  5.953083366155624\n",
      "training: epoch:  1469  loss:  49.28950357437134 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1470  loss:  49.299578100442886 -- aux loss:  5.952185541391373\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.3153863549232483\n",
      "validating: epoch:  1470  loss:  0.3153863549232483\n",
      "The current loss: 0.3153863549232483\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 8\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1471  loss:  49.290942907333374 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1472  loss:  49.30438274145126 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1473  loss:  49.30386319756508 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1474  loss:  49.29473540186882 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1475  loss:  49.29116052389145 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1476  loss:  49.29686787724495 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1477  loss:  49.29394745826721 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1478  loss:  49.30060717463493 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1479  loss:  49.30321544408798 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1480  loss:  49.3111469745636 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.3153863549232483\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1480  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.3153863549232483\n",
      "trigger times: 0\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1481  loss:  49.2928472161293 -- aux loss:  5.95199379324913\n",
      "training: epoch:  1482  loss:  49.29171681404114 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1483  loss:  49.29272985458374 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1484  loss:  49.30021306872368 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1485  loss:  49.30682581663132 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1486  loss:  49.29326179623604 -- aux loss:  5.951991260051727\n",
      "training: epoch:  1487  loss:  49.29138395190239 -- aux loss:  5.951972544193268\n",
      "training: epoch:  1488  loss:  49.29205858707428 -- aux loss:  5.951971650123596\n",
      "training: epoch:  1489  loss:  49.29880028963089 -- aux loss:  5.95476695895195\n",
      "training: epoch:  1490  loss:  49.29312273859978 -- aux loss:  5.951971113681793\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31326156854629517\n",
      "validating: epoch:  1490  loss:  0.31326156854629517\n",
      "The current loss: 0.31326156854629517\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 1\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "training: epoch:  1491  loss:  49.2982941865921 -- aux loss:  5.952324360609055\n",
      "training: epoch:  1492  loss:  49.308572977781296 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1493  loss:  49.29642942547798 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1494  loss:  49.29144561290741 -- aux loss:  5.953403413295746\n",
      "training: epoch:  1495  loss:  49.30257606506348 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1496  loss:  49.288351476192474 -- aux loss:  5.952146768569946\n",
      "training: epoch:  1497  loss:  49.297597616910934 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1498  loss:  49.29800462722778 -- aux loss:  5.951971709728241\n",
      "training: epoch:  1499  loss:  49.31199890375137 -- aux loss:  5.951970964670181\n",
      "training: epoch:  1500  loss:  49.28907838463783 -- aux loss:  5.951970964670181\n",
      "the_last_loss:  0.31326156854629517\n",
      "running_loss_val:  0.31891125440597534\n",
      "validating: epoch:  1500  loss:  0.31891125440597534\n",
      "The current loss: 0.31891125440597534\n",
      "the_last_loss: 0.31326156854629517\n",
      "trigger times: 2\n",
      "sum mask2 - L1:  tensor(4799, device='cuda:0')\n",
      "sum mask2 - L2:  tensor(7553, device='cuda:0')\n",
      "sum mask2 - L3:  tensor(151, device='cuda:0')\n",
      "sum mask1 - L1 (aux):  tensor(1201, device='cuda:0')\n",
      "sum mask1 - L2 (aux):  tensor(2447, device='cuda:0')\n",
      "sum mask1 - L3 (aux):  tensor(49, device='cuda:0')\n",
      "recall\n",
      "tensor(0.9997)\n",
      "precision\n",
      "tensor(0.9990)\n",
      "f1_score\n",
      "tensor(0.9994)\n",
      "Accuracy of the network on test objects: 99 %\n",
      "99.89826\n",
      "recall\n",
      "tensor(0.4503)\n",
      "precision\n",
      "tensor(1.)\n",
      "f1_score\n",
      "tensor(0.6210)\n",
      "Accuracy of the network on test objects: 100 %\n",
      "100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscoperez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:943: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e95dd8450bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m                             \u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                             \u001b[0mroc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                             \u001b[0mroc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_loss_activated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPS1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/vsbms_multiple_classes/vsbms_multiple_classes/Network.py\u001b[0m in \u001b[0;36mget_roc_curve\u001b[0;34m(net, test_loader, input_size, name, title)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     '''optimal_idx = np.argmax(tpr - fpr)\n\u001b[1;32m    254\u001b[0m     \u001b[0moptimal_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimal_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    543\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    544\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    328\u001b[0m                          \"is not defined in that case.\")\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "learning_rate = 0.005\n",
    "samples = 3000\n",
    "epsilon=0\n",
    "results = []\n",
    "#for epsilon in [0.1, 0.05, 0.025, 0.15]:\n",
    "for batch_size in [256]:\n",
    "    for hidden_size in [100]:\n",
    "        for aux_loss_activated in [True, False]:\n",
    "            for EPS1 in [0.025]:\n",
    "                for n in [50000]:\n",
    "                    for opt in [1]:\n",
    "                        for t in range(10):\n",
    "                            train_dataset, test_dataset = ut.load_files(dataset=1)\n",
    "                            test_dataseta  = RRab_test[train_dataset.columns]\n",
    "                            print(test_dataset.shape)\n",
    "                            test_dataset = pd.concat([test_dataseta[test_dataseta.label=='ClassB'], test_dataseta])\n",
    "                            print(test_dataset.shape)\n",
    "                            test_dataset['random'] = np.random.random(test_dataset.shape[0])\n",
    "                            test_dataset = test_dataset.sort_values('random')\n",
    "                            del test_dataset['random']\n",
    "                            input_size = train_dataset.shape[1]-1\n",
    "                            train_dataset, test_dataset = ut.delete_outliers(train_dataset, test_dataset)\n",
    "                            if n < 50000:\n",
    "                                train_dataset = ut.down_sampling(train_dataset)\n",
    "                                train_dataset = train_dataset.sample(n)\n",
    "                            else: \n",
    "                                trainig_dataset_a = train_dataset[train_dataset.label=='ClassA']\n",
    "                                n2 = n - trainig_dataset_a.shape[0]\n",
    "                                trainig_dataset_b = train_dataset[~(train_dataset.label=='ClassA')].sample(n2)\n",
    "                                train_dataset = pd.concat([trainig_dataset_a, trainig_dataset_b])\n",
    "                            \n",
    "                            train_dataset = ut.sort_columns(train_dataset)\n",
    "                            test_dataset = ut.sort_columns(test_dataset)\n",
    "                            test_dataset_pred = test_dataset.copy()\n",
    "                            train_dataset_pred = train_dataset.copy()\n",
    "\n",
    "                            data_prior = ut.generate_samples_2D(samples, train_dataset, distribution='gaussian')\n",
    "                            if train_dataset[train_dataset.label=='ClassB'].shape[0] >= samples:\n",
    "                                samples_prior = samples \n",
    "                            else: \n",
    "                                samples_prior = train_dataset[train_dataset.label=='ClassB'].shape[0] \n",
    "\n",
    "                            data_prior = pd.concat([data_prior, train_dataset[train_dataset.label=='ClassB'].sample(samples_prior)])\n",
    "\n",
    "\n",
    "                            train_dataset, test_dataset, data_prior = ut.normalize(train_dataset, test_dataset, data_prior)\n",
    "\n",
    "                            train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2)\n",
    "\n",
    "                            train_dataset_prior, val_dataset_prior = train_test_split(data_prior, test_size=0.2)\n",
    "                            _, _, train_target_prior, train_loader_prior = ut.get_tensors(train_dataset_prior, batch_size)\n",
    "                            _, _, val_target_prior, val_loader_prior     = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, train_target, train_loader             = ut.get_tensors(train_dataset, batch_size)\n",
    "                            _, _, train_target_pred, train_loader_pred   = ut.get_tensors(train_dataset_pred, batch_size)\n",
    "                            _, _, val_target, val_loader                 = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, test_target, test_loader               = ut.get_tensors(test_dataset, batch_size)\n",
    "                            _, _, test_target_pred, test_loader_pred     = ut.get_tensors(test_dataset_pred, batch_size)\n",
    "\n",
    "                            net = Net(input_size, hidden_size, hidden_size, num_classes)\n",
    "                            net.cuda()\n",
    "\n",
    "                            hist_val, hist_train, _ = nn.train(net, train_loader, train_loader_prior, val_loader, test_loader,\n",
    "                            EPS1, learning_rate, input_size, aux_loss_activated=aux_loss_activated, model_number=t, size=n)\n",
    "\n",
    "                            acc_train, recall_train, f1_train = nn.get_results(net, train_loader, input_size)\n",
    "                            acc_test, recall_test, f1_test  = nn.get_results(net, test_loader, input_size)\n",
    "                            roc_train = nn.get_roc_curve(net, train_loader, input_size)\n",
    "                            roc_test = nn.get_roc_curve(net, test_loader, input_size)\n",
    "                            results.append([acc_train, acc_test,recall_train, recall_test, f1_train, f1_test, roc_train, roc_test, epsilon, batch_size, hidden_size, aux_loss_activated, EPS1, n, opt])\n",
    "\n",
    "                            pd.DataFrame(results, columns=['acc_train', 'acc_test','recall_train', 'recall_test','f1_train', 'f1_test', \n",
    "                                   'roc_train', 'roc_test', 'epsilon', 'batch_size', 'hidden_size',\n",
    "                             'aux_loss_activated', 'EPS1', 'n', 'opt']).to_csv('RRab_17_01_2023_subclasses_gaussian2d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "num_classes = 2\n",
    "learning_rate = 0.005\n",
    "samples = 3000\n",
    "epsilon=0\n",
    "#for epsilon in [0.1, 0.05, 0.025, 0.15]:\n",
    "for batch_size in [256]:\n",
    "    for hidden_size in [100]:\n",
    "        for aux_loss_activated in [True, False]:\n",
    "            for EPS1 in [0.025]:\n",
    "                for n in [50000]:\n",
    "                    for opt in [1]:\n",
    "                        for t in range(10):\n",
    "                            train_dataset, test_dataset = ut.load_files(dataset=1)\n",
    "                            test_dataseta  = RRc_test[train_dataset.columns]\n",
    "                            test_dataset = pd.concat([test_dataseta[test_dataseta.label=='ClassB'], test_dataseta])\n",
    "                            test_dataset['random'] = np.random.random(test_dataset.shape[0])\n",
    "                            test_dataset = test_dataset.sort_values('random')\n",
    "                            del test_dataset['random']\n",
    "                            input_size = train_dataset.shape[1]-1\n",
    "                            \n",
    "                            train_dataset, test_dataset = ut.delete_outliers(train_dataset, test_dataset)\n",
    "                            if n < 50000:\n",
    "                                train_dataset = ut.down_sampling(train_dataset)\n",
    "                                train_dataset = train_dataset.sample(n)\n",
    "                            else: \n",
    "                                trainig_dataset_a = train_dataset[train_dataset.label=='ClassA']\n",
    "                                n2 = n - trainig_dataset_a.shape[0]\n",
    "                                trainig_dataset_b = train_dataset[~(train_dataset.label=='ClassA')].sample(n2)\n",
    "                                train_dataset = pd.concat([trainig_dataset_a, trainig_dataset_b])\n",
    "                            \n",
    "                            train_dataset = ut.sort_columns(train_dataset)\n",
    "                            test_dataset = ut.sort_columns(test_dataset)\n",
    "                            test_dataset_pred = test_dataset.copy()\n",
    "                            train_dataset_pred = train_dataset.copy()\n",
    "\n",
    "                            data_prior = ut.generate_samples_2D(samples, train_dataset, distribution='gaussian')\n",
    "                            if train_dataset[train_dataset.label=='ClassB'].shape[0] >= samples:\n",
    "                                samples_prior = samples \n",
    "                            else: \n",
    "                                samples_prior = train_dataset[train_dataset.label=='ClassB'].shape[0] \n",
    "\n",
    "                            data_prior = pd.concat([data_prior, train_dataset[train_dataset.label=='ClassB'].sample(samples_prior)])\n",
    "\n",
    "\n",
    "                            train_dataset, test_dataset, data_prior = ut.normalize(train_dataset, test_dataset, data_prior)\n",
    "\n",
    "                            train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2)\n",
    "\n",
    "                            train_dataset_prior, val_dataset_prior = train_test_split(data_prior, test_size=0.2)\n",
    "                            _, _, train_target_prior, train_loader_prior = ut.get_tensors(train_dataset_prior, batch_size)\n",
    "                            _, _, val_target_prior, val_loader_prior     = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, train_target, train_loader             = ut.get_tensors(train_dataset, batch_size)\n",
    "                            _, _, train_target_pred, train_loader_pred   = ut.get_tensors(train_dataset_pred, batch_size)\n",
    "                            _, _, val_target, val_loader                 = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, test_target, test_loader               = ut.get_tensors(test_dataset, batch_size)\n",
    "                            _, _, test_target_pred, test_loader_pred     = ut.get_tensors(test_dataset_pred, batch_size)\n",
    "\n",
    "                            net = Net(input_size, hidden_size, hidden_size, num_classes)\n",
    "                            net.cuda()\n",
    "\n",
    "                            hist_val, hist_train, _ = nn.train(net, train_loader, train_loader_prior, val_loader, test_loader,\n",
    "                            EPS1, learning_rate, input_size, aux_loss_activated=aux_loss_activated, model_number=t, size=n)\n",
    "\n",
    "                            acc_train, recall_train, f1_train = nn.get_results(net, train_loader, input_size)\n",
    "                            acc_test, recall_test, f1_test  = nn.get_results(net, test_loader, input_size)\n",
    "                            roc_train = nn.get_roc_curve(net, train_loader, input_size)\n",
    "                            roc_test = nn.get_roc_curve(net, test_loader, input_size)\n",
    "                            results.append([acc_train, acc_test,recall_train, recall_test, f1_train, f1_test, roc_train, roc_test, epsilon, batch_size, hidden_size, aux_loss_activated, EPS1, n, opt])\n",
    "\n",
    "                            pd.DataFrame(results, columns=['acc_train', 'acc_test','recall_train', 'recall_test','f1_train', 'f1_test', \n",
    "                                   'roc_train', 'roc_test', 'epsilon', 'batch_size', 'hidden_size',\n",
    "                             'aux_loss_activated', 'EPS1', 'n', 'opt']).to_csv('RRc_17_01_2023_subclasses_gaussian2d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "num_classes = 2\n",
    "learning_rate = 0.005\n",
    "samples = 3000\n",
    "epsilon=0\n",
    "#for epsilon in [0.1, 0.05, 0.025, 0.15]:\n",
    "for batch_size in [256]:\n",
    "    for hidden_size in [100]:\n",
    "        for aux_loss_activated in [True, False]:\n",
    "            for EPS1 in [0.025]:\n",
    "                for n in [50000]:\n",
    "                    for opt in [1]:\n",
    "                        for t in range(10):\n",
    "                            train_dataset, test_dataset = ut.load_files(dataset=1)\n",
    "                            test_dataseta  = RRd_test[train_dataset.columns]\n",
    "                            test_dataset = pd.concat([test_dataseta[test_dataseta.label=='ClassB'], test_dataseta])\n",
    "                            test_dataset['random'] = np.random.random(test_dataset.shape[0])\n",
    "                            test_dataset = test_dataset.sort_values('random')\n",
    "                            del test_dataset['random']\n",
    "                            input_size = train_dataset.shape[1]-1\n",
    "                            \n",
    "                            \n",
    "                            train_dataset, test_dataset = ut.delete_outliers(train_dataset, test_dataset)\n",
    "                            if n < 50000:\n",
    "                                train_dataset = ut.down_sampling(train_dataset)\n",
    "                                train_dataset = train_dataset.sample(n)\n",
    "                            else: \n",
    "                                trainig_dataset_a = train_dataset[train_dataset.label=='ClassA']\n",
    "                                n2 = n - trainig_dataset_a.shape[0]\n",
    "                                trainig_dataset_b = train_dataset[~(train_dataset.label=='ClassA')].sample(n2)\n",
    "                                train_dataset = pd.concat([trainig_dataset_a, trainig_dataset_b])\n",
    "                            \n",
    "                            train_dataset = ut.sort_columns(train_dataset)\n",
    "                            test_dataset = ut.sort_columns(test_dataset)\n",
    "                            test_dataset_pred = test_dataset.copy()\n",
    "                            train_dataset_pred = train_dataset.copy()\n",
    "\n",
    "                            data_prior = ut.generate_samples_2D(samples, train_dataset, distribution='gaussian')\n",
    "                            if train_dataset[train_dataset.label=='ClassB'].shape[0] >= samples:\n",
    "                                samples_prior = samples \n",
    "                            else: \n",
    "                                samples_prior = train_dataset[train_dataset.label=='ClassB'].shape[0] \n",
    "\n",
    "                            data_prior = pd.concat([data_prior, train_dataset[train_dataset.label=='ClassB'].sample(samples_prior)])\n",
    "\n",
    "\n",
    "                            train_dataset, test_dataset, data_prior = ut.normalize(train_dataset, test_dataset, data_prior)\n",
    "\n",
    "                            train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2)\n",
    "\n",
    "                            train_dataset_prior, val_dataset_prior = train_test_split(data_prior, test_size=0.2)\n",
    "                            _, _, train_target_prior, train_loader_prior = ut.get_tensors(train_dataset_prior, batch_size)\n",
    "                            _, _, val_target_prior, val_loader_prior     = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, train_target, train_loader             = ut.get_tensors(train_dataset, batch_size)\n",
    "                            _, _, train_target_pred, train_loader_pred   = ut.get_tensors(train_dataset_pred, batch_size)\n",
    "                            _, _, val_target, val_loader                 = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, test_target, test_loader               = ut.get_tensors(test_dataset, batch_size)\n",
    "                            _, _, test_target_pred, test_loader_pred     = ut.get_tensors(test_dataset_pred, batch_size)\n",
    "\n",
    "                            net = Net(input_size, hidden_size, hidden_size, num_classes)\n",
    "                            net.cuda()\n",
    "\n",
    "                            hist_val, hist_train, _ = nn.train(net, train_loader, train_loader_prior, val_loader, test_loader,\n",
    "                            EPS1, learning_rate, input_size, aux_loss_activated=aux_loss_activated, model_number=t, size=n)\n",
    "\n",
    "                            acc_train, recall_train, f1_train = nn.get_results(net, train_loader, input_size)\n",
    "                            acc_test, recall_test, f1_test  = nn.get_results(net, test_loader, input_size)\n",
    "                            roc_train = nn.get_roc_curve(net, train_loader, input_size)\n",
    "                            roc_test = nn.get_roc_curve(net, test_loader, input_size)\n",
    "                            results.append([acc_train, acc_test,recall_train, recall_test, f1_train, f1_test, roc_train, roc_test, epsilon, batch_size, hidden_size, aux_loss_activated, EPS1, n, opt])\n",
    "\n",
    "                            pd.DataFrame(results, columns=['acc_train', 'acc_test','recall_train', 'recall_test','f1_train', 'f1_test', \n",
    "                                   'roc_train', 'roc_test', 'epsilon', 'batch_size', 'hidden_size',\n",
    "                             'aux_loss_activated', 'EPS1', 'n', 'opt']).to_csv('RRd_17_01_2023_subclasses_gaussian2d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "num_classes = 2\n",
    "learning_rate = 0.005\n",
    "samples = 3000\n",
    "epsilon=0\n",
    "#for epsilon in [0.1, 0.05, 0.025, 0.15]:\n",
    "for batch_size in [256]:\n",
    "    for hidden_size in [100]:\n",
    "        for aux_loss_activated in [True, False]:\n",
    "            for EPS1 in [0.025]:\n",
    "                for n in [50000]:\n",
    "                    for opt in [1]:\n",
    "                        for t in range(10):\n",
    "                            \n",
    "                            train_dataset, test_dataset = ut.load_files(dataset=1)\n",
    "                            test_dataseta  = RRe_test[train_dataset.columns]\n",
    "                            test_dataset = pd.concat([test_dataseta[test_dataseta.label=='ClassB'], test_dataseta])\n",
    "                            test_dataset['random'] = np.random.random(test_dataset.shape[0])\n",
    "                            test_dataset = test_dataset.sort_values('random')\n",
    "                            del test_dataset['random']\n",
    "                            input_size = train_dataset.shape[1]-1\n",
    "                            \n",
    "                            input_size = train_dataset.shape[1]-1\n",
    "                            train_dataset, test_dataset = ut.delete_outliers(train_dataset, test_dataset)\n",
    "                            if n < 50000:\n",
    "                                train_dataset = ut.down_sampling(train_dataset)\n",
    "                                train_dataset = train_dataset.sample(n)\n",
    "                            else: \n",
    "                                trainig_dataset_a = train_dataset[train_dataset.label=='ClassA']\n",
    "                                n2 = n - trainig_dataset_a.shape[0]\n",
    "                                trainig_dataset_b = train_dataset[~(train_dataset.label=='ClassA')].sample(n2)\n",
    "                                train_dataset = pd.concat([trainig_dataset_a, trainig_dataset_b])\n",
    "                            \n",
    "                            train_dataset = ut.sort_columns(train_dataset)\n",
    "                            test_dataset = ut.sort_columns(test_dataset)\n",
    "                            test_dataset_pred = test_dataset.copy()\n",
    "                            train_dataset_pred = train_dataset.copy()\n",
    "\n",
    "                            data_prior = ut.generate_samples_2D(samples, train_dataset, distribution='gaussian')\n",
    "                            if train_dataset[train_dataset.label=='ClassB'].shape[0] >= samples:\n",
    "                                samples_prior = samples \n",
    "                            else: \n",
    "                                samples_prior = train_dataset[train_dataset.label=='ClassB'].shape[0] \n",
    "\n",
    "                            data_prior = pd.concat([data_prior, train_dataset[train_dataset.label=='ClassB'].sample(samples_prior)])\n",
    "\n",
    "\n",
    "                            train_dataset, test_dataset, data_prior = ut.normalize(train_dataset, test_dataset, data_prior)\n",
    "\n",
    "                            train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2)\n",
    "\n",
    "                            train_dataset_prior, val_dataset_prior = train_test_split(data_prior, test_size=0.2)\n",
    "                            _, _, train_target_prior, train_loader_prior = ut.get_tensors(train_dataset_prior, batch_size)\n",
    "                            _, _, val_target_prior, val_loader_prior     = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, train_target, train_loader             = ut.get_tensors(train_dataset, batch_size)\n",
    "                            _, _, train_target_pred, train_loader_pred   = ut.get_tensors(train_dataset_pred, batch_size)\n",
    "                            _, _, val_target, val_loader                 = ut.get_tensors(val_dataset_prior, batch_size)\n",
    "                            _, _, test_target, test_loader               = ut.get_tensors(test_dataset, batch_size)\n",
    "                            _, _, test_target_pred, test_loader_pred     = ut.get_tensors(test_dataset_pred, batch_size)\n",
    "\n",
    "                            net = Net(input_size, hidden_size, hidden_size, num_classes)\n",
    "                            net.cuda()\n",
    "\n",
    "                            hist_val, hist_train, _ = nn.train(net, train_loader, train_loader_prior, val_loader, test_loader,\n",
    "                            EPS1, learning_rate, input_size, aux_loss_activated=aux_loss_activated, model_number=t, size=n)\n",
    "\n",
    "                            acc_train, recall_train, f1_train = nn.get_results(net, train_loader, input_size)\n",
    "                            acc_test, recall_test, f1_test  = nn.get_results(net, test_loader, input_size)\n",
    "                            roc_train = nn.get_roc_curve(net, train_loader, input_size)\n",
    "                            roc_test = nn.get_roc_curve(net, test_loader, input_size)\n",
    "                            results.append([acc_train, acc_test,recall_train, recall_test, f1_train, f1_test, roc_train, roc_test, epsilon, batch_size, hidden_size, aux_loss_activated, EPS1, n, opt])\n",
    "\n",
    "                            pd.DataFrame(results, columns=['acc_train', 'acc_test','recall_train', 'recall_test','f1_train', 'f1_test', \n",
    "                                   'roc_train', 'roc_test', 'epsilon', 'batch_size', 'hidden_size',\n",
    "                             'aux_loss_activated', 'EPS1', 'n', 'opt']).to_csv('RRe_17_01_2023_subclasses_gaussian2d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50000\n",
    "samples = 3000\n",
    "for i in range(0,30):\n",
    "\n",
    "    net = Net(input_size, hidden_size, hidden_size, num_classes)\n",
    "    net.load_state_dict(dict(torch.load('model_'+str(i)+'_False_50000.pt'))['model'+str(i)+'_False_50000'])\n",
    "    net.eval()\n",
    "    net.cuda()\n",
    "\n",
    "    train_dataset , test_dataset = ut.load_files(dataset=1)\n",
    "    input_size = test_dataset.shape[1]-1\n",
    "    train_dataset, test_dataset = ut.delete_outliers(train_dataset, test_dataset)\n",
    "    \n",
    "    trainig_dataset_a = train_dataset[train_dataset.label=='ClassA']\n",
    "    n2 = n - trainig_dataset_a.shape[0]\n",
    "    trainig_dataset_b = train_dataset[~(train_dataset.label=='ClassA')].sample(n2)\n",
    "    train_dataset = pd.concat([trainig_dataset_a, trainig_dataset_b])\n",
    "    test_dataset = ut.sort_columns(test_dataset)\n",
    "    test_dataset_pred = test_dataset.copy()\n",
    "    data_prior = ut.generate_samples_2D(samples, train_dataset, distribution='gaussian')\n",
    "    if train_dataset[train_dataset.label=='ClassB'].shape[0] >= samples:\n",
    "        samples_prior = samples \n",
    "    else: \n",
    "        samples_prior = train_dataset[train_dataset.label=='ClassB'].shape[0] \n",
    "\n",
    "    data_prior = pd.concat([data_prior, train_dataset[train_dataset.label=='ClassB'].sample(samples_prior)])\n",
    "    train_dataset, test_dataset, data_prior = ut.normalize(train_dataset, test_dataset, data_prior)\n",
    "\n",
    "    _, _, test_target, test_loader               = ut.get_tensors(test_dataset, batch_size)\n",
    "    _, _, test_target_pred, test_loader_pred     = ut.get_tensors(test_dataset_pred, batch_size)\n",
    "\n",
    "    acc_test, recall_test, f1_test  = nn.get_results(net, test_loader, input_size)\n",
    "    roc_test = nn.get_roc_curve(net, test_loader, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RRab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
